{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.rk import RegressionKriging\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_soil_texture(sand, silt, clay):\n",
    "    \"\"\"\n",
    "    根据国际土壤质地三角图对土壤质地进行分类，共有12个类别。\n",
    "    \n",
    "    参数:\n",
    "    sand (float): 砂粒百分比 (0-100) >0.2mm\n",
    "    silt (float): 粉粒百分比 (0-100) >=0.002mm and <0.2mm\n",
    "    clay (float): 粘粒百分比 (0-100) < 0.002\n",
    "    \n",
    "    返回:\n",
    "    str: 土壤质地分类结果的英文名称\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查砂粒、粉粒和粘粒的百分比之和是否接近100%\n",
    "    if not 98 <= sand + silt + clay <= 102:\n",
    "        # 如果不符合条件，打印提示信息\n",
    "        print(\"砂粒、粉粒和粘粒的百分比之和应大约为100%\")\n",
    "\n",
    "    # 对百分比进行归一化处理，确保它们加起来等于100\n",
    "    total = sand + silt + clay\n",
    "    sand, silt, clay = (sand / total * 100, silt / total * 100, clay / total * 100)\n",
    "\n",
    "    # 根据国际土壤质地三角图进行土壤质地分类的逻辑\n",
    "    if clay >= 40:\n",
    "        # 如果粘粒含量大于等于40%\n",
    "        if silt >= 40:\n",
    "            return \"SiltyClay\"  # 粉质粘土\n",
    "        elif sand <= 45:\n",
    "            return \"Clay\"  # 粘土\n",
    "        else:\n",
    "            return \"SandyClay\"  # 沙质粘土\n",
    "    elif clay >= 27:\n",
    "        # 如果粘粒含量大于等于27%\n",
    "        if silt < 28 and sand > 45:\n",
    "            return \"SandyClayLoam\"  # 沙质粘壤土\n",
    "        elif silt >= 28 and silt < 40:\n",
    "            return \"ClayLoam\"  # 粘壤土\n",
    "        else:\n",
    "            return \"SiltyClayLoam\"  # 粉质粘壤土\n",
    "    elif clay >= 20:\n",
    "        # 如果粘粒含量大于等于20%\n",
    "        if sand >= 52:\n",
    "            return \"SandyClayLoam\"  # 沙质粘壤土\n",
    "        elif silt >= 50:\n",
    "            return \"SiltyClayLoam\"  # 粉质粘壤土\n",
    "        else:\n",
    "            return \"ClayLoam\"  # 粘壤土\n",
    "    elif silt >= 50:\n",
    "        # 如果粉粒含量大于等于50%\n",
    "        if silt >= 80:\n",
    "            return \"Silt\"  # 粉土\n",
    "        else:\n",
    "            return \"SiltLoam\"  # 粉壤土\n",
    "    elif sand >= 85:\n",
    "        return \"Sand\"  # 沙土\n",
    "    elif sand >= 70:\n",
    "        return \"LoamySand\"  # 壤沙土\n",
    "    elif sand >= 52:\n",
    "        return \"SandyLoam\"  # 沙壤土\n",
    "    else:\n",
    "        return \"Loam\"  # 壤土\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classics_classification(df, label_col, feature_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    n_iter_search = 100\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 打印最佳参数\n",
    "    best_random_params = random_search.best_params_\n",
    "    print('Best Random Parameters: \\n', best_random_params)\n",
    "    \n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    best_randomrf = random_search.best_estimator_\n",
    "    testrandom_score = best_randomrf.score(X_test, y_test)\n",
    "    trainrandom_score = best_randomrf.score(X_train, y_train)\n",
    "\n",
    "    print('RandomSearch Test accuracy:', testrandom_score,'RandomSearch Train accuracy:',trainrandom_score)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    print(f\"Random search best params: {best_random_params}\")\n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_random_params['n_estimators'] - 50), best_random_params['n_estimators'], min(1000, best_random_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_random_params['max_depth'] - 5), best_random_params['max_depth'], best_random_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_random_params['min_samples_split'] - 2), best_random_params['min_samples_split'], best_random_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_random_params['min_samples_leaf'] - 1), best_random_params['min_samples_leaf'], best_random_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=best_randomrf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_gr_params = grid_search.best_params_\n",
    "    best_gr_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 打印最佳参数\n",
    "    print('Best Grid Parameters: \\n', best_gr_params)\n",
    "    \n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    test_gr_score = best_gr_rf.score(X_test, y_test)\n",
    "    train_gr_score = best_gr_rf.score(X_train, y_train)\n",
    "    print('GridSearch Test accuracy:', test_gr_score,'GridSearch Train accuracy:',train_gr_score)\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_gr_importances = best_gr_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_gr_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_gr_rf.predict(X_train)\n",
    "    y_test_pred = best_gr_rf.predict(X_test)\n",
    "    \n",
    "    # 计算评估指标\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest Accuracy: {accuracy}\")\n",
    "    print(f\"Random Forest Precision: {precision}\")\n",
    "    print(f\"Random Forest Recall: {recall}\")\n",
    "    print(f\"Random Forest F1-score: {f1}\")\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(np.unique(y)))\n",
    "    plt.xticks(tick_marks, np.unique(y), rotation=45)\n",
    "    plt.yticks(tick_marks, np.unique(y))\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    \n",
    "    # 在混淆矩阵中添加文本\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'confusion_matrix.png'))\n",
    "    \n",
    "    # 绘制评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
    "    values = [accuracy, precision, recall, f1]\n",
    "\n",
    "    bars = plt.bar(metrics, values)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Classification Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    \n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_gr_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": feature_cols,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-score\": f1\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF(regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rf_classics(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 确保坐标列为浮点型\n",
    "    for col in coord_cols:\n",
    "        X_train[col] = X_train[col].astype(float)\n",
    "        X_test[col] = X_test[col].astype(float)\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    n_iter_search = 100\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_random_params = random_search.best_params_\n",
    "    print('Best Random Parameters:', best_random_params)\n",
    "    \n",
    "    best_randomrf = random_search.best_estimator_\n",
    "    testrandom_score = best_randomrf.score(X_test, y_test)\n",
    "    trainrandom_score = best_randomrf.score(X_train, y_train)\n",
    "    print(f'RandomSearch Test accuracy: {testrandom_score:.4f}, Train accuracy: {trainrandom_score:.4f}')\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_random_params['n_estimators'] - 50), best_random_params['n_estimators'], min(1000, best_random_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_random_params['max_depth'] - 5), best_random_params['max_depth'], best_random_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_random_params['min_samples_split'] - 2), best_random_params['min_samples_split'], best_random_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_random_params['min_samples_leaf'] - 1), best_random_params['min_samples_leaf'], best_random_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=best_randomrf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_gr_params = grid_search.best_params_\n",
    "    best_gr_rf = grid_search.best_estimator_\n",
    "    print('Best Grid Parameters:', best_gr_params)\n",
    "    \n",
    "    test_gr_score = best_gr_rf.score(X_test, y_test)\n",
    "    train_gr_score = best_gr_rf.score(X_train, y_train)\n",
    "    print(f'GridSearch Test accuracy: {test_gr_score:.4f}, Train accuracy: {train_gr_score:.4f}')\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_gr_importances = best_gr_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_gr_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_gr_rf.predict(X_train)\n",
    "    y_test_pred = best_gr_rf.predict(X_test)\n",
    "    \n",
    "    # 评估函数\n",
    "    def evaluate_model(y_true, y_pred, model_name):\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"{model_name} - R2: {r2:.4f}, MAE: {mae:.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}\")\n",
    "        return r2, mae, mse, rmse\n",
    "    \n",
    "    rf_scores = evaluate_model(y_test, y_test_pred, \"Random Forest\")\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    rk_scores = evaluate_model(y_test, predictions_test, \"Regression Kriging\")\n",
    "    \n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_gr_rf, f)\n",
    "    \n",
    "    # 绘图函数\n",
    "    def plot_feature_importance(importance_df, save_path):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.ylabel('Feature')\n",
    "        plt.title('Feature Importances')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_evaluation_scores(rf_scores, rk_scores, save_path):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "        \n",
    "        plt.subplot(2, 1, 1)\n",
    "        bars_rf = plt.bar(metrics, rf_scores)\n",
    "        plt.ylabel('Scores')\n",
    "        plt.title('Random Forest Evaluation Scores')\n",
    "        for bar, value in zip(bars_rf, rf_scores):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.subplot(2, 1, 2)\n",
    "        bars_rk = plt.bar(metrics, rk_scores)\n",
    "        plt.xlabel('Metrics')\n",
    "        plt.ylabel('Scores')\n",
    "        plt.title('Regression Kriging Evaluation Scores')\n",
    "        for bar, value in zip(bars_rk, rk_scores):\n",
    "            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{value:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    \n",
    "    # 绘制图表\n",
    "    plot_feature_importance(importance_df, os.path.join(os.path.dirname(save_model_path), 'feature_importance.png'))\n",
    "    plot_evaluation_scores(rf_scores, rk_scores, os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": feature_cols,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": dict(zip(['R2', 'MAE', 'MSE', 'RMSE'], rf_scores)),\n",
    "        \"RegressionKriging\": dict(zip(['R2', 'MAE', 'MSE', 'RMSE'], rk_scores))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rf_classics_2(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    rf = RandomForestRegressor()\n",
    "    n_iter_search = 100\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # 打印最佳参数\n",
    "    best_random_params = random_search.best_params_\n",
    "    print('Best Random Parameters: \\n', best_random_params)\n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    best_randomrf = random_search.best_estimator_\n",
    "    testrandom_score = best_randomrf.score(X_test, y_test)\n",
    "    trainrandom_score = best_randomrf.score(X_train, y_train)\n",
    "\n",
    "    print('RandomSearch Test accuracy:', testrandom_score,'RandomSearch Train accuracy:',trainrandom_score)\n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    print(f\"Random search best params: {best_random_params}\")\n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_random_params['n_estimators'] - 50), best_random_params['n_estimators'], min(1000, best_random_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_random_params['max_depth'] - 5), best_random_params['max_depth'], best_random_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_random_params['min_samples_split'] - 2), best_random_params['min_samples_split'], best_random_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_random_params['min_samples_leaf'] - 1), best_random_params['min_samples_leaf'], best_random_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=best_randomrf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # 最优参数\n",
    "    best_gr_params = grid_search.best_params_\n",
    "    best_gr_rf = grid_search.best_estimator_\n",
    "    # 打印最佳参数\n",
    "    print('Best Grid Parameters: \\n', best_gr_params)\n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    test_gr_score = best_gr_rf.score(X_test, y_test)\n",
    "    train_gr_score = best_gr_rf.score(X_train, y_train)\n",
    "    print('GridSearch Test accuracy:', test_gr_score,'GridSearch Train accuracy:',train_gr_score)\n",
    "    # 特征重要性\n",
    "    feature_gr_importances = best_gr_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_gr_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_gr_rf.predict(X_train)\n",
    "    y_test_pred = best_gr_rf.predict(X_test)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    # 数据类型统一\n",
    "    X_train[coord_cols[0]] = X_train[coord_cols[0]].astype(float)\n",
    "    X_train[coord_cols[1]] = X_train[coord_cols[1]].astype(float)\n",
    "    X_test[coord_cols[0]] = X_test[coord_cols[0]].astype(float)\n",
    "    X_test[coord_cols[1]] = X_test[coord_cols[1]].astype(float)\n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_gr_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": feature_cols,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFRK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regression_prediction_cc(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    n_iter_search = 50\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_params['n_estimators'] - 50), best_params['n_estimators'], min(1000, best_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_params['max_depth'] - 5), best_params['max_depth'], best_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_params['min_samples_split'] - 2), best_params['min_samples_split'], best_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_params['min_samples_leaf'] - 1), best_params['min_samples_leaf'], best_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regression_prediction(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    n_iter_search = 50\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [_ for _ in range(best_params['n_estimators'] - 5, best_params['n_estimators'] + 5,2)],\n",
    "        'max_depth': [_ for _ in range(best_params['max_depth'] - 2, best_params['max_depth'] + 2)],\n",
    "        'min_samples_split': [_ for _ in range(best_params['min_samples_split'] - 2, best_params['min_samples_split'] + 2)],\n",
    "        'min_samples_leaf': [_ for _ in range(best_params['min_samples_leaf'] - 2, best_params['min_samples_leaf'] + 2)]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # 使用克里回归模型训练\n",
    "    rk = RegressionKriging(regression_model=best_rf,n_closest_points=36)\n",
    "    rk.fit(X_train_selected, X_train[coord_cols].values, y_train)\n",
    "    y_pred_rk = rk.predict(X_test_selected, X_test[coord_cols].values)\n",
    "\n",
    "    r2_rk = r2_score(y_test, y_pred_rk)\n",
    "    mae_rk = mean_absolute_error(y_test, y_pred_rk)\n",
    "    mse_rk = mean_squared_error(y_test, y_pred_rk)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "\n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv(r\"F:\\cache_data\\pre_property_table\\gl\\feature_gl.csv\")\n",
    "print(len(data))\n",
    "# 删除有缺失值的行\n",
    "# data.dropna(inplace=True)\n",
    "# len(data),data.columns\n",
    "# 选择数值列并计算它们的均值\n",
    "numeric_cols = data.select_dtypes(include=[np.number])\n",
    "means = numeric_cols.mean()\n",
    "# 使用均值填充每个数值列的缺失值\n",
    "data[numeric_cols.columns] = data[numeric_cols.columns].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [_ for _ in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DLMCN'] = data['DLMCN'].astype(\"category\")\n",
    "data['MZMC'] = data['MZMC'].astype(\"category\")\n",
    "data['slope_postion_101'] = data['slope_postion_101'].astype(\"category\")\n",
    "# 用户上传的DataFrame\n",
    "df = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_ph = df[df['ph']==0.0001]\n",
    "df.drop(drop_ph.index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_cols = [\"lon\", \"lat\"]\n",
    "# 用户选择的标签列和特征列\n",
    "# label_col = \"ph\"\n",
    "feature_cols = ['aligned_AnalyticalHillshading',\n",
    " 'aligned_Aspect',\n",
    " 'aligned_ChannelNetworkBaseLevel',\n",
    " 'aligned_ChannelNetworkDistance',\n",
    " 'aligned_Contrast',\n",
    " 'aligned_ConvergenceIndex',\n",
    " 'aligned_Correlation',\n",
    " 'aligned_DEM',\n",
    " 'aligned_Dissimilarity',\n",
    " 'aligned_Entropy',\n",
    " 'aligned_ETP2022_3',\n",
    " 'aligned_ETP2022_mean',\n",
    " 'aligned_evi',\n",
    " 'aligned_Homogeneity',\n",
    " 'aligned_LSFactor',\n",
    " 'aligned_lswi',\n",
    " 'aligned_Mean',\n",
    " 'aligned_mndwi',\n",
    " 'aligned_ndmi',\n",
    " 'aligned_ndvi',\n",
    " 'aligned_ndwi',\n",
    " 'aligned_NIGHT2022',\n",
    " 'aligned_pca_1',\n",
    " 'aligned_pca_2',\n",
    " 'aligned_PlanCurvature',\n",
    " 'aligned_PRE2022_3',\n",
    " 'aligned_PRE2022_mean',\n",
    " 'aligned_ProfileCurvature',\n",
    " 'aligned_RelativeSlopePosition',\n",
    " 'aligned_savi',\n",
    " 'aligned_SecondMoment',\n",
    " 'aligned_Slope',\n",
    " 'aligned_TMP2022_3',\n",
    " 'aligned_TMP2022_mean',\n",
    " 'aligned_TopographicWetnessIndex',\n",
    " 'aligned_TotalCatchmentArea',\n",
    " 'aligned_ValleyDepth',\n",
    " 'aligned_vari',\n",
    " 'aligned_Variance']\n",
    "\n",
    "# 用户指定的超参数调优范围\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(10, 1000, 10),\n",
    "    'max_depth': [None] + list(np.arange(1, 100)),\n",
    "    'min_samples_split': np.arange(2, 100),\n",
    "    'min_samples_leaf': np.arange(1, 100),\n",
    "}\n",
    "# 逐个训练并导出\n",
    "label_cols_list = ['ph', 'ylzjhl', 'yjz', 'qdan', 'qlin', 'qjia', 'qxi', 'yxlin', 'sxjia', 'jxzc11', 'jxzc12', 'jxzc13', 'jxzc14']\n",
    "# rf模型目录\n",
    "rf_dir = r\"F:\\cache_data\\model_path\\gl\\rfrk\"\n",
    "for col in label_cols_list:\n",
    "    print(col)\n",
    "    # 选取符合条件的数据\n",
    "    # pre_data = df[df[f\"{col}_Status\"]=='Normal']\n",
    "    print(df.shape)\n",
    "    pre_data = df[(df[f\"{col}\"]!=0.0001) & (df[f\"{col}\"]!=0.0002) & (df[f\"{col}_Sta\"]=='Normal')]\n",
    "    print(pre_data.shape)\n",
    "    X = pre_data[feature_cols+coord_cols]\n",
    "    y = pre_data[col]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    # 输出训练集和测试集的形状\n",
    "    print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "    # 模型存放位置,检查是否存在该目录,不存在则创建\n",
    "    temp_dir_path = os.path.join(rf_dir,col)\n",
    "    if not os.path.exists(temp_dir_path):\n",
    "        os.makedirs(temp_dir_path)\n",
    "    # 模型存放路径\n",
    "    save_model_path =os.path.join(temp_dir_path,f\"{col}_rf_model.pkl\") \n",
    "    # 训练模型\n",
    "    train_log = rf_classics(pre_data,col,feature_cols,coord_cols,param_grid,save_model_path)\n",
    "    print(train_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data = pd.read_csv(r\"F:\\float_data\\DY\\marked_data.csv\")\n",
    "print(cl_data.shape)\n",
    "cl_data = cl_data[cl_data['jxzc11'] != 0.0001]\n",
    "print(cl_data.shape)\n",
    "cl_data['jxzc15'] = cl_data['jxzc12']+cl_data['jxzc13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_data['soil_texure'] = cl_data.apply(lambda row: classify_soil_texture(row['jxzc11'], row['jxzc15'], row['jxzc14']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = cl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户选择的标签列和特征列\n",
    "feature_cols = ['jxzc11', 'jxzc12', 'jxzc13', 'jxzc14']\n",
    "# 用户指定的超参数调优范围\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(10, 1000, 10),\n",
    "    'max_depth': [None] + list(np.arange(1, 100)),\n",
    "    'min_samples_split': np.arange(2, 100),\n",
    "    'min_samples_leaf': np.arange(1, 100),\n",
    "}\n",
    "# 逐个训练并导出\n",
    "label_cols_list = ['soil_texure']\n",
    "# rf模型目录\n",
    "rf_dir = r\"F:\\cache_data\\model_path\\dy\\rfrk\"\n",
    "for col in label_cols_list:\n",
    "    print(col)\n",
    "    # 选取符合条件的数据\n",
    "    # pre_data = df[df[f\"{col}_Status\"]=='Normal']\n",
    "    print(df.shape)\n",
    "    pre_data = cl_df[(cl_df[f\"{col}\"]!=0.0001) & (cl_df[f\"{col}\"]!=0.0002)]\n",
    "    print(pre_data.shape)\n",
    "    X = pre_data[feature_cols]\n",
    "    y = pre_data[col]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    # 输出训练集和测试集的形状\n",
    "    print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "    # 模型存放位置,检查是否存在该目录,不存在则创建\n",
    "    temp_dir_path = os.path.join(rf_dir,col)\n",
    "    if not os.path.exists(temp_dir_path):\n",
    "        os.makedirs(temp_dir_path)\n",
    "    # 模型存放路径\n",
    "    save_model_path =os.path.join(temp_dir_path,f\"{col}_rf_model.pkl\") \n",
    "    # 训练模型\n",
    "    train_log = rf_classics_classification(pre_data,col,feature_cols,param_grid,save_model_path)\n",
    "    print(train_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
