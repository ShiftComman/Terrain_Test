{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from sklearn.metrics import r2_score\n",
    "from pyproj import Transformer\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前日期\n",
    "def get_dtime():\n",
    "    # 例如20240516\n",
    "    import datetime\n",
    "    dtime = datetime.datetime.now().strftime('%Y%m%d')\n",
    "    return dtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入autogluon模型\n",
    "model_path = r\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class\"\n",
    "sdt_predictor = TabularPredictor.load(os.path.join(model_path, f\"{'sdt'}_model\"))\n",
    "fzrt_predictor = TabularPredictor.load(os.path.join(model_path, f\"{'fzrt'}_model\"))\n",
    "zrt_predictor = TabularPredictor.load(os.path.join(model_path, f\"{'zrt'}_model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdt_predictor.model_best,sdt_predictor.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzrt_predictor.model_best,fzrt_predictor.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zrt_predictor.model_best,zrt_predictor.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征\n",
    "sdt_feature_names = sdt_predictor.feature_metadata_in.get_features()\n",
    "print(\"SDT\",sdt_feature_names)\n",
    "fzrt_feature_names = fzrt_predictor.feature_metadata_in.get_features()\n",
    "print(\"FZRT\",fzrt_feature_names)\n",
    "zrt_feature_names = zrt_predictor.feature_metadata_in.get_features()\n",
    "print(\"ZRT\",zrt_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存放预测结果的路径\n",
    "result_path =  r\"F:\\cache_data\\zone_ana\\dy\\prediction_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "feature_path = r'F:\\cache_data\\zone_ana\\dy\\prediction_data\\result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv(feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区分数据\n",
    "# 筛选水稻土数据\n",
    "sdt_data = feature_df[feature_df['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选非自然土数据\n",
    "fzrt_data = feature_df[~feature_df['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选自然土数据\n",
    "zrt_data = feature_df[feature_df['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查数据完整性\n",
    "sdt_data.shape,fzrt_data.shape,zrt_data.shape,feature_df.shape,sdt_data.shape[0]+fzrt_data.shape[0]+zrt_data.shape[0]==feature_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取对照字典\n",
    "with open(r'D:\\worker_code\\Terrain_Test\\data\\soil_dict.json', 'r') as f:\n",
    "    soil_dict = json.load(f)\n",
    "# 将键转为int\n",
    "soil_dict = {int(k):v for k, v in soil_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型选择\n",
    "select_model = 'RandomForestEntr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 概率预测函数\n",
    "def predict_top_classes(data, predictor,feature_names, model, top_n, soil_dict):\n",
    "    \"\"\"\n",
    "    根据给定的AutoGluon模型，预测数据集中的前n个最可能的类别及其概率，并根据提供的字典转换类别编号为描述字符串。\n",
    "    参数:\n",
    "    data (DataFrame): 输入的数据集。\n",
    "    predictor（model）: 对应的模型\n",
    "    feature_names (list): 用于预测的特征名列表。\n",
    "    model (str): 选择的模型名称。\n",
    "    top_n (int): 需要返回的最高概率的类别数量。\n",
    "    soil_dict (dict): 类别编号到描述字符串的映射字典。\n",
    "    \n",
    "    返回:\n",
    "    DataFrame: 原始数据与预测结果合并后的DataFrame。\n",
    "    \"\"\"\n",
    "    # 复制数据\n",
    "    data = data.copy()\n",
    "    # 预测概率\n",
    "    pred_probs = predictor.predict_proba(data[feature_names], model=model)\n",
    "    # 获取概率最高的前n个类别及其概率\n",
    "    top_classes = pred_probs.apply(lambda x: pd.Series(x.nlargest(top_n).index.astype(int).tolist() + x.nlargest(top_n).values.tolist()), axis=1)\n",
    "    # 重命名列\n",
    "    class_cols = ['Class{}'.format(i+1) for i in range(top_n)]\n",
    "    prob_cols = ['Prob{}'.format(i+1) for i in range(top_n)]\n",
    "    top_classes.columns = class_cols + prob_cols\n",
    "    # 转换类别编号为描述字符串\n",
    "    for col in class_cols:\n",
    "        top_classes[col] = top_classes[col].map(soil_dict)\n",
    "    # 计算每个预测的熵\n",
    "    entropy = pred_probs.apply(lambda x: -np.sum(x * np.log(x + 1e-9)), axis=1)\n",
    "    top_classes['Entropy'] = entropy\n",
    "    # 计算每个预测的不确定性（标准差）\n",
    "    uncertainty = pred_probs.std(axis=1)\n",
    "    top_classes['Uncertainty'] = uncertainty\n",
    "    # 将新列添加到原有的DataFrame中\n",
    "    return pd.concat([data, top_classes], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDT\n",
    "sdt_result_df = predict_top_classes(sdt_data, sdt_predictor,sdt_feature_names, select_model, 3, soil_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FZRT\n",
    "fzrt_result_df = predict_top_classes(fzrt_data, fzrt_predictor,fzrt_feature_names, select_model, 3, soil_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZRT\n",
    "zrt_result_df = predict_top_classes(zrt_data, zrt_predictor,zrt_feature_names, select_model, 3, soil_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "result_df = pd.concat([sdt_result_df,fzrt_result_df,zrt_result_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取指定列\n",
    "result_df = result_df[['OBJECTID','Class1', 'Class2', 'Class3', 'Prob1','Prob2', 'Prob3', 'Entropy', 'Uncertainty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取三普土种对照字典\n",
    "# 读取Excel文件\n",
    "sp_file_path = r\"C:\\Users\\Runker\\Desktop\\search_dict.xlsx\"\n",
    "df = pd.read_excel(sp_file_path)\n",
    "\n",
    "# 使用前向填充（ffill）处理合并单元格的情况\n",
    "df_filled = df.ffill()\n",
    "# 定义一个函数来为每一行生成一个字典\n",
    "def create_dict(row):\n",
    "    return {\n",
    "        row['三普土种']: {\n",
    "            '土类': row['三普土类'],\n",
    "            '亚类': row['三普亚类'],\n",
    "            '土属': row['三普土属'],\n",
    "        }\n",
    "    }\n",
    "\n",
    "# 使用apply方法为每一行应用这个函数，并将结果合并到一个字典中\n",
    "sp_soiltype_dict = {}\n",
    "for d in df_filled.apply(create_dict, axis=1):\n",
    "    sp_soiltype_dict.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_soiltype_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 apply 方法结合 lambda 函数来获取对应的 '土类' 值\n",
    "result_df['Class1_tl'] = result_df['Class1'].apply(lambda x: sp_soiltype_dict.get(x, {}).get('土类', None))\n",
    "result_df['Class1_yl'] = result_df['Class1'].apply(lambda x: sp_soiltype_dict.get(x, {}).get('亚类', None))\n",
    "result_df['Class1_ts'] = result_df['Class1'].apply(lambda x: sp_soiltype_dict.get(x, {}).get('土属', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "result_df.to_csv(os.path.join(result_path, f'prediction_class_{select_model}_{get_dtime()}.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
