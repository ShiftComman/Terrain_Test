{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor,export_graphviz\n",
    "import graphviz\n",
    "import dtreeviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn import tree\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已存在\n"
     ]
    }
   ],
   "source": [
    "# autogluon保存路径\n",
    "model_path = r\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\"\n",
    "# 检查路径是否存在，否则便创建\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "else:\n",
    "    print(\"文件夹已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"F:\\cache_data\\zone_ana\\dy\\train_data\\train_20240726.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OBJECTID', 'DLMC', '母质', 'TL', 'YL', 'TS', 'TZ', 'XMin', 'YMin',\n",
       "       'XMax',\n",
       "       ...\n",
       "       'DZ_MAX', 'DZ_RANGE', 'DZ_MEAN', 'DZ_STD', 'DZ_SUM', 'DZ_VARIETY',\n",
       "       'DZ_MAJORITY', 'DZ_MINORITY', 'DZ_MEDIAN', 'DZ_PCT90'],\n",
       "      dtype='object', length=433)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rename(columns={'母质': 'MZ'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"TZ_label\"] = dataset.TZ.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['DLMC'] = dataset['DLMC'].astype('category')\n",
    "dataset['MZ'] = dataset['MZ'].astype('category')\n",
    "dataset['TZ_label'] = dataset['TZ_label'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '中层壤质中性紫色土', 1: '中层壤质酸性紫色土', 2: '中层壤质黄色石灰土', 3: '中层泥砂质黄壤', 4: '中层泥质黄壤', 5: '中层灰泥质黄壤', 6: '中层灰泥质黄色石灰土', 7: '中层砂泥质黄壤', 8: '中层砂泥黄壤', 9: '中层砾壤质黑色石灰土', 10: '中层硅质酸性粗骨土', 11: '中层红泥质黄壤', 12: '中层黏质黄色石灰土', 13: '厚层泥质黄壤', 14: '厚层灰泥质黄壤', 15: '厚层砂泥质黄壤', 16: '厚层硅质酸性粗骨土', 17: '厚层红泥质黄壤', 18: '厚层黏质黄色石灰土', 19: '浅石灰泥田', 20: '渗潮泥田', 21: '渗石灰泥田', 22: '潮泥田', 23: '石灰泥田', 24: '紫泥田', 25: '腐中层壤质中性紫色土', 26: '腐中层壤质酸性紫色土', 27: '腐中层壤质黄色石灰土', 28: '腐中层泥砂质黄壤', 29: '腐中层泥质黄壤', 30: '腐中层灰泥质黄壤', 31: '腐中层砂泥质黄壤', 32: '腐中层砂质山地灌丛草甸土', 33: '腐中层砾壤质黑色石灰土', 34: '腐中层硅质酸性粗骨土', 35: '腐中层硅质黄壤', 36: '腐中层红泥质黄壤', 37: '腐中层黏质黄色石灰土', 38: '腐厚层泥质黄壤', 39: '腐厚层灰泥质黄壤', 40: '腐厚层砂泥质黄壤', 41: '腐厚层硅质酸性粗骨土', 42: '腐厚层硅质黄壤', 43: '腐厚层红泥质黄壤', 44: '腐厚层黏质黄色石灰土', 45: '腐薄层壤质酸性紫色土', 46: '腐薄层壤质黄色石灰土', 47: '腐薄层壤质黑色石灰土', 48: '腐薄层泥砂质黄壤', 49: '腐薄层泥质黄壤', 50: '腐薄层灰泥质黄壤', 51: '腐薄层砂泥质黄壤', 52: '腐薄层砂质山地灌丛草甸土', 53: '腐薄层砾泥质黄壤性土', 54: '腐薄层硅质酸性粗骨土', 55: '腐薄层硅质黄壤', 56: '腐薄层硅质黄壤性土', 57: '腐薄层红泥质黄壤', 58: '腐薄层黏质黄色石灰土', 59: '薄层壤质酸性紫色土', 60: '薄层壤质黑色石灰土', 61: '薄层泥质黄壤', 62: '薄层灰泥质黄壤', 63: '薄层灰泥质黄色石灰土', 64: '薄层砂泥质黄壤', 65: '薄层砂泥黄壤', 66: '薄层砾壤质黑色石灰土', 67: '薄层硅质黄壤', 68: '薄层红泥质黄壤', 69: '薄层黏质黄色石灰土', 70: '重漂砂泥田', 71: '青潮泥田', 72: '青石灰泥田', 73: '黄浅灰泥田', 74: '黄浅白粉泥田', 75: '黄浅红泥田', 76: '黄浅鳝泥田', 77: '黄渗灰泥田', 78: '黄渗白粉泥田', 79: '黄渗红泥田', 80: '黄渗鳝泥田', 81: '黄潮泥田', 82: '黄白粉泥田', 83: '黄砂泥田', 84: '黄红泥田', 85: '黄青白粉泥田', 86: '黄青砂泥田', 87: '黄青红泥田', 88: '黄鳝泥田', 89: '黄黄灰泥田'}\n"
     ]
    }
   ],
   "source": [
    "result = dataset.groupby('TZ_label', observed=True)[\"TZ\"].apply(lambda x: list(x.unique())).to_dict()\n",
    "for one_type in result:\n",
    "    result[one_type] = result[one_type][0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存映射关系\n",
    "with open(r'D:\\worker_code\\Terrain_Test\\data\\soil_dict_20240726.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看地类类别\n",
    "dl_df = pd.DataFrame(dataset['DLMC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DLMC</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>乔木林地</th>\n",
       "      <td>10523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>水田</th>\n",
       "      <td>3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>灌木林地</th>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>旱地</th>\n",
       "      <td>1419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他草地</th>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>茶园</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他园地</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他林地</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>果园</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>竹林地</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>裸岩石砾地</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>设施农用地</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>采矿用地</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>裸土地</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "DLMC        \n",
       "乔木林地   10523\n",
       "水田      3563\n",
       "灌木林地    2115\n",
       "旱地      1419\n",
       "其他草地     663\n",
       "茶园       172\n",
       "其他园地      78\n",
       "其他林地      78\n",
       "果园        59\n",
       "竹林地       44\n",
       "裸岩石砾地     11\n",
       "设施农用地      6\n",
       "采矿用地       3\n",
       "裸土地        2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看母质类别\n",
    "mz_df = pd.DataFrame(dataset['MZ'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MZ</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>砂岩</th>\n",
       "      <td>5666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>泥(页)岩</th>\n",
       "      <td>5512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>碳酸岩</th>\n",
       "      <td>4922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>第四系红粘土</th>\n",
       "      <td>1213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>砂页岩</th>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>紫红色砂页岩</th>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>砾岩</th>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>河流冲积物</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>第四纪冰川冲积物</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "MZ             \n",
       "砂岩         5666\n",
       "泥(页)岩      5512\n",
       "碳酸岩        4922\n",
       "第四系红粘土     1213\n",
       "砂页岩         438\n",
       "紫红色砂页岩      409\n",
       "砾岩          276\n",
       "河流冲积物       167\n",
       "第四纪冰川冲积物    133"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂岩土种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['潮泥田', '黄青砂泥田', '黄渗白粉泥田', '黄白粉泥田', '黄浅白粉泥田', '黄鳝泥田', '黄青白粉泥田',\n",
       "       '黄潮泥田'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂岩水稻土数据\n",
    "sy_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & (dataset['MZ'] == '砂岩')]\n",
    "pd.unique(sy_sdt_data['TZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['薄层硅质黄壤', '厚层硅质酸性粗骨土'], dtype=object),\n",
       " array(['硅质黄壤', '硅质酸性粗骨土'], dtype=object))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛砂岩选非自然土数据\n",
    "sy_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & (dataset['MZ'] == '砂岩')]\n",
    "pd.unique(sy_fzrt_data['TZ']),pd.unique(sy_fzrt_data['TS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐厚层硅质黄壤', '腐薄层硅质黄壤', '腐中层砂质山地灌丛草甸土', '腐薄层硅质黄壤性土', '腐薄层砂质山地灌丛草甸土',\n",
       "        '腐中层硅质黄壤', '薄层硅质黄壤'], dtype=object),\n",
       " array(['硅质黄壤', '砂质山地灌丛草甸土', '硅质黄壤性土'], dtype=object))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选自然土数据\n",
    "sy_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '砂岩')]\n",
    "pd.unique(sy_zrt_data['TZ']),pd.unique(sy_zrt_data['TS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 碳酸岩土种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['石灰泥田', '青石灰泥田', '潮泥田', '渗潮泥田', '黄渗灰泥田', '浅石灰泥田', '黄浅灰泥田', '黄黄灰泥田',\n",
       "        '渗石灰泥田'], dtype=object),\n",
       " array(['灰泥田', '青灰泥田', '潮泥田', '渗潮泥田', '渗灰泥田', '浅灰泥田', '黄灰泥田'], dtype=object))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩水稻土数据\n",
    "tsy_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & (dataset['MZ'] == '碳酸岩')]\n",
    "pd.unique(tsy_sdt_data['TZ']),pd.unique(tsy_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['薄层砾壤质黑色石灰土', '中层灰泥质黄色石灰土', '中层灰泥质黄壤', '薄层灰泥质黄色石灰土', '中层砾壤质黑色石灰土',\n",
       "        '中层壤质黄色石灰土', '薄层灰泥质黄壤', '厚层灰泥质黄壤', '薄层壤质黑色石灰土', '中层黏质黄色石灰土'],\n",
       "       dtype=object),\n",
       " array(['壤质黑色石灰土', '灰泥质黄色石灰土', '灰泥质黄壤', '壤质黄色石灰土', '黏质黄色石灰土'], dtype=object))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩选非自然土数据\n",
    "tsy_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & ( dataset['TZ'].str.contains('灰')) & (dataset['MZ'] != '泥(页)岩') &(dataset['MZ'] != '第四系红粘土')]\n",
    "pd.unique(tsy_fzrt_data['TZ']),pd.unique(tsy_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐薄层壤质黄色石灰土', '腐中层壤质黄色石灰土', '腐中层灰泥质黄壤', '腐薄层灰泥质黄壤', '腐薄层壤质黑色石灰土',\n",
       "        '腐厚层灰泥质黄壤', '腐中层砾壤质黑色石灰土'], dtype=object),\n",
       " array(['壤质黄色石灰土', '灰泥质黄壤', '壤质黑色石灰土'], dtype=object))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩自然土数据\n",
    "tsy_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & ( dataset['TZ'].str.contains('灰')) & (dataset['MZ'] != '泥(页)岩') &(dataset['MZ'] != '第四系红粘土')]\n",
    "pd.unique(tsy_zrt_data['TZ']),pd.unique(tsy_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四系红粘土"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄红泥田', '黄渗红泥田', '黄浅红泥田', '潮泥田', '黄青红泥田'], dtype=object),\n",
       " array(['红泥田', '渗红泥田', '浅红泥田', '潮泥田', '青红泥田'], dtype=object))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土水稻土数据\n",
    "hnt_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & (dataset['MZ'] == '第四系红粘土')]\n",
    "pd.unique(hnt_sdt_data['TZ']),pd.unique(hnt_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['薄层黏质黄色石灰土', '中层黏质黄色石灰土', '中层红泥质黄壤', '厚层红泥质黄壤', '厚层黏质黄色石灰土',\n",
       "        '薄层红泥质黄壤'], dtype=object),\n",
       " array(['黏质黄色石灰土', '红泥质黄壤'], dtype=object))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土非自然土数据\n",
    "hnt_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & (dataset['MZ'] == '第四系红粘土')]\n",
    "pd.unique(hnt_fzrt_data['TZ']),pd.unique(hnt_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐厚层红泥质黄壤', '腐中层黏质黄色石灰土', '腐厚层黏质黄色石灰土', '腐中层红泥质黄壤', '腐薄层黏质黄色石灰土',\n",
       "        '腐薄层红泥质黄壤'], dtype=object),\n",
       " array(['红泥质黄壤', '黏质黄色石灰土'], dtype=object))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土自然土数据\n",
    "hnt_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '第四系红粘土')]\n",
    "pd.unique(hnt_zrt_data['TZ']),pd.unique(hnt_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泥(页)岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['潮泥田', '黄浅鳝泥田', '黄鳝泥田', '黄渗鳝泥田'], dtype=object),\n",
       " array(['潮泥田', '浅鳝泥田', '鳝泥田', '渗鳝泥田'], dtype=object))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩水稻土数据\n",
    "nyy_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & (dataset['MZ'] == '泥(页)岩')]\n",
    "pd.unique(nyy_sdt_data['TZ']),pd.unique(nyy_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['薄层泥质黄壤', '厚层泥质黄壤', '中层泥质黄壤', '薄层黏质黄色石灰土'], dtype=object),\n",
       " array(['泥质黄壤', '黏质黄色石灰土'], dtype=object))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩非自然土数据\n",
    "nyy_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & (dataset['MZ'] == '泥(页)岩')]\n",
    "pd.unique(nyy_fzrt_data['TZ']),pd.unique(nyy_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐薄层泥质黄壤', '腐厚层泥质黄壤', '腐薄层黏质黄色石灰土', '腐中层泥质黄壤', '腐中层黏质黄色石灰土',\n",
       "        '腐厚层黏质黄色石灰土', '腐薄层砾泥质黄壤性土'], dtype=object),\n",
       " array(['泥质黄壤', '黏质黄色石灰土'], dtype=object))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩自然土数据\n",
    "nyy_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '泥(页)岩')]\n",
    "pd.unique(nyy_zrt_data['TZ']),pd.unique(nyy_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 紫红色砂页岩\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['潮泥田', '渗潮泥田', '青潮泥田', '紫泥田'], dtype=object),\n",
       " array(['潮泥田', '渗潮泥田', '青潮泥田', '紫泥田'], dtype=object))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩水稻土数据\n",
    "zhsyy_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & ((dataset['MZ'] == '紫红色砂页岩') | (dataset['MZ'] == '河流冲积物'))]\n",
    "pd.unique(zhsyy_sdt_data['TZ']),pd.unique(zhsyy_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层壤质酸性紫色土', '薄层壤质酸性紫色土', '中层壤质中性紫色土'], dtype=object),\n",
       " array(['壤质酸性紫色土', '壤质中性紫色土'], dtype=object))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩非自然土数据\n",
    "zhsyy_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & (dataset['MZ'] == '紫红色砂页岩')]\n",
    "pd.unique(zhsyy_fzrt_data['TZ']),pd.unique(zhsyy_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐薄层壤质酸性紫色土', '腐中层壤质酸性紫色土', '腐中层壤质中性紫色土'], dtype=object),\n",
       " array(['壤质酸性紫色土', '壤质中性紫色土'], dtype=object))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩自然土数据\n",
    "zhsyy_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '紫红色砂页岩')]\n",
    "pd.unique(zhsyy_zrt_data['TZ']),pd.unique(zhsyy_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 河流冲积物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄红泥田', '黄渗红泥田', '黄浅红泥田', '潮泥田', '黄青红泥田', '渗潮泥田', '青潮泥田', '黄浅白粉泥田',\n",
       "        '黄白粉泥田', '黄浅鳝泥田', '黄鳝泥田', '黄渗鳝泥田', '黄青砂泥田', '黄渗白粉泥田', '黄青白粉泥田',\n",
       "        '黄潮泥田', '黄砂泥田', '重漂砂泥田', '石灰泥田', '青石灰泥田', '黄渗灰泥田', '浅石灰泥田',\n",
       "        '黄浅灰泥田', '黄黄灰泥田', '渗石灰泥田', '紫泥田'], dtype=object),\n",
       " array(['红泥田', '渗红泥田', '浅红泥田', '潮泥田', '青红泥田', '渗潮泥田', '青潮泥田', '浅白粉泥田',\n",
       "        '白粉泥田', '浅鳝泥田', '鳝泥田', '渗鳝泥田', '青砂泥田', '渗白粉泥田', '青白粉泥田', '黄潮泥田',\n",
       "        '砂泥田', '漂砂泥田', '灰泥田', '青灰泥田', '渗灰泥田', '浅灰泥田', '黄灰泥田', '紫泥田'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选河流冲积物水稻土数据\n",
    "hlcjw_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂'])]\n",
    "pd.unique(hlcjw_sdt_data['TZ']),pd.unique(hlcjw_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砾岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄浅白粉泥田', '黄白粉泥田', '潮泥田', '黄青砂泥田', '黄渗白粉泥田', '黄鳝泥田', '黄青白粉泥田',\n",
       "        '黄潮泥田'], dtype=object),\n",
       " array(['浅白粉泥田', '白粉泥田', '潮泥田', '青砂泥田', '渗白粉泥田', '鳝泥田', '青白粉泥田', '黄潮泥田'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砾岩水稻土数据\n",
    "ly_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & ((dataset['MZ'] == '砾岩') | (dataset['MZ'] == '砂岩'))]\n",
    "pd.unique(ly_sdt_data['TZ']),pd.unique(ly_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['厚层硅质酸性粗骨土', '中层硅质酸性粗骨土', '薄层硅质黄壤'], dtype=object),\n",
       " array(['硅质酸性粗骨土', '硅质黄壤'], dtype=object))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砾岩非自然土数据\n",
    "ly_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & ((dataset['MZ'] == '砾岩') | (dataset['MZ'] == '砂岩'))]\n",
    "pd.unique(ly_fzrt_data['TZ']),pd.unique(ly_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐厚层硅质酸性粗骨土', '腐厚层硅质黄壤', '腐中层硅质酸性粗骨土', '腐薄层硅质酸性粗骨土', '腐薄层硅质黄壤',\n",
       "        '腐中层砂质山地灌丛草甸土', '腐薄层硅质黄壤性土', '腐薄层砂质山地灌丛草甸土', '腐中层硅质黄壤', '薄层硅质黄壤'],\n",
       "       dtype=object),\n",
       " array(['硅质酸性粗骨土', '硅质黄壤', '砂质山地灌丛草甸土', '硅质黄壤性土'], dtype=object))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砾岩非自然土数据\n",
    "ly_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地']) \n",
    "                       & ((dataset['MZ'] == '砾岩') | (dataset['MZ'] == '砂岩'))]\n",
    "pd.unique(ly_zrt_data['TZ']),pd.unique(ly_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四纪冰川冲积物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄红泥田', '黄渗红泥田', '黄浅红泥田', '潮泥田', '黄青红泥田', '渗潮泥田', '青潮泥田', '黄浅白粉泥田',\n",
       "        '黄白粉泥田', '黄浅鳝泥田', '黄鳝泥田', '黄渗鳝泥田', '黄青砂泥田', '黄渗白粉泥田', '黄青白粉泥田',\n",
       "        '黄潮泥田', '黄砂泥田', '重漂砂泥田', '石灰泥田', '青石灰泥田', '黄渗灰泥田', '浅石灰泥田',\n",
       "        '黄浅灰泥田', '黄黄灰泥田', '渗石灰泥田', '紫泥田'], dtype=object),\n",
       " array(['红泥田', '渗红泥田', '浅红泥田', '潮泥田', '青红泥田', '渗潮泥田', '青潮泥田', '浅白粉泥田',\n",
       "        '白粉泥田', '浅鳝泥田', '鳝泥田', '渗鳝泥田', '青砂泥田', '渗白粉泥田', '青白粉泥田', '黄潮泥田',\n",
       "        '砂泥田', '漂砂泥田', '灰泥田', '青灰泥田', '渗灰泥田', '浅灰泥田', '黄灰泥田', '紫泥田'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四纪冰川冲积物水稻土数据\n",
    "bccjw_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                     ]\n",
    "pd.unique(bccjw_sdt_data['TZ']),pd.unique(bccjw_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层泥砂质黄壤', '薄层硅质黄壤', '厚层硅质酸性粗骨土'], dtype=object),\n",
       " array(['泥砂质黄壤', '硅质黄壤', '硅质酸性粗骨土'], dtype=object))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四纪冰川冲积物非自然土数据\n",
    "bccjw_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & ((dataset['MZ'] == '第四纪冰川冲积物') | (dataset['MZ'] == '砂岩'))]\n",
    "pd.unique(bccjw_fzrt_data['TZ']),pd.unique(bccjw_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层泥砂质黄壤', '腐薄层泥砂质黄壤'], dtype=object), array(['泥砂质黄壤'], dtype=object))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四纪冰川冲积物自然土数据\n",
    "bccjw_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '第四纪冰川冲积物')]\n",
    "pd.unique(bccjw_zrt_data['TZ']),pd.unique(bccjw_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂页岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄砂泥田', '重漂砂泥田'], dtype=object), array(['砂泥田', '漂砂泥田'], dtype=object))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩水稻土数据\n",
    "syy_sdt_data = dataset[dataset['DLMC'].isin(['水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                      & (dataset['MZ'] == '砂页岩')]\n",
    "pd.unique(syy_sdt_data['TZ']),pd.unique(syy_sdt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层砂泥质黄壤', '薄层砂泥质黄壤', '中层砂泥黄壤', '薄层砂泥黄壤', '厚层砂泥质黄壤'], dtype=object),\n",
       " array(['砂泥质黄壤', '砂泥黄壤'], dtype=object))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩非自然土数据\n",
    "syy_fzrt_data = dataset[~dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地','水田','水浇地','坑塘水面','养殖坑塘','内陆滩涂']) \n",
    "                       & (dataset['MZ'] == '砂页岩')]\n",
    "pd.unique(syy_fzrt_data['TZ']),pd.unique(syy_fzrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层砂泥质黄壤', '腐薄层砂泥质黄壤', '腐厚层砂泥质黄壤'], dtype=object),\n",
       " array(['砂泥质黄壤'], dtype=object))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩物自然土数据\n",
    "syy_zrt_data = dataset[dataset['DLMC'].isin(['乔木林地','灌木林地','竹林地','其他林地','其他草地','天然牧草地','人工牧草地'])\n",
    "                   & (dataset['MZ'] == '砂页岩')]\n",
    "pd.unique(syy_zrt_data['TZ']),pd.unique(syy_zrt_data['TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "DLMC\n",
      "MZ\n",
      "TL\n",
      "YL\n",
      "TS\n",
      "TZ\n",
      "XMin\n",
      "YMin\n",
      "XMax\n",
      "YMax\n",
      "Centroid_X\n",
      "Centroid_Y\n",
      "DEM_COUNT\n",
      "DEM_AREA\n",
      "DEM_MIN\n",
      "DEM_MAX\n",
      "DEM_RANGE\n",
      "DEM_MEAN\n",
      "DEM_STD\n",
      "DEM_SUM\n",
      "DEM_MEDIAN\n",
      "DEM_PCT90\n",
      "AnalyticalHillshading_COUNT\n",
      "AnalyticalHillshading_AREA\n",
      "AnalyticalHillshading_MIN\n",
      "AnalyticalHillshading_MAX\n",
      "AnalyticalHillshading_RANGE\n",
      "AnalyticalHillshading_MEAN\n",
      "AnalyticalHillshading_STD\n",
      "AnalyticalHillshading_SUM\n",
      "AnalyticalHillshading_MEDIAN\n",
      "AnalyticalHillshading_PCT90\n",
      "Aspect_COUNT\n",
      "Aspect_AREA\n",
      "Aspect_MIN\n",
      "Aspect_MAX\n",
      "Aspect_RANGE\n",
      "Aspect_MEAN\n",
      "Aspect_STD\n",
      "Aspect_SUM\n",
      "Aspect_MEDIAN\n",
      "Aspect_PCT90\n",
      "ChannelNetworkBaseLevel_COUNT\n",
      "ChannelNetworkBaseLevel_AREA\n",
      "ChannelNetworkBaseLevel_MIN\n",
      "ChannelNetworkBaseLevel_MAX\n",
      "ChannelNetworkBaseLevel_RANGE\n",
      "ChannelNetworkBaseLevel_MEAN\n",
      "ChannelNetworkBaseLevel_STD\n",
      "ChannelNetworkBaseLevel_SUM\n",
      "ChannelNetworkBaseLevel_MEDIAN\n",
      "ChannelNetworkBaseLevel_PCT90\n",
      "ChannelNetworkDistance_COUNT\n",
      "ChannelNetworkDistance_AREA\n",
      "ChannelNetworkDistance_MIN\n",
      "ChannelNetworkDistance_MAX\n",
      "ChannelNetworkDistance_RANGE\n",
      "ChannelNetworkDistance_MEAN\n",
      "ChannelNetworkDistance_STD\n",
      "ChannelNetworkDistance_SUM\n",
      "ChannelNetworkDistance_MEDIAN\n",
      "ChannelNetworkDistance_PCT90\n",
      "ClosedDepressions_COUNT\n",
      "ClosedDepressions_AREA\n",
      "ClosedDepressions_MIN\n",
      "ClosedDepressions_MAX\n",
      "ClosedDepressions_RANGE\n",
      "ClosedDepressions_MEAN\n",
      "ClosedDepressions_STD\n",
      "ClosedDepressions_SUM\n",
      "ClosedDepressions_MEDIAN\n",
      "ClosedDepressions_PCT90\n",
      "ConvergenceIndex_COUNT\n",
      "ConvergenceIndex_AREA\n",
      "ConvergenceIndex_MIN\n",
      "ConvergenceIndex_MAX\n",
      "ConvergenceIndex_RANGE\n",
      "ConvergenceIndex_MEAN\n",
      "ConvergenceIndex_STD\n",
      "ConvergenceIndex_SUM\n",
      "ConvergenceIndex_MEDIAN\n",
      "ConvergenceIndex_PCT90\n",
      "LSFactor_COUNT\n",
      "LSFactor_AREA\n",
      "LSFactor_MIN\n",
      "LSFactor_MAX\n",
      "LSFactor_RANGE\n",
      "LSFactor_MEAN\n",
      "LSFactor_STD\n",
      "LSFactor_SUM\n",
      "LSFactor_MEDIAN\n",
      "LSFactor_PCT90\n",
      "MRRTF_COUNT\n",
      "MRRTF_AREA\n",
      "MRRTF_MIN\n",
      "MRRTF_MAX\n",
      "MRRTF_RANGE\n",
      "MRRTF_MEAN\n",
      "MRRTF_STD\n",
      "MRRTF_SUM\n",
      "MRRTF_MEDIAN\n",
      "MRRTF_PCT90\n",
      "MRVBF_COUNT\n",
      "MRVBF_AREA\n",
      "MRVBF_MIN\n",
      "MRVBF_MAX\n",
      "MRVBF_RANGE\n",
      "MRVBF_MEAN\n",
      "MRVBF_STD\n",
      "MRVBF_SUM\n",
      "MRVBF_MEDIAN\n",
      "MRVBF_PCT90\n",
      "PlanCurvature_COUNT\n",
      "PlanCurvature_AREA\n",
      "PlanCurvature_MIN\n",
      "PlanCurvature_MAX\n",
      "PlanCurvature_RANGE\n",
      "PlanCurvature_MEAN\n",
      "PlanCurvature_STD\n",
      "PlanCurvature_SUM\n",
      "PlanCurvature_MEDIAN\n",
      "PlanCurvature_PCT90\n",
      "ProfileCurvature_COUNT\n",
      "ProfileCurvature_AREA\n",
      "ProfileCurvature_MIN\n",
      "ProfileCurvature_MAX\n",
      "ProfileCurvature_RANGE\n",
      "ProfileCurvature_MEAN\n",
      "ProfileCurvature_STD\n",
      "ProfileCurvature_SUM\n",
      "ProfileCurvature_MEDIAN\n",
      "ProfileCurvature_PCT90\n",
      "RelativeSlopePosition_COUNT\n",
      "RelativeSlopePosition_AREA\n",
      "RelativeSlopePosition_MIN\n",
      "RelativeSlopePosition_MAX\n",
      "RelativeSlopePosition_RANGE\n",
      "RelativeSlopePosition_MEAN\n",
      "RelativeSlopePosition_STD\n",
      "RelativeSlopePosition_SUM\n",
      "RelativeSlopePosition_MEDIAN\n",
      "RelativeSlopePosition_PCT90\n",
      "Slope_COUNT\n",
      "Slope_AREA\n",
      "Slope_MIN\n",
      "Slope_MAX\n",
      "Slope_RANGE\n",
      "Slope_MEAN\n",
      "Slope_STD\n",
      "Slope_SUM\n",
      "Slope_MEDIAN\n",
      "Slope_PCT90\n",
      "TopographicWetnessIndex_COUNT\n",
      "TopographicWetnessIndex_AREA\n",
      "TopographicWetnessIndex_MIN\n",
      "TopographicWetnessIndex_MAX\n",
      "TopographicWetnessIndex_RANGE\n",
      "TopographicWetnessIndex_MEAN\n",
      "TopographicWetnessIndex_STD\n",
      "TopographicWetnessIndex_SUM\n",
      "TopographicWetnessIndex_MEDIAN\n",
      "TopographicWetnessIndex_PCT90\n",
      "TotalCatchmentArea_COUNT\n",
      "TotalCatchmentArea_AREA\n",
      "TotalCatchmentArea_MIN\n",
      "TotalCatchmentArea_MAX\n",
      "TotalCatchmentArea_RANGE\n",
      "TotalCatchmentArea_MEAN\n",
      "TotalCatchmentArea_STD\n",
      "TotalCatchmentArea_SUM\n",
      "TotalCatchmentArea_MEDIAN\n",
      "TotalCatchmentArea_PCT90\n",
      "ValleyDepth_COUNT\n",
      "ValleyDepth_AREA\n",
      "ValleyDepth_MIN\n",
      "ValleyDepth_MAX\n",
      "ValleyDepth_RANGE\n",
      "ValleyDepth_MEAN\n",
      "ValleyDepth_STD\n",
      "ValleyDepth_SUM\n",
      "ValleyDepth_MEDIAN\n",
      "ValleyDepth_PCT90\n",
      "NIGHT2022_COUNT\n",
      "NIGHT2022_AREA\n",
      "NIGHT2022_MIN\n",
      "NIGHT2022_MAX\n",
      "NIGHT2022_RANGE\n",
      "NIGHT2022_MEAN\n",
      "NIGHT2022_STD\n",
      "NIGHT2022_SUM\n",
      "NIGHT2022_MEDIAN\n",
      "NIGHT2022_PCT90\n",
      "ETP2022_mean_COUNT\n",
      "ETP2022_mean_AREA\n",
      "ETP2022_mean_MIN\n",
      "ETP2022_mean_MAX\n",
      "ETP2022_mean_RANGE\n",
      "ETP2022_mean_MEAN\n",
      "ETP2022_mean_STD\n",
      "ETP2022_mean_SUM\n",
      "ETP2022_mean_MEDIAN\n",
      "ETP2022_mean_PCT90\n",
      "TMP2022_mean_COUNT\n",
      "TMP2022_mean_AREA\n",
      "TMP2022_mean_MIN\n",
      "TMP2022_mean_MAX\n",
      "TMP2022_mean_RANGE\n",
      "TMP2022_mean_MEAN\n",
      "TMP2022_mean_STD\n",
      "TMP2022_mean_SUM\n",
      "TMP2022_mean_MEDIAN\n",
      "TMP2022_mean_PCT90\n",
      "PRE2022_mean_COUNT\n",
      "PRE2022_mean_AREA\n",
      "PRE2022_mean_MIN\n",
      "PRE2022_mean_MAX\n",
      "PRE2022_mean_RANGE\n",
      "PRE2022_mean_MEAN\n",
      "PRE2022_mean_STD\n",
      "PRE2022_mean_SUM\n",
      "PRE2022_mean_MEDIAN\n",
      "PRE2022_mean_PCT90\n",
      "PRE2022_3_MAX\n",
      "PRE2022_3_RANGE\n",
      "PRE2022_3_MEAN\n",
      "PRE2022_3_STD\n",
      "PRE2022_3_SUM\n",
      "PRE2022_3_VARIETY\n",
      "PRE2022_3_MAJORITY\n",
      "PRE2022_3_MINORITY\n",
      "PRE2022_3_MEDIAN\n",
      "PRE2022_3_PCT90\n",
      "PRE2022_11_MAX\n",
      "PRE2022_11_RANGE\n",
      "PRE2022_11_MEAN\n",
      "PRE2022_11_STD\n",
      "PRE2022_11_SUM\n",
      "PRE2022_11_VARIETY\n",
      "PRE2022_11_MAJORITY\n",
      "PRE2022_11_MINORITY\n",
      "PRE2022_11_MEDIAN\n",
      "PRE2022_11_PCT90\n",
      "ETP2022_3_MAX\n",
      "ETP2022_3_RANGE\n",
      "ETP2022_3_MEAN\n",
      "ETP2022_3_STD\n",
      "ETP2022_3_SUM\n",
      "ETP2022_3_VARIETY\n",
      "ETP2022_3_MAJORITY\n",
      "ETP2022_3_MINORITY\n",
      "ETP2022_3_MEDIAN\n",
      "ETP2022_3_PCT90\n",
      "ETP2022_11_MAX\n",
      "ETP2022_11_RANGE\n",
      "ETP2022_11_MEAN\n",
      "ETP2022_11_STD\n",
      "ETP2022_11_SUM\n",
      "ETP2022_11_VARIETY\n",
      "ETP2022_11_MAJORITY\n",
      "ETP2022_11_MINORITY\n",
      "ETP2022_11_MEDIAN\n",
      "ETP2022_11_PCT90\n",
      "TMP2022_3_MAX\n",
      "TMP2022_3_RANGE\n",
      "TMP2022_3_MEAN\n",
      "TMP2022_3_STD\n",
      "TMP2022_3_SUM\n",
      "TMP2022_3_VARIETY\n",
      "TMP2022_3_MAJORITY\n",
      "TMP2022_3_MINORITY\n",
      "TMP2022_3_MEDIAN\n",
      "TMP2022_3_PCT90\n",
      "TMP2022_11_MAX\n",
      "TMP2022_11_RANGE\n",
      "TMP2022_11_MEAN\n",
      "TMP2022_11_STD\n",
      "TMP2022_11_SUM\n",
      "TMP2022_11_VARIETY\n",
      "TMP2022_11_MAJORITY\n",
      "TMP2022_11_MINORITY\n",
      "TMP2022_11_MEDIAN\n",
      "TMP2022_11_PCT90\n",
      "evi_COUNT\n",
      "evi_AREA\n",
      "evi_MIN\n",
      "evi_MAX\n",
      "evi_RANGE\n",
      "evi_MEAN\n",
      "evi_STD\n",
      "evi_SUM\n",
      "evi_MEDIAN\n",
      "evi_PCT90\n",
      "lswi_COUNT\n",
      "lswi_AREA\n",
      "lswi_MIN\n",
      "lswi_MAX\n",
      "lswi_RANGE\n",
      "lswi_MEAN\n",
      "lswi_STD\n",
      "lswi_SUM\n",
      "lswi_MEDIAN\n",
      "lswi_PCT90\n",
      "mndwi_COUNT\n",
      "mndwi_AREA\n",
      "mndwi_MIN\n",
      "mndwi_MAX\n",
      "mndwi_RANGE\n",
      "mndwi_MEAN\n",
      "mndwi_STD\n",
      "mndwi_SUM\n",
      "mndwi_MEDIAN\n",
      "mndwi_PCT90\n",
      "ndmi_COUNT\n",
      "ndmi_AREA\n",
      "ndmi_MIN\n",
      "ndmi_MAX\n",
      "ndmi_RANGE\n",
      "ndmi_MEAN\n",
      "ndmi_STD\n",
      "ndmi_SUM\n",
      "ndmi_MEDIAN\n",
      "ndmi_PCT90\n",
      "ndvi_COUNT\n",
      "ndvi_AREA\n",
      "ndvi_MIN\n",
      "ndvi_MAX\n",
      "ndvi_RANGE\n",
      "ndvi_MEAN\n",
      "ndvi_STD\n",
      "ndvi_SUM\n",
      "ndvi_MEDIAN\n",
      "ndvi_PCT90\n",
      "ndwi_COUNT\n",
      "ndwi_AREA\n",
      "ndwi_MIN\n",
      "ndwi_MAX\n",
      "ndwi_RANGE\n",
      "ndwi_MEAN\n",
      "ndwi_STD\n",
      "ndwi_SUM\n",
      "ndwi_MEDIAN\n",
      "ndwi_PCT90\n",
      "PCA_0_COUNT\n",
      "PCA_0_AREA\n",
      "PCA_0_MIN\n",
      "PCA_0_MAX\n",
      "PCA_0_RANGE\n",
      "PCA_0_MEAN\n",
      "PCA_0_STD\n",
      "PCA_0_SUM\n",
      "PCA_0_MEDIAN\n",
      "PCA_0_PCT90\n",
      "PCA_1_COUNT\n",
      "PCA_1_AREA\n",
      "PCA_1_MIN\n",
      "PCA_1_MAX\n",
      "PCA_1_RANGE\n",
      "PCA_1_MEAN\n",
      "PCA_1_STD\n",
      "PCA_1_SUM\n",
      "PCA_1_MEDIAN\n",
      "PCA_1_PCT90\n",
      "savi_COUNT\n",
      "savi_AREA\n",
      "savi_MIN\n",
      "savi_MAX\n",
      "savi_RANGE\n",
      "savi_MEAN\n",
      "savi_STD\n",
      "savi_SUM\n",
      "savi_MEDIAN\n",
      "savi_PCT90\n",
      "vari_COUNT\n",
      "vari_AREA\n",
      "vari_MIN\n",
      "vari_MAX\n",
      "vari_RANGE\n",
      "vari_MEAN\n",
      "vari_STD\n",
      "vari_SUM\n",
      "vari_MEDIAN\n",
      "vari_PCT90\n",
      "DL_MAX\n",
      "DL_RANGE\n",
      "DL_MEAN\n",
      "DL_STD\n",
      "DL_SUM\n",
      "DL_VARIETY\n",
      "DL_MAJORITY\n",
      "DL_MINORITY\n",
      "DL_MEDIAN\n",
      "DL_PCT90\n",
      "LON_COUNT\n",
      "LON_AREA\n",
      "LON_MIN\n",
      "LON_MAX\n",
      "LON_RANGE\n",
      "LON_MEAN\n",
      "LON_STD\n",
      "LON_SUM\n",
      "LON_MEDIAN\n",
      "LON_PCT90\n",
      "LAT_COUNT\n",
      "LAT_AREA\n",
      "LAT_MIN\n",
      "LAT_MAX\n",
      "LAT_RANGE\n",
      "LAT_MEAN\n",
      "LAT_STD\n",
      "LAT_SUM\n",
      "LAT_MEDIAN\n",
      "LAT_PCT90\n",
      "SlopeClass_MAX\n",
      "SlopeClass_RANGE\n",
      "SlopeClass_MEAN\n",
      "SlopeClass_STD\n",
      "SlopeClass_SUM\n",
      "SlopeClass_VARIETY\n",
      "SlopeClass_MAJORITY\n",
      "SlopeClass_MINORITY\n",
      "SlopeClass_MEDIAN\n",
      "SlopeClass_PCT90\n",
      "DZ_MAX\n",
      "DZ_RANGE\n",
      "DZ_MEAN\n",
      "DZ_STD\n",
      "DZ_SUM\n",
      "DZ_VARIETY\n",
      "DZ_MAJORITY\n",
      "DZ_MINORITY\n",
      "DZ_MEDIAN\n",
      "DZ_PCT90\n",
      "TZ_label\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "['DEM_COUNT', 'DEM_AREA', 'DEM_MIN', 'DEM_MAX', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', 'DEM_SUM', 'DEM_MEDIAN', 'DEM_PCT90', 'Aspect_COUNT', 'Aspect_AREA', 'Aspect_MIN', 'Aspect_MAX', 'Aspect_RANGE', 'Aspect_MEAN', 'Aspect_STD', 'Aspect_SUM', 'Aspect_MEDIAN', 'Aspect_PCT90', 'PlanCurvature_COUNT', 'PlanCurvature_AREA', 'PlanCurvature_MIN', 'PlanCurvature_MAX', 'PlanCurvature_RANGE', 'PlanCurvature_MEAN', 'PlanCurvature_STD', 'PlanCurvature_SUM', 'PlanCurvature_MEDIAN', 'PlanCurvature_PCT90', 'RelativeSlopePosition_COUNT', 'RelativeSlopePosition_AREA', 'RelativeSlopePosition_MIN', 'RelativeSlopePosition_MAX', 'RelativeSlopePosition_RANGE', 'RelativeSlopePosition_MEAN', 'RelativeSlopePosition_STD', 'RelativeSlopePosition_SUM', 'RelativeSlopePosition_MEDIAN', 'RelativeSlopePosition_PCT90', 'Slope_COUNT', 'Slope_AREA', 'Slope_MIN', 'Slope_MAX', 'Slope_RANGE', 'Slope_MEAN', 'Slope_STD', 'Slope_SUM', 'Slope_MEDIAN', 'Slope_PCT90', 'TopographicWetnessIndex_COUNT', 'TopographicWetnessIndex_AREA', 'TopographicWetnessIndex_MIN', 'TopographicWetnessIndex_MAX', 'TopographicWetnessIndex_RANGE', 'TopographicWetnessIndex_MEAN', 'TopographicWetnessIndex_STD', 'TopographicWetnessIndex_SUM', 'TopographicWetnessIndex_MEDIAN', 'TopographicWetnessIndex_PCT90', 'Mean_COUNT', 'Mean_AREA', 'Mean_MIN', 'Mean_MAX', 'Mean_RANGE', 'Mean_MEAN', 'Mean_STD', 'Mean_SUM', 'Mean_MEDIAN', 'Mean_PCT90', 'ndvi_COUNT', 'ndvi_AREA', 'ndvi_MIN', 'ndvi_MAX', 'ndvi_RANGE', 'ndvi_MEAN', 'ndvi_STD', 'ndvi_SUM', 'ndvi_MEDIAN', 'ndvi_PCT90', 'PCA_0_COUNT', 'PCA_0_AREA', 'PCA_0_MIN', 'PCA_0_MAX', 'PCA_0_RANGE', 'PCA_0_MEAN', 'PCA_0_STD', 'PCA_0_SUM', 'PCA_0_MEDIAN', 'PCA_0_PCT90', 'PRE_COUNT', 'PRE_AREA', 'PRE_MIN', 'PRE_MAX', 'PRE_RANGE', 'PRE_MEAN', 'PRE_STD', 'PRE_SUM', 'PRE_MEDIAN', 'PRE_PCT90', 'SRA_COUNT', 'SRA_AREA', 'SRA_MIN', 'SRA_MAX', 'SRA_RANGE', 'SRA_MEAN', 'SRA_STD', 'SRA_SUM', 'SRA_MEDIAN', 'SRA_PCT90', 'TMP_COUNT', 'TMP_AREA', 'TMP_MIN', 'TMP_MAX', 'TMP_RANGE', 'TMP_MEAN', 'TMP_STD', 'TMP_SUM', 'TMP_MEDIAN', 'TMP_PCT90', 'VAP_COUNT', 'VAP_AREA', 'VAP_MIN', 'VAP_MAX', 'VAP_RANGE', 'VAP_MEAN', 'VAP_STD', 'VAP_SUM', 'VAP_MEDIAN', 'VAP_PCT90', 'WIND_COUNT', 'WIND_AREA', 'WIND_MIN', 'WIND_MAX', 'WIND_RANGE', 'WIND_MEAN', 'WIND_STD', 'WIND_SUM', 'WIND_MEDIAN', 'WIND_PCT90', 'PH_COUNT', 'PH_AREA', 'PH_MIN', 'PH_MAX', 'PH_RANGE', 'PH_MEAN', 'PH_STD', 'PH_SUM', 'PH_MEDIAN', 'PH_PCT90', 'MRVBF_COUNT', 'MRVBF_AREA', 'MRVBF_MIN', 'MRVBF_MAX', 'MRVBF_RANGE', 'MRVBF_MEAN', 'MRVBF_STD', 'MRVBF_SUM', 'MRVBF_MEDIAN', 'MRVBF_PCT90']\n"
     ]
    }
   ],
   "source": [
    "# 定义要检查的关键字列表\n",
    "keywords = ['DEM','ndvi', 'PCA_0', 'Slope','Aspect', 'MRVBF','TopographicWetnessIndex', 'Mean',  'PH','PRE','SRA','TMP','VAP','WIND','PlanCurvature']\n",
    "\n",
    "# 定义包含字符串的列表\n",
    "strings = list(dataset.columns)\n",
    "\n",
    "# 使用列表推导式和any函数检查并添加到新列表\n",
    "filtered_strings = [s for s in strings if any(keyword in s for keyword in keywords)]\n",
    "print(len(filtered_strings))\n",
    "print(filtered_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdt_features= ['DLMC','MZ','Centroid_X','Centroid_Y',\n",
    "           'DEM_MAX','DEM_MIN','DEM_MEAN','DEM_RANGE','DEM_STD',\n",
    "           'ndvi_MEAN',\n",
    "           'PCA_0_MEAN',\n",
    "           'Slope_MAX', 'Slope_MIN','Slope_MEAN','Slope_RANGE',\n",
    "           'Aspect_MEAN',\n",
    "           'MRVBF_MAX','MRVBF_MIN','MRVBF_MEAN','MRVBF_RANGE',\n",
    "           'TopographicWetnessIndex_MEAN','TopographicWetnessIndex_RANGE',\n",
    "           'Mean_MEAN',\n",
    "           'PH_MEAN',\n",
    "           'PRE_MEAN','PRE_RANGE',\n",
    "           'SRA_MEAN','SRA_RANGE',\n",
    "           'TMP_MEAN','TMP_RANGE',\n",
    "           'VAP_MEAN','VAP_RANGE',\n",
    "           'WIND_MEAN','WIND_RANGE',\n",
    "           'PlanCurvature_MEAN','PlanCurvature_RANGE'\n",
    "         ]\n",
    "fzrt_features = ['DLMC','MZ','Centroid_X','Centroid_Y',\n",
    "           'DEM_MAX','DEM_MIN','DEM_MEAN','DEM_RANGE','DEM_STD',\n",
    "           'ndvi_MEAN',\n",
    "           'PCA_0_MEAN',\n",
    "           'Slope_MAX', 'Slope_MIN','Slope_MEAN','Slope_RANGE',\n",
    "           'Aspect_MEAN',\n",
    "           'MRVBF_MAX','MRVBF_MIN','MRVBF_MEAN','MRVBF_RANGE',\n",
    "           'TopographicWetnessIndex_MEAN','TopographicWetnessIndex_RANGE',\n",
    "           'Mean_MEAN',\n",
    "           'PH_MEAN',\n",
    "           'PRE_MEAN','PRE_RANGE',\n",
    "           'SRA_MEAN','SRA_RANGE',\n",
    "           'TMP_MEAN','TMP_RANGE',\n",
    "           'VAP_MEAN','VAP_RANGE',\n",
    "           'WIND_MEAN','WIND_RANGE',\n",
    "           'PlanCurvature_MEAN','PlanCurvature_RANGE'\n",
    "         ]\n",
    "zrt_features = ['DLMC','MZ','Centroid_X','Centroid_Y',\n",
    "           'DEM_MAX','DEM_MIN','DEM_MEAN','DEM_RANGE','DEM_STD',\n",
    "           'ndvi_MEAN',\n",
    "           'PCA_0_MEAN',\n",
    "           'Slope_MAX', 'Slope_MIN','Slope_MEAN','Slope_RANGE',\n",
    "           'Aspect_MEAN',\n",
    "           'MRVBF_MAX','MRVBF_MIN','MRVBF_MEAN','MRVBF_RANGE',\n",
    "           'TopographicWetnessIndex_MEAN','TopographicWetnessIndex_RANGE',\n",
    "           'Mean_MEAN',\n",
    "           'PH_MEAN',\n",
    "           'PRE_MEAN','PRE_RANGE',\n",
    "           'SRA_MEAN','SRA_RANGE',\n",
    "           'TMP_MEAN','TMP_RANGE',\n",
    "           'VAP_MEAN','VAP_RANGE',\n",
    "           'WIND_MEAN','WIND_RANGE',\n",
    "           'PlanCurvature_MEAN','PlanCurvature_RANGE'\n",
    "         ]\n",
    "target = \"TZ_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\n",
    "    \"Centroid_X\",\n",
    "    \"Centroid_Y\",\n",
    "    \"DEM_RANGE\",\n",
    "    \"DEM_MEAN\",\n",
    "    \"DEM_STD\",\n",
    "    \"AnalyticalHillshading_MEAN\",\n",
    "    \"Aspect_MEAN\",\n",
    "    \"ChannelNetworkBaseLevel_MEAN\",\n",
    "    \"ChannelNetworkDistance_MEAN\",\n",
    "    \"ConvergenceIndex_MEAN\",\n",
    "    \"LSFactor_MEAN\",\n",
    "    \"MRRTF_MEAN\",\n",
    "    \"MRVBF_MEAN\",\n",
    "    \"PlanCurvature_MEAN\",\n",
    "    \"ProfileCurvature_MEAN\",\n",
    "    \"RelativeSlopePosition_MEAN\",\n",
    "    \"Slope_MEAN\",\n",
    "    \"TopographicWetnessIndex_MEAN\",\n",
    "    \"TotalCatchmentArea_MEAN\",\n",
    "    \"ValleyDepth_MEAN\",\n",
    "    \"NIGHT2022_MEAN\",\n",
    "    \"ETP2022_mean_MEAN\",\n",
    "    \"TMP2022_mean_MEAN\",\n",
    "    \"PRE2022_mean_MEAN\",\n",
    "    \"PRE2022_3_MEAN\",\n",
    "    \"PRE2022_11_MEAN\",\n",
    "    \"ETP2022_3_MEAN\",\n",
    "    \"ETP2022_11_MEAN\",\n",
    "    \"TMP2022_3_MEAN\",\n",
    "    \"TMP2022_11_MEAN\",\n",
    "    \"evi_MEAN\",\n",
    "    \"lswi_MEAN\",\n",
    "    \"mndwi_MEAN\",\n",
    "    \"ndmi_MEAN\",\n",
    "    \"ndvi_MEAN\",\n",
    "    \"ndwi_MEAN\",\n",
    "    \"PCA_0_MEAN\",\n",
    "    \"PCA_1_MEAN\",\n",
    "    \"savi_MEAN\",\n",
    "    \"vari_MEAN\",\n",
    "    \"DL_MAJORITY\",\n",
    "    \"SlopeClass_MAJORITY\",\n",
    "    \"DZ_MAJORITY\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdt_features= ['DLMC','MZ']+ terms\n",
    "fzrt_features = ['DLMC','MZ']+ terms\n",
    "zrt_features = ['DLMC','MZ']+ terms\n",
    "target = \"TZ_label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "sy_sdt_data = sy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "sy_fzrt_data = sy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "sy_zrt_data = sy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 碳酸岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "tsy_sdt_data = tsy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "tsy_fzrt_data = tsy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "tsy_zrt_data = tsy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四系红粘土数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "hnt_sdt_data = hnt_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "hnt_fzrt_data = hnt_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "hnt_zrt_data = hnt_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泥(页)岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "nyy_sdt_data = nyy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "nyy_fzrt_data = nyy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "nyy_zrt_data = nyy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 紫红色砂页岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "zhsyy_sdt_data = zhsyy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "zhsyy_fzrt_data = zhsyy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "zhsyy_zrt_data = zhsyy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 河流冲积物数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "hlcjw_sdt_data = hlcjw_sdt_data[sdt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砾岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "ly_sdt_data = ly_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "ly_fzrt_data = ly_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "ly_zrt_data = ly_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四纪冰川冲积物数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "bccjw_sdt_data = bccjw_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "bccjw_fzrt_data = bccjw_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "bccjw_zrt_data = bccjw_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂页岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "syy_sdt_data = syy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "syy_fzrt_data = syy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "syy_zrt_data = syy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "砂岩 (2494, 46) (68, 46) (3104, 46)\n",
      "碳酸岩 (310, 46) (763, 46) (3849, 46)\n",
      "第四系红粘土 (379, 46) (205, 46) (629, 46)\n",
      "泥页岩 (100, 46) (160, 46) (5252, 46)\n",
      "紫红色砂页岩 (195, 46) (146, 46) (235, 46)\n",
      "河流冲积物 (3563, 46)\n",
      "砾岩 (2553, 46) (112, 46) (3277, 46)\n",
      "第四纪冰川冲积物 (3563, 46) (100, 46) (101, 46)\n",
      "砂页岩 (26, 46) (332, 46) (80, 46)\n"
     ]
    }
   ],
   "source": [
    "# 查看各个数据集的大小\n",
    "print('砂岩',sy_sdt_data.shape,sy_fzrt_data.shape,sy_zrt_data.shape)\n",
    "print('碳酸岩',tsy_sdt_data.shape,tsy_fzrt_data.shape,tsy_zrt_data.shape)\n",
    "print('第四系红粘土',hnt_sdt_data.shape,hnt_fzrt_data.shape,hnt_zrt_data.shape)\n",
    "print('泥页岩',nyy_sdt_data.shape,nyy_fzrt_data.shape,nyy_zrt_data.shape)\n",
    "print('紫红色砂页岩',zhsyy_sdt_data.shape,zhsyy_fzrt_data.shape,zhsyy_zrt_data.shape)\n",
    "print('河流冲积物',hlcjw_sdt_data.shape)\n",
    "print('砾岩',ly_sdt_data.shape,ly_fzrt_data.shape,ly_zrt_data.shape)\n",
    "print('第四纪冰川冲积物',bccjw_sdt_data.shape,bccjw_fzrt_data.shape,bccjw_zrt_data.shape)\n",
    "print('砂页岩',syy_sdt_data.shape,syy_fzrt_data.shape,syy_zrt_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 分割训练集和测试集\n",
    "# sdt_data_train,sdt_data_test = train_test_split(sdt_data, test_size=0.2, random_state=42)\n",
    "# fzrt_data_train,fzrt_data_test = train_test_split(fzrt_data, test_size=0.2, random_state=42)\n",
    "# zrt_data_train,zrt_data_test = train_test_split(zrt_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # data = data\n",
    "# label = \"TZ_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定标签\n",
    "label = \"TZ_label\"\n",
    "eval_metric = 'f1_weighted'\n",
    "problem_type = 'multiclass'\n",
    "# 初始化模型和超参数\n",
    "hyperparameters={\n",
    "\t'NN_TORCH': {},\n",
    "\t'FASTAI': {},\n",
    "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
    "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,label,eval_metric,hyperparameters,problem_type,model_master,model_branch,model_root):\n",
    "    # 训练model\n",
    "    temp_master_path =os.path.join(model_root,model_master)\n",
    "    temp_branch_path = os.path.join(temp_master_path,model_branch)\n",
    "    # 检查路径是否存在，否则便创建\n",
    "    if not os.path.exists(temp_branch_path):\n",
    "        os.makedirs(temp_branch_path)\n",
    "    else:\n",
    "        print(\"文件夹已存在\")\n",
    "    # 执行训练\n",
    "    train_predictor = TabularPredictor(label=label,path=temp_branch_path,eval_metric=eval_metric,problem_type=problem_type).fit(train_data,hyperparameters=hyperparameters)\n",
    "    train_predictor.fit_summary()\n",
    "    return train_predictor.model_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.21 GB / 63.81 GB (77.1%)\n",
      "Disk Space Avail:   303.97 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    2494\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9963913392141138\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50395.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['DLMC', 'MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t42 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.80 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1988, Val Rows: 497\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.4686\t = Validation score   (f1_weighted)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4597\t = Validation score   (f1_weighted)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4577\t = Validation score   (f1_weighted)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4462\t = Validation score   (f1_weighted)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.4494\t = Validation score   (f1_weighted)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.4649\t = Validation score   (f1_weighted)\n",
      "\t5.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.4686\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 12.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\sdt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.468590  f1_weighted       0.020247  3.583091                0.000000           0.103074            2       True          7\n",
      "1      NeuralNetFastAI   0.468590  f1_weighted       0.020247  3.480017                0.020247           3.480017            1       True          1\n",
      "2       NeuralNetTorch   0.464853  f1_weighted       0.009955  5.984483                0.009955           5.984483            1       True          6\n",
      "3     RandomForestGini   0.459676  f1_weighted       0.034488  0.551089                0.034488           0.551089            1       True          2\n",
      "4     RandomForestEntr   0.457734  f1_weighted       0.034539  0.570506                0.034539           0.570506            1       True          3\n",
      "5       ExtraTreesEntr   0.449357  f1_weighted       0.035050  0.424490                0.035050           0.424490            1       True          5\n",
      "6       ExtraTreesGini   0.446220  f1_weighted       0.035591  0.439597                0.035591           0.439597            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       48.90 GB / 63.81 GB (76.6%)\n",
      "Disk Space Avail:   303.84 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    68\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 2 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50073.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['DLMC']\n",
      "\t\t('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "\t0.0s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 54, Val Rows: 14\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8942\t = Validation score   (f1_weighted)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       48.91 GB / 63.81 GB (76.6%)\n",
      "Disk Space Avail:   303.84 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    3104\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9961340206185567\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50081.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.99 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.16108247422680413, Train Rows: 2593, Val Rows: 499\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2    1.00000  f1_weighted       0.005291  0.385365                0.000000           0.090194            2       True          7\n",
      "1      NeuralNetFastAI    1.00000  f1_weighted       0.005291  0.295171                0.005291           0.295171            1       True          5\n",
      "2       ExtraTreesEntr    1.00000  f1_weighted       0.028408  0.310010                0.028408           0.310010            1       True          4\n",
      "3     RandomForestEntr    1.00000  f1_weighted       0.034410  0.303987                0.034410           0.303987            1       True          2\n",
      "4       ExtraTreesGini    1.00000  f1_weighted       0.035706  0.304420                0.035706           0.304420            1       True          3\n",
      "5     RandomForestGini    1.00000  f1_weighted       0.035801  0.304115                0.035801           0.304115            1       True          1\n",
      "6       NeuralNetTorch    0.89418  f1_weighted       0.008005  0.221995                0.008005           0.221995            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['DLMC']\n",
      "('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9767\t = Validation score   (f1_weighted)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.965\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9696\t = Validation score   (f1_weighted)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9563\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9544\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9605\t = Validation score   (f1_weighted)\n",
      "\t8.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.6, 'NeuralNetFastAI': 0.4}\n",
      "\t0.9827\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 13.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       48.91 GB / 63.81 GB (76.6%)\n",
      "Disk Space Avail:   303.78 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    310\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 5 examples. AutoGluon will only keep 8 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 5 examples that will be kept for training models: 0.9903225806451613\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50080.40 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['DLMC', 'MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t42 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 245, Val Rows: 62\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.982749  f1_weighted       0.037097  2.496392                0.000000           0.104653            2       True          7\n",
      "1      NeuralNetFastAI   0.976724  f1_weighted       0.001976  1.859879                0.001976           1.859879            1       True          1\n",
      "2     RandomForestEntr   0.969563  f1_weighted       0.035121  0.531859                0.035121           0.531859            1       True          3\n",
      "3     RandomForestGini   0.964987  f1_weighted       0.033322  0.508556                0.033322           0.508556            1       True          2\n",
      "4       NeuralNetTorch   0.960504  f1_weighted       0.008543  8.826768                0.008543           8.826768            1       True          6\n",
      "5       ExtraTreesGini   0.956322  f1_weighted       0.033656  0.432164                0.033656           0.432164            1       True          4\n",
      "6       ExtraTreesEntr   0.954359  f1_weighted       0.035986  0.426548                0.035986           0.426548            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\sy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7918\t = Validation score   (f1_weighted)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7932\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7932\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7426\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7566\t = Validation score   (f1_weighted)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6745\t = Validation score   (f1_weighted)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.5, 'NeuralNetFastAI': 0.333, 'NeuralNetTorch': 0.167}\n",
      "\t0.8469\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.54s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       48.90 GB / 63.81 GB (76.6%)\n",
      "Disk Space Avail:   303.76 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    763\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 8 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9908256880733946\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50071.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.846863  f1_weighted       0.058362  2.899117                0.002004           0.103423            2       True          7\n",
      "1     RandomForestEntr   0.793197  f1_weighted       0.035172  0.433273                0.035172           0.433273            1       True          3\n",
      "2     RandomForestGini   0.793197  f1_weighted       0.035844  0.429970                0.035844           0.429970            1       True          2\n",
      "3      NeuralNetFastAI   0.791764  f1_weighted       0.013022  1.148161                0.013022           1.148161            1       True          1\n",
      "4       ExtraTreesEntr   0.756619  f1_weighted       0.034376  0.413887                0.034376           0.413887            1       True          5\n",
      "5       ExtraTreesGini   0.742564  f1_weighted       0.034432  0.431182                0.034432           0.431182            1       True          4\n",
      "6       NeuralNetTorch   0.674539  f1_weighted       0.007491  1.217563                0.007491           1.217563            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.19s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 604, Val Rows: 152\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8084\t = Validation score   (f1_weighted)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8965\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9027\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8941\t = Validation score   (f1_weighted)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8941\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8492\t = Validation score   (f1_weighted)\n",
      "\t7.77s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.8, 'NeuralNetTorch': 0.2}\n",
      "\t0.9091\t = Validation score   (f1_weighted)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.71s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.18 GB / 63.81 GB (78.6%)\n",
      "Disk Space Avail:   303.74 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    3849\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.998181345804105\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51384.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.909106  f1_weighted       0.053171  8.367840                0.000000           0.154917            2       True          7\n",
      "1     RandomForestEntr   0.902691  f1_weighted       0.039232  0.447671                0.039232           0.447671            1       True          3\n",
      "2     RandomForestGini   0.896475  f1_weighted       0.034510  0.451834                0.034510           0.451834            1       True          2\n",
      "3       ExtraTreesGini   0.894108  f1_weighted       0.033673  0.444855                0.033673           0.444855            1       True          4\n",
      "4       ExtraTreesEntr   0.894108  f1_weighted       0.034568  0.430531                0.034568           0.430531            1       True          5\n",
      "5       NeuralNetTorch   0.849159  f1_weighted       0.013939  7.765252                0.013939           7.765252            1       True          6\n",
      "6      NeuralNetFastAI   0.808400  f1_weighted       0.013153  0.531287                0.013153           0.531287            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.12990387113535984, Train Rows: 3342, Val Rows: 500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9645\t = Validation score   (f1_weighted)\n",
      "\t2.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9739\t = Validation score   (f1_weighted)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9759\t = Validation score   (f1_weighted)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9538\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9599\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.957\t = Validation score   (f1_weighted)\n",
      "\t15.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.5, 'NeuralNetFastAI': 0.167, 'ExtraTreesEntr': 0.167, 'NeuralNetTorch': 0.167}\n",
      "\t0.9821\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 21.28s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.49 GB / 63.81 GB (77.5%)\n",
      "Disk Space Avail:   303.65 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    379\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9841688654353562\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50677.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.13 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['DLMC', 'MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "\t0.1s = Fit runtime\n",
      "\t42 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 298, Val Rows: 75\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.982123  f1_weighted       0.097761  19.732185                0.000000           0.104328            2       True          7\n",
      "1     RandomForestEntr   0.975921  f1_weighted       0.034099   0.627429                0.034099           0.627429            1       True          3\n",
      "2     RandomForestGini   0.973949  f1_weighted       0.049991   0.597838                0.049991           0.597838            1       True          2\n",
      "3      NeuralNetFastAI   0.964453  f1_weighted       0.013067   2.911370                0.013067           2.911370            1       True          1\n",
      "4       ExtraTreesEntr   0.959879  f1_weighted       0.036517   0.449044                0.036517           0.449044            1       True          5\n",
      "5       NeuralNetTorch   0.956961  f1_weighted       0.014077  15.640014                0.014077          15.640014            1       True          6\n",
      "6       ExtraTreesGini   0.953792  f1_weighted       0.035085   0.447089                0.035085           0.447089            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\tsy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 7: early stopping\n",
      "\t0.564\t = Validation score   (f1_weighted)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5915\t = Validation score   (f1_weighted)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5628\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5609\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5535\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5506\t = Validation score   (f1_weighted)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.75, 'ExtraTreesEntr': 0.25}\n",
      "\t0.6015\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.05 GB / 63.81 GB (78.4%)\n",
      "Disk Space Avail:   303.63 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    205\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 6 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51251.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 164, Val Rows: 41\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.601479  f1_weighted       0.073455  0.944552                0.000000           0.097926            2       True          7\n",
      "1     RandomForestGini   0.591544  f1_weighted       0.038967  0.496234                0.038967           0.496234            1       True          2\n",
      "2      NeuralNetFastAI   0.563985  f1_weighted       0.005831  0.409357                0.005831           0.409357            1       True          1\n",
      "3     RandomForestEntr   0.562765  f1_weighted       0.034845  0.433552                0.034845           0.433552            1       True          3\n",
      "4       ExtraTreesGini   0.560934  f1_weighted       0.032515  0.353683                0.032515           0.353683            1       True          4\n",
      "5       ExtraTreesEntr   0.553540  f1_weighted       0.034488  0.350393                0.034488           0.350393            1       True          5\n",
      "6       NeuralNetTorch   0.550572  f1_weighted       0.010066  0.839686                0.010066           0.839686            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8004\t = Validation score   (f1_weighted)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.793\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7305\t = Validation score   (f1_weighted)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6412\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6712\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7684\t = Validation score   (f1_weighted)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t0.8435\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.05 GB / 63.81 GB (78.4%)\n",
      "Disk Space Avail:   303.62 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    629\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9872813990461049\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51255.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.21 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.20 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 496, Val Rows: 125\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.843534  f1_weighted       0.015727  2.293173                0.000000           0.089202            2       True          7\n",
      "1      NeuralNetFastAI   0.800383  f1_weighted       0.005979  0.979201                0.005979           0.979201            1       True          1\n",
      "2     RandomForestGini   0.793022  f1_weighted       0.020772  0.403666                0.020772           0.403666            1       True          2\n",
      "3       NeuralNetTorch   0.768399  f1_weighted       0.009748  1.224770                0.009748           1.224770            1       True          6\n",
      "4     RandomForestEntr   0.730546  f1_weighted       0.017830  0.414489                0.017830           0.414489            1       True          3\n",
      "5       ExtraTreesEntr   0.671214  f1_weighted       0.033474  0.384157                0.033474           0.384157            1       True          5\n",
      "6       ExtraTreesGini   0.641195  f1_weighted       0.019323  0.386922                0.019323           0.386922            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8389\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8218\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.834\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8053\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8053\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8613\t = Validation score   (f1_weighted)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8613\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.93s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.10 GB / 63.81 GB (78.5%)\n",
      "Disk Space Avail:   303.60 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    100\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 8 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 8 examples. AutoGluon will only keep 4 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51303.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['DLMC', 'MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "\t0.0s = Fit runtime\n",
      "\t42 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch   0.861302  f1_weighted       0.010086  1.714987                0.010086           1.714987            1       True          6\n",
      "1  WeightedEnsemble_L2   0.861302  f1_weighted       0.015177  1.802376                0.005090           0.087389            2       True          7\n",
      "2      NeuralNetFastAI   0.838917  f1_weighted       0.005507  0.374433                0.005507           0.374433            1       True          1\n",
      "3     RandomForestEntr   0.833959  f1_weighted       0.029188  0.356067                0.029188           0.356067            1       True          3\n",
      "4     RandomForestGini   0.821830  f1_weighted       0.033304  0.349909                0.033304           0.349909            1       True          2\n",
      "5       ExtraTreesEntr   0.805332  f1_weighted       0.034268  0.355088                0.034268           0.355088            1       True          5\n",
      "6       ExtraTreesGini   0.805332  f1_weighted       0.034328  0.360043                0.034328           0.360043            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hnt\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 6: early stopping\n",
      "\t0.7792\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.733\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.733\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.733\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.733\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6417\t = Validation score   (f1_weighted)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.7792\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.75s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.06 GB / 63.81 GB (78.5%)\n",
      "Disk Space Avail:   303.60 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    160\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.98125\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51263.10 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['DLMC']\n",
      "\t\t('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "\t0.0s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 125, Val Rows: 32\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.779167  f1_weighted       0.005004  0.452578                0.000000           0.087517            2       True          7\n",
      "1      NeuralNetFastAI   0.779167  f1_weighted       0.005004  0.365061                0.005004           0.365061            1       True          1\n",
      "2     RandomForestGini   0.732971  f1_weighted       0.033014  0.347101                0.033014           0.347101            1       True          2\n",
      "3       ExtraTreesGini   0.732971  f1_weighted       0.033969  0.338219                0.033969           0.338219            1       True          4\n",
      "4       ExtraTreesEntr   0.732971  f1_weighted       0.034134  0.330029                0.034134           0.330029            1       True          5\n",
      "5     RandomForestEntr   0.732971  f1_weighted       0.034176  0.339942                0.034176           0.339942            1       True          3\n",
      "6       NeuralNetTorch   0.641667  f1_weighted       0.005029  0.645425                0.005029           0.645425            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.6368\t = Validation score   (f1_weighted)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6379\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6379\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6648\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6648\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6387\t = Validation score   (f1_weighted)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.5, 'ExtraTreesGini': 0.5}\n",
      "\t0.6783\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.07 GB / 63.81 GB (78.5%)\n",
      "Disk Space Avail:   303.59 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    5252\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9980959634424981\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51272.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.73 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.678267  f1_weighted       0.074607  0.739129                0.005013           0.089121            2       True          7\n",
      "1       ExtraTreesGini   0.664828  f1_weighted       0.034203  0.319949                0.034203           0.319949            1       True          4\n",
      "2       ExtraTreesEntr   0.664828  f1_weighted       0.035144  0.321760                0.035144           0.321760            1       True          5\n",
      "3       NeuralNetTorch   0.638672  f1_weighted       0.005504  0.420632                0.005504           0.420632            1       True          6\n",
      "4     RandomForestGini   0.637902  f1_weighted       0.035391  0.330059                0.035391           0.330059            1       True          2\n",
      "5     RandomForestEntr   0.637902  f1_weighted       0.035551  0.338117                0.035551           0.338117            1       True          3\n",
      "6      NeuralNetFastAI   0.636795  f1_weighted       0.006553  0.543564                0.006553           0.543564            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['DLMC']\n",
      "('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['DZ_MAJORITY']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.69 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 4717, Val Rows: 525\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.8307\t = Validation score   (f1_weighted)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.843\t = Validation score   (f1_weighted)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8462\t = Validation score   (f1_weighted)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8322\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.836\t = Validation score   (f1_weighted)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8088\t = Validation score   (f1_weighted)\n",
      "\t22.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.312, 'ExtraTreesGini': 0.25, 'NeuralNetFastAI': 0.188, 'ExtraTreesEntr': 0.188, 'RandomForestGini': 0.062}\n",
      "\t0.8628\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 28.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.12 GB / 63.81 GB (78.5%)\n",
      "Disk Space Avail:   303.38 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    195\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 9 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 9 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 9 examples that will be kept for training models: 0.9794871794871794\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51321.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.862793  f1_weighted       0.153268   5.535872                0.000000           0.107332            2       True          7\n",
      "1     RandomForestEntr   0.846173  f1_weighted       0.034694   0.666131                0.034694           0.666131            1       True          3\n",
      "2     RandomForestGini   0.842974  f1_weighted       0.033392   0.625709                0.033392           0.625709            1       True          2\n",
      "3       ExtraTreesEntr   0.836037  f1_weighted       0.032404   0.467891                0.032404           0.467891            1       True          5\n",
      "4       ExtraTreesGini   0.832221  f1_weighted       0.034107   0.447253                0.034107           0.447253            1       True          4\n",
      "5      NeuralNetFastAI   0.830724  f1_weighted       0.018672   3.221558                0.018672           3.221558            1       True          1\n",
      "6       NeuralNetTorch   0.808774  f1_weighted       0.010799  22.370810                0.010799          22.370810            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\nyy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUseless Original Features (Count: 1): ['DLMC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['MZ', 'DZ_MAJORITY']\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 152, Val Rows: 39\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7396\t = Validation score   (f1_weighted)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 1.0}\n",
      "\t0.9703\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.63s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.12 GB / 63.81 GB (78.5%)\n",
      "Disk Space Avail:   303.38 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    146\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 5 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51326.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 42): ['MZ', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', 'AnalyticalHillshading_MEAN', 'Aspect_MEAN', 'ChannelNetworkBaseLevel_MEAN', 'ChannelNetworkDistance_MEAN', 'ConvergenceIndex_MEAN', 'LSFactor_MEAN', 'MRRTF_MEAN', 'MRVBF_MEAN', 'PlanCurvature_MEAN', 'ProfileCurvature_MEAN', 'RelativeSlopePosition_MEAN', 'Slope_MEAN', 'TopographicWetnessIndex_MEAN', 'TotalCatchmentArea_MEAN', 'ValleyDepth_MEAN', 'NIGHT2022_MEAN', 'ETP2022_mean_MEAN', 'TMP2022_mean_MEAN', 'PRE2022_mean_MEAN', 'PRE2022_3_MEAN', 'PRE2022_11_MEAN', 'ETP2022_3_MEAN', 'ETP2022_11_MEAN', 'TMP2022_3_MEAN', 'TMP2022_11_MEAN', 'evi_MEAN', 'lswi_MEAN', 'mndwi_MEAN', 'ndmi_MEAN', 'ndvi_MEAN', 'ndwi_MEAN', 'PCA_0_MEAN', 'PCA_1_MEAN', 'savi_MEAN', 'vari_MEAN', 'DL_MAJORITY', 'SlopeClass_MAJORITY', 'DZ_MAJORITY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['DLMC']\n",
      "\t\t('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['DLMC']\n",
      "\t\t('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "\t0.0s = Fit runtime\n",
      "\t3 features in original data used to generate 3 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 116, Val Rows: 30\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI   0.970283  f1_weighted       0.010024  0.545077                0.010024           0.545077            1       True          1\n",
      "1     RandomForestEntr   0.970283  f1_weighted       0.033326  0.323692                0.033326           0.323692            1       True          3\n",
      "2       ExtraTreesGini   0.970283  f1_weighted       0.033379  0.325792                0.033379           0.325792            1       True          4\n",
      "3     RandomForestGini   0.970283  f1_weighted       0.034544  0.330044                0.034544           0.330044            1       True          2\n",
      "4       ExtraTreesEntr   0.970283  f1_weighted       0.035482  0.321078                0.035482           0.321078            1       True          5\n",
      "5  WeightedEnsemble_L2   0.970283  f1_weighted       0.040571  0.410779                0.005089           0.089701            2       True          7\n",
      "6       NeuralNetTorch   0.739617  f1_weighted       0.007397  0.282062                0.007397           0.282062            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  2 | ['MZ', 'DZ_MAJORITY']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.74s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.13 GB / 63.81 GB (78.6%)\n",
      "Disk Space Avail:   303.38 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    235\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51330.44 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 42): ['MZ', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', 'AnalyticalHillshading_MEAN', 'Aspect_MEAN', 'ChannelNetworkBaseLevel_MEAN', 'ChannelNetworkDistance_MEAN', 'ConvergenceIndex_MEAN', 'LSFactor_MEAN', 'MRRTF_MEAN', 'MRVBF_MEAN', 'PlanCurvature_MEAN', 'ProfileCurvature_MEAN', 'RelativeSlopePosition_MEAN', 'Slope_MEAN', 'TopographicWetnessIndex_MEAN', 'TotalCatchmentArea_MEAN', 'ValleyDepth_MEAN', 'NIGHT2022_MEAN', 'ETP2022_mean_MEAN', 'TMP2022_mean_MEAN', 'PRE2022_mean_MEAN', 'PRE2022_3_MEAN', 'PRE2022_11_MEAN', 'ETP2022_3_MEAN', 'ETP2022_11_MEAN', 'TMP2022_3_MEAN', 'TMP2022_11_MEAN', 'evi_MEAN', 'lswi_MEAN', 'mndwi_MEAN', 'ndmi_MEAN', 'ndvi_MEAN', 'ndwi_MEAN', 'PCA_0_MEAN', 'PCA_1_MEAN', 'savi_MEAN', 'vari_MEAN', 'DL_MAJORITY', 'SlopeClass_MAJORITY', 'DZ_MAJORITY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['DLMC']\n",
      "\t\t('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 1 | ['DLMC']\n",
      "\t\t('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "\t0.0s = Fit runtime\n",
      "\t3 features in original data used to generate 3 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 188, Val Rows: 47\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI        1.0  f1_weighted       0.000000  0.516849                0.000000           0.516849            1       True          1\n",
      "1       NeuralNetTorch        1.0  f1_weighted       0.009615  0.560353                0.009615           0.560353            1       True          6\n",
      "2     RandomForestGini        1.0  f1_weighted       0.032706  0.320757                0.032706           0.320757            1       True          2\n",
      "3     RandomForestEntr        1.0  f1_weighted       0.033525  0.327024                0.033525           0.327024            1       True          3\n",
      "4       ExtraTreesGini        1.0  f1_weighted       0.033571  0.338051                0.033571           0.338051            1       True          4\n",
      "5  WeightedEnsemble_L2        1.0  f1_weighted       0.033740  0.390239                0.000000           0.084758            2       True          7\n",
      "6       ExtraTreesEntr        1.0  f1_weighted       0.033740  0.305481                0.033740           0.305481            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 1 | ['DLMC']\n",
      "('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 6: early stopping\n",
      "\t0.938\t = Validation score   (f1_weighted)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9784\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9784\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.938\t = Validation score   (f1_weighted)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesGini': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.9s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hlcjw\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hlcjw\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       50.13 GB / 63.81 GB (78.6%)\n",
      "Disk Space Avail:   303.37 GB / 1406.25 GB (21.6%)\n",
      "===================================================\n",
      "Train Data Rows:    3563\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9823182711198428\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51335.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['DLMC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.019485  0.415174                0.000000           0.092490            2       True          7\n",
      "1       ExtraTreesGini   1.000000  f1_weighted       0.019485  0.322684                0.019485           0.322684            1       True          4\n",
      "2       ExtraTreesEntr   1.000000  f1_weighted       0.033634  0.323829                0.033634           0.323829            1       True          5\n",
      "3     RandomForestGini   0.978441  f1_weighted       0.020165  0.329230                0.020165           0.329230            1       True          2\n",
      "4     RandomForestEntr   0.978441  f1_weighted       0.034833  0.336116                0.034833           0.336116            1       True          3\n",
      "5      NeuralNetFastAI   0.937975  f1_weighted       0.006726  0.765905                0.006726           0.765905            1       True          1\n",
      "6       NeuralNetTorch   0.937975  f1_weighted       0.009490  0.470574                0.009490           0.470574            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 1 | ['DLMC']\n",
      "('float', [])    : 2 | ['Centroid_X', 'Centroid_Y']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\zhsyy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.13 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.140331181588549, Train Rows: 3008, Val Rows: 492\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.5661\t = Validation score   (f1_weighted)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5924\t = Validation score   (f1_weighted)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5942\t = Validation score   (f1_weighted)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5827\t = Validation score   (f1_weighted)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5907\t = Validation score   (f1_weighted)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5565\t = Validation score   (f1_weighted)\n",
      "\t8.91s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.875, 'NeuralNetFastAI': 0.125}\n",
      "\t0.595\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 14.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hlcjw\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.88 GB / 63.81 GB (78.2%)\n",
      "Disk Space Avail:   303.01 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    2553\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9964747356051704\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51072.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.84 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['DLMC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['MZ']\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.595002  f1_weighted       0.044685  2.995907                0.000000           0.110276            2       True          7\n",
      "1     RandomForestEntr   0.594151  f1_weighted       0.033954  0.785879                0.033954           0.785879            1       True          3\n",
      "2     RandomForestGini   0.592444  f1_weighted       0.035603  0.755762                0.035603           0.755762            1       True          2\n",
      "3       ExtraTreesEntr   0.590678  f1_weighted       0.033510  0.590342                0.033510           0.590342            1       True          5\n",
      "4       ExtraTreesGini   0.582673  f1_weighted       0.034380  0.592591                0.034380           0.592591            1       True          4\n",
      "5      NeuralNetFastAI   0.566101  f1_weighted       0.010731  2.099752                0.010731           2.099752            1       True          1\n",
      "6       NeuralNetTorch   0.556471  f1_weighted       0.010174  8.914859                0.010174           8.914859            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['MZ']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\hlcjw\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.19584802193497847, Train Rows: 2045, Val Rows: 499\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.4967\t = Validation score   (f1_weighted)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4943\t = Validation score   (f1_weighted)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5057\t = Validation score   (f1_weighted)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4809\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5099\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.4906\t = Validation score   (f1_weighted)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.333, 'RandomForestGini': 0.19, 'ExtraTreesEntr': 0.19, 'NeuralNetFastAI': 0.143, 'ExtraTreesGini': 0.095, 'NeuralNetTorch': 0.048}\n",
      "\t0.5344\t = Validation score   (f1_weighted)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.19 GB / 63.81 GB (77.1%)\n",
      "Disk Space Avail:   302.87 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    112\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50390.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['DLMC', 'MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['DLMC']\n",
      "\t\t('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['MZ']\n",
      "\t0.0s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 89, Val Rows: 23\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.534376  f1_weighted       0.166578  10.311499                0.000569           0.128531            2       True          7\n",
      "1       ExtraTreesEntr   0.509870  f1_weighted       0.036022   0.430622                0.036022           0.430622            1       True          5\n",
      "2     RandomForestEntr   0.505678  f1_weighted       0.034338   0.557540                0.034338           0.557540            1       True          3\n",
      "3      NeuralNetFastAI   0.496655  f1_weighted       0.009936   1.322596                0.009936           1.322596            1       True          1\n",
      "4     RandomForestGini   0.494276  f1_weighted       0.034547   0.545547                0.034547           0.545547            1       True          2\n",
      "5       NeuralNetTorch   0.490565  f1_weighted       0.015526   6.901528                0.015526           6.901528            1       True          6\n",
      "6       ExtraTreesGini   0.480885  f1_weighted       0.035640   0.425135                0.035640           0.425135            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['MZ']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 3: early stopping\n",
      "\t0.9138\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.9542\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.87s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.04 GB / 63.81 GB (76.8%)\n",
      "Disk Space Avail:   302.87 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    3277\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 8 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9963381141287763\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    50213.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['DLMC', 'MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['DLMC']\n",
      "\t\t('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['MZ']\n",
      "\t0.1s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.15257857796765334, Train Rows: 2766, Val Rows: 499\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch   0.954221  f1_weighted       0.002199  0.536596                0.002199           0.536596            1       True          6\n",
      "1  WeightedEnsemble_L2   0.954221  f1_weighted       0.003197  0.621401                0.000998           0.084804            2       True          7\n",
      "2     RandomForestGini   0.954221  f1_weighted       0.031920  0.405203                0.031920           0.405203            1       True          2\n",
      "3     RandomForestEntr   0.954221  f1_weighted       0.033847  0.325839                0.033847           0.325839            1       True          3\n",
      "4       ExtraTreesGini   0.954221  f1_weighted       0.034512  0.339055                0.034512           0.339055            1       True          4\n",
      "5       ExtraTreesEntr   0.954221  f1_weighted       0.036069  0.353862                0.036069           0.353862            1       True          5\n",
      "6      NeuralNetFastAI   0.913846  f1_weighted       0.011188  0.521440                0.011188           0.521440            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['DLMC']\n",
      "('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['MZ']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9577\t = Validation score   (f1_weighted)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9672\t = Validation score   (f1_weighted)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9665\t = Validation score   (f1_weighted)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.94\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9465\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.964\t = Validation score   (f1_weighted)\n",
      "\t16.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.375, 'RandomForestGini': 0.25, 'NeuralNetFastAI': 0.125, 'ExtraTreesEntr': 0.125, 'NeuralNetTorch': 0.125}\n",
      "\t0.9777\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 22.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.97 GB / 63.81 GB (78.3%)\n",
      "Disk Space Avail:   302.79 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    3563\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 17 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9823182711198428\n",
      "Train Data Class Count: 17\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51169.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.16 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['DLMC']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.13 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.977657  f1_weighted       0.170006  21.107781                0.000000           0.104845            2       True          7\n",
      "1     RandomForestGini   0.967166  f1_weighted       0.051028   0.615796                0.051028           0.615796            1       True          2\n",
      "2     RandomForestEntr   0.966540  f1_weighted       0.051412   0.612079                0.051412           0.612079            1       True          3\n",
      "3       NeuralNetTorch   0.963975  f1_weighted       0.009983  16.820169                0.009983          16.820169            1       True          6\n",
      "4      NeuralNetFastAI   0.957695  f1_weighted       0.005016   2.439789                0.005016           2.439789            1       True          1\n",
      "5       ExtraTreesEntr   0.946512  f1_weighted       0.052567   0.515103                0.052567           0.515103            1       True          5\n",
      "6       ExtraTreesGini   0.940029  f1_weighted       0.050974   0.507644                0.050974           0.507644            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['DLMC']\n",
      "('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['MZ']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\ly\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically generating train/validation split with holdout_frac=0.140331181588549, Train Rows: 3008, Val Rows: 492\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.5661\t = Validation score   (f1_weighted)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5924\t = Validation score   (f1_weighted)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5942\t = Validation score   (f1_weighted)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5827\t = Validation score   (f1_weighted)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5907\t = Validation score   (f1_weighted)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5565\t = Validation score   (f1_weighted)\n",
      "\t9.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.875, 'NeuralNetFastAI': 0.125}\n",
      "\t0.595\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 15.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.87 GB / 63.81 GB (78.1%)\n",
      "Disk Space Avail:   302.43 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    100\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51064.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['DLMC', 'MZ']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['DLMC']\n",
      "\t\t('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['MZ']\n",
      "\t0.1s = Fit runtime\n",
      "\t44 features in original data used to generate 44 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.595002  f1_weighted       0.045357  3.209138                0.000000           0.107495            2       True          7\n",
      "1     RandomForestEntr   0.594151  f1_weighted       0.034340  0.839715                0.034340           0.839715            1       True          3\n",
      "2     RandomForestGini   0.592444  f1_weighted       0.035519  0.761045                0.035519           0.761045            1       True          2\n",
      "3       ExtraTreesEntr   0.590678  f1_weighted       0.034819  0.628403                0.034819           0.628403            1       True          5\n",
      "4       ExtraTreesGini   0.582673  f1_weighted       0.035913  0.581156                0.035913           0.581156            1       True          4\n",
      "5      NeuralNetFastAI   0.566101  f1_weighted       0.011017  2.261928                0.011017           2.261928            1       True          1\n",
      "6       NeuralNetTorch   0.556471  f1_weighted       0.006896  9.631077                0.006896           9.631077            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['MZ']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 8: early stopping\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.04s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.88 GB / 63.81 GB (78.2%)\n",
      "Disk Space Avail:   302.43 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    101\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51075.82 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['MZ']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t43 features in original data used to generate 43 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 21\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI        1.0  f1_weighted       0.007017  0.404790                0.007017           0.404790            1       True          1\n",
      "1       NeuralNetTorch        1.0  f1_weighted       0.012599  0.927603                0.012599           0.927603            1       True          6\n",
      "2     RandomForestEntr        1.0  f1_weighted       0.031638  0.341535                0.031638           0.341535            1       True          3\n",
      "3     RandomForestGini        1.0  f1_weighted       0.032664  0.329037                0.032664           0.329037            1       True          2\n",
      "4       ExtraTreesEntr        1.0  f1_weighted       0.034075  0.321982                0.034075           0.321982            1       True          5\n",
      "5       ExtraTreesGini        1.0  f1_weighted       0.034953  0.320085                0.034953           0.320085            1       True          4\n",
      "6  WeightedEnsemble_L2        1.0  f1_weighted       0.039142  0.406746                0.005068           0.084765            2       True          7\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['DLMC']\n",
      "('float', [])     : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['MZ']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9526\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9526\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9526\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9526\t = Validation score   (f1_weighted)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.90 GB / 63.81 GB (78.2%)\n",
      "Disk Space Avail:   302.43 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    26\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51101.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['DLMC', 'MZ', 'DL_MAJORITY', 'DZ_MAJORITY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t40 features in original data used to generate 40 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 20, Val Rows: 6\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.009710  0.479371                0.000000           0.082095            2       True          7\n",
      "1      NeuralNetFastAI   1.000000  f1_weighted       0.009710  0.397277                0.009710           0.397277            1       True          5\n",
      "2       NeuralNetTorch   1.000000  f1_weighted       0.010064  0.439903                0.010064           0.439903            1       True          6\n",
      "3       ExtraTreesGini   0.952599  f1_weighted       0.032138  0.323942                0.032138           0.323942            1       True          3\n",
      "4       ExtraTreesEntr   0.952599  f1_weighted       0.032662  0.306628                0.032662           0.306628            1       True          4\n",
      "5     RandomForestGini   0.952599  f1_weighted       0.033410  0.317677                0.033410           0.317677            1       True          1\n",
      "6     RandomForestEntr   0.952599  f1_weighted       0.035830  0.325843                0.035830           0.325843            1       True          2\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 42 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\bccjw\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8381\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6667\t = Validation score   (f1_weighted)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.92s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.92 GB / 63.81 GB (78.2%)\n",
      "Disk Space Avail:   302.43 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    332\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9819277108433735\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51118.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['MZ', 'DZ_MAJORITY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t42 features in original data used to generate 42 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 260, Val Rows: 66\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       ExtraTreesGini   1.000000  f1_weighted       0.034157  0.301839                0.034157           0.301839            1       True          3\n",
      "1  WeightedEnsemble_L2   1.000000  f1_weighted       0.036230  0.392762                0.000000           0.083836            2       True          7\n",
      "2     RandomForestEntr   1.000000  f1_weighted       0.036230  0.308926                0.036230           0.308926            1       True          2\n",
      "3       ExtraTreesEntr   1.000000  f1_weighted       0.036231  0.305512                0.036231           0.305512            1       True          4\n",
      "4     RandomForestGini   0.838095  f1_weighted       0.034740  0.317674                0.034740           0.317674            1       True          1\n",
      "5       NeuralNetTorch   0.666667  f1_weighted       0.012912  0.176863                0.012912           0.176863            1       True          6\n",
      "6      NeuralNetFastAI   0.533333  f1_weighted       0.003504  0.103538                0.003504           0.103538            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 9: early stopping\n",
      "\t0.6396\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7376\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7601\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6766\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.687\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6732\t = Validation score   (f1_weighted)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestEntr': 1.0}\n",
      "\t0.7601\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       49.90 GB / 63.81 GB (78.2%)\n",
      "Disk Space Avail:   302.41 GB / 1406.25 GB (21.5%)\n",
      "===================================================\n",
      "Train Data Rows:    80\n",
      "Train Data Columns: 45\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 8 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 8 examples. AutoGluon will only keep 3 out of 90 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    51100.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['MZ', 'DL_MAJORITY', 'DZ_MAJORITY']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi_MEAN']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi_MEAN']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['DLMC']\n",
      "\t\t('float', [])    : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['DLMC']\n",
      "\t0.0s = Fit runtime\n",
      "\t41 features in original data used to generate 41 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 64, Val Rows: 16\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.760101  f1_weighted       0.032869  0.440153                0.000000           0.085071            2       True          7\n",
      "1     RandomForestEntr   0.760101  f1_weighted       0.032869  0.355082                0.032869           0.355082            1       True          3\n",
      "2     RandomForestGini   0.737583  f1_weighted       0.033494  0.359396                0.033494           0.359396            1       True          2\n",
      "3       ExtraTreesEntr   0.687008  f1_weighted       0.033830  0.341401                0.033830           0.341401            1       True          5\n",
      "4       ExtraTreesGini   0.676585  f1_weighted       0.034197  0.336596                0.034197           0.336596            1       True          4\n",
      "5       NeuralNetTorch   0.673199  f1_weighted       0.003258  1.289706                0.003258           1.289706            1       True          6\n",
      "6      NeuralNetFastAI   0.639616  f1_weighted       0.007128  0.321709                0.007128           0.321709            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['DLMC']\n",
      "('float', [])    : 41 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.9393\t = Validation score   (f1_weighted)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8661\t = Validation score   (f1_weighted)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8661\t = Validation score   (f1_weighted)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6875\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7935\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5795\t = Validation score   (f1_weighted)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'RandomForestGini': 0.5}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\zrt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.056621  1.424368                0.006243           0.139735            2       True          7\n",
      "1      NeuralNetFastAI   0.939327  f1_weighted       0.010022  0.780796                0.010022           0.780796            1       True          1\n",
      "2     RandomForestGini   0.866071  f1_weighted       0.040355  0.503836                0.040355           0.503836            1       True          2\n",
      "3     RandomForestEntr   0.866071  f1_weighted       0.051300  0.482829                0.051300           0.482829            1       True          3\n",
      "4       ExtraTreesEntr   0.793478  f1_weighted       0.036205  0.400121                0.036205           0.400121            1       True          5\n",
      "5       ExtraTreesGini   0.687500  f1_weighted       0.036073  0.447430                0.036073           0.447430            1       True          4\n",
      "6       NeuralNetTorch   0.579545  f1_weighted       0.000000  0.284379                0.000000           0.284379            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'XTModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'NNFastAiTabularModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 40 | ['Centroid_X', 'Centroid_Y', 'DEM_RANGE', 'DEM_MEAN', 'DEM_STD', ...]\n",
      "('int', ['bool']) :  1 | ['DLMC']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\dy\\modle\\autogluon_type_class_DY_20240726\\syy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "# 砂岩\n",
    "sy_sdt_predictor = train_model(sy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='sdt',model_root=model_path) \n",
    "sy_fzrt_predictor = train_model(sy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='fzrt',model_root=model_path) \n",
    "sy_zrt_predictor = train_model(sy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='zrt',model_root=model_path) \n",
    "# 碳酸岩\n",
    "tsy_sdt_predictor = train_model(tsy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='sdt',model_root=model_path) \n",
    "tsy_fzrt_predictor = train_model(tsy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='fzrt',model_root=model_path) \n",
    "tsy_zrt_predictor = train_model(tsy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='zrt',model_root=model_path) \n",
    "# 第四系红粘土\n",
    "hnt_sdt_predictor = train_model(hnt_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='sdt',model_root=model_path) \n",
    "hnt_fzrt_predictor = train_model(hnt_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='fzrt',model_root=model_path) \n",
    "hnt_zrt_predictor = train_model(hnt_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='zrt',model_root=model_path) \n",
    "# 泥页岩\n",
    "nyy_sdt_predictor = train_model(nyy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='sdt',model_root=model_path) \n",
    "nyy_fzrt_predictor = train_model(nyy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='fzrt',model_root=model_path) \n",
    "nyy_zrt_predictor = train_model(nyy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='zrt',model_root=model_path) \n",
    "# 紫红色砂页岩\n",
    "zhsyy_sdt_predictor = train_model(zhsyy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='sdt',model_root=model_path) \n",
    "zhsyy_fzrt_predictor = train_model(zhsyy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='fzrt',model_root=model_path) \n",
    "zhsyy_zrt_predictor = train_model(zhsyy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='zrt',model_root=model_path) \n",
    "# 河流冲积物\n",
    "hlcjw_sdt_predictor = train_model(hlcjw_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hlcjw',model_branch='sdt',model_root=model_path)\n",
    "# 砾岩\n",
    "ly_sdt_predictor = train_model(ly_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='ly',model_branch='sdt',model_root=model_path) \n",
    "ly_fzrt_predictor = train_model(ly_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='ly',model_branch='fzrt',model_root=model_path) \n",
    "ly_zrt_predictor = train_model(ly_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='ly',model_branch='zrt',model_root=model_path) \n",
    "# 第四纪冰川冲积物\n",
    "bccjw_sdt_predictor = train_model(bccjw_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='bccjw',model_branch='sdt',model_root=model_path) \n",
    "bccjw_fzrt_predictor = train_model(bccjw_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='bccjw',model_branch='fzrt',model_root=model_path) \n",
    "bccjw_zrt_predictor = train_model(bccjw_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='bccjw',model_branch='zrt',model_root=model_path) \n",
    "# 砂页岩\n",
    "syy_sdt_predictor = train_model(syy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='sdt',model_root=model_path) \n",
    "syy_fzrt_predictor = train_model(syy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='fzrt',model_root=model_path) \n",
    "syy_zrt_predictor = train_model(syy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='zrt',model_root=model_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
