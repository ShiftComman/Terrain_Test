{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, to_hetero\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1. 数据预处理\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 编码标签\n",
    "    label_encoders = {}\n",
    "    for col in ['TL', 'YL', 'TS', 'TZ']:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le.classes_  # 存储类别列表而不是编码器对象\n",
    "\n",
    "    # 分割特征\n",
    "    terrain_features = ['DEM_MEAN', 'Slope_MEAN', 'Aspect_MEAN', 'TopographicWetnessIndex_MEAN']\n",
    "    climate_features = ['PRE2022_mean_MEAN', 'TMP2022_mean_MEAN', 'ETP2022_mean_MEAN']\n",
    "    vegetation_features = ['ndvi_MEAN', 'evi_MEAN']\n",
    "    \n",
    "    # 识别分类特征和数值特征\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    numeric_features = [f for f in numeric_features if f not in terrain_features + climate_features + vegetation_features + ['TL', 'YL', 'TS', 'TZ']]\n",
    "\n",
    "    # 创建预处理管道\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ])\n",
    "\n",
    "    # 拟合和转换数据\n",
    "    X_transformed = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # 获取特征名称\n",
    "    onehot_encoder = preprocessor.named_transformers_['cat']\n",
    "    cat_feature_names = onehot_encoder.get_feature_names_out(categorical_features).tolist()\n",
    "    feature_names = numeric_features + cat_feature_names\n",
    "    \n",
    "    # 创建新的 DataFrame\n",
    "    df_transformed = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "    \n",
    "    # 添加回标签和其他特征\n",
    "    for col in ['TL', 'YL', 'TS', 'TZ'] + terrain_features + climate_features + vegetation_features:\n",
    "        df_transformed[col] = df[col]\n",
    "\n",
    "    other_features = [col for col in feature_names if col not in terrain_features + climate_features + vegetation_features]\n",
    "\n",
    "    return df_transformed, label_encoders, terrain_features, climate_features, vegetation_features, other_features\n",
    "\n",
    "# 2. 创建异构图 (保持不变)\n",
    "def create_hetero_data(df, terrain_features, climate_features, vegetation_features, other_features):\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # 添加节点\n",
    "    data['sample'].x = torch.tensor(df[other_features].values, dtype=torch.float)\n",
    "    data['terrain'].x = torch.tensor(df[terrain_features].values, dtype=torch.float)\n",
    "    data['climate'].x = torch.tensor(df[climate_features].values, dtype=torch.float)\n",
    "    data['vegetation'].x = torch.tensor(df[vegetation_features].values, dtype=torch.float)\n",
    "    \n",
    "    # 确保所有节点类型都有特征，即使是空特征\n",
    "    for node_type in ['sample', 'terrain', 'climate', 'vegetation']:\n",
    "        if data[node_type].x is None:\n",
    "            data[node_type].x = torch.zeros((len(df), 1), dtype=torch.float)\n",
    "    \n",
    "    # 添加边\n",
    "    num_samples = len(df)\n",
    "    edge_index = torch.stack([torch.arange(num_samples), torch.arange(num_samples)], dim=0)\n",
    "    \n",
    "    data['sample', 'has', 'terrain'].edge_index = edge_index\n",
    "    data['terrain', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    data['sample', 'has', 'climate'].edge_index = edge_index\n",
    "    data['climate', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    data['sample', 'has', 'vegetation'].edge_index = edge_index\n",
    "    data['vegetation', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    # 添加标签\n",
    "    data['sample'].y_TL = torch.tensor(df['TL'].values, dtype=torch.long)\n",
    "    data['sample'].y_YL = torch.tensor(df['YL'].values, dtype=torch.long)\n",
    "    data['sample'].y_TS = torch.tensor(df['TS'].values, dtype=torch.long)\n",
    "    data['sample'].y_TZ = torch.tensor(df['TZ'].values, dtype=torch.long)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 3. 定义模型 (保持不变)\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, metadata):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() if x is not None else x for key, x in x_dict.items()}\n",
    "        return {key: self.lin(x) if x is not None else x for key, x in x_dict.items()}\n",
    "# SoilClassifier 类\n",
    "class SoilClassifier(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, metadata, num_classes):\n",
    "        super().__init__()\n",
    "        self.gnn = HeteroGNN(hidden_channels, hidden_channels, num_layers=2, metadata=metadata)\n",
    "        self.classifier_TL = torch.nn.Linear(hidden_channels, num_classes['TL'])\n",
    "        self.classifier_YL = torch.nn.Linear(hidden_channels, num_classes['YL'])\n",
    "        self.classifier_TS = torch.nn.Linear(hidden_channels, num_classes['TS'])\n",
    "        self.classifier_TZ = torch.nn.Linear(hidden_channels, num_classes['TZ'])\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.gnn(x_dict, edge_index_dict)\n",
    "        x = x_dict.get('sample')\n",
    "        if x is None:\n",
    "            return None\n",
    "        return {\n",
    "            'TL': self.classifier_TL(x),\n",
    "            'YL': self.classifier_YL(x),\n",
    "            'TS': self.classifier_TS(x),\n",
    "            'TZ': self.classifier_TZ(x)\n",
    "        }\n",
    "# 4. 训练函数 (保持不变)\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        loss = (F.cross_entropy(out['TL'], data['sample'].y_TL) +\n",
    "                F.cross_entropy(out['YL'], data['sample'].y_YL) +\n",
    "                F.cross_entropy(out['TS'], data['sample'].y_TS) +\n",
    "                F.cross_entropy(out['TZ'], data['sample'].y_TZ)) / 4\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 5. 评估函数 (保持不变)\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    total_correct = {key: 0 for key in ['TL', 'YL', 'TS', 'TZ']}\n",
    "    total_examples = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        for key in ['TL', 'YL', 'TS', 'TZ']:\n",
    "            pred = out[key].argmax(dim=-1)\n",
    "            total_correct[key] += int((pred == data['sample'][f'y_{key}']).sum())\n",
    "        total_examples += data['sample'].y_TL.size(0)\n",
    "    return {key: total_correct[key] / total_examples for key in ['TL', 'YL', 'TS', 'TZ']}\n",
    "\n",
    "# 主函数\n",
    "def main(data_path):\n",
    "    # 数据预处理\n",
    "    df, label_encoders, terrain_features, climate_features, vegetation_features, other_features = preprocess_data(data_path)\n",
    "    \n",
    "    # 创建异构图数据\n",
    "    data = create_hetero_data(df, terrain_features, climate_features, vegetation_features, other_features)\n",
    "    \n",
    "    # 直接分割索引，而不是分割 HeteroData 对象\n",
    "    num_samples = df.shape[0]\n",
    "    indices = list(range(num_samples))\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 创建子图的索引字典\n",
    "    train_subset = {\n",
    "        'sample': torch.tensor(train_indices),\n",
    "        'terrain': torch.tensor(train_indices),\n",
    "        'climate': torch.tensor(train_indices),\n",
    "        'vegetation': torch.tensor(train_indices)\n",
    "    }\n",
    "    test_subset = {\n",
    "        'sample': torch.tensor(test_indices),\n",
    "        'terrain': torch.tensor(test_indices),\n",
    "        'climate': torch.tensor(test_indices),\n",
    "        'vegetation': torch.tensor(test_indices)\n",
    "    }\n",
    "\n",
    "    # 使用索引创建训练集和测试集\n",
    "    train_data = data.subgraph(train_subset)\n",
    "    test_data = data.subgraph(test_subset)\n",
    "\n",
    "    train_loader = DataLoader([train_data], batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader([test_data], batch_size=32, shuffle=False)\n",
    "\n",
    "    # 定义模型\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = {key: len(classes) for key, classes in label_encoders.items()}\n",
    "    model = SoilClassifier(hidden_channels=64, metadata=data.metadata(), num_classes=num_classes).to(device)\n",
    "    \n",
    "    # 训练模型\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(100):\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "        train_acc = test(model, train_loader, device)\n",
    "        test_acc = test(model, test_loader, device)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc}, Test Acc: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 001, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 002, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 003, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 004, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 005, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 006, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 007, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 008, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 009, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 010, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 011, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 012, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 013, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 014, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 015, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 016, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 017, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 018, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 019, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 020, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 021, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 022, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 023, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 024, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 025, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 026, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 027, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 028, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 029, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 030, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 031, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 032, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 033, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 034, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 035, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 036, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 037, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 038, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 039, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 040, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 041, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 042, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 043, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 044, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 045, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 046, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 047, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 048, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 049, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 050, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 051, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 052, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 053, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 054, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 055, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 056, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 057, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 058, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 059, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 060, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 061, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 062, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 063, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 064, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 065, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 066, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 067, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 068, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 069, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 070, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 071, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 072, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 073, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 074, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 075, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 076, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 077, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 078, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 079, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 080, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 081, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 082, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 083, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 084, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 085, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 086, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 087, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 088, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 089, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 090, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 091, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 092, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 093, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 094, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 095, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 096, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 097, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 098, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n",
      "Epoch: 099, Loss: nan, Train Acc: {'TL': 0.00625, 'YL': 0.6625, 'TS': 0.0125, 'TZ': 0.00625}, Test Acc: {'TL': 0.0, 'YL': 0.6, 'TS': 0.075, 'TZ': 0.025}\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Runker\\Desktop\\train_polygon.csv\"\n",
    "main(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 数据预处理\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 只编码 TZ 标签\n",
    "    le_tz = LabelEncoder()\n",
    "    df['TZ'] = le_tz.fit_transform(df['TZ'])\n",
    "    label_encoder = le_tz\n",
    "\n",
    "    # 分割特征\n",
    "    terrain_features = ['DEM_MEAN', 'Slope_MEAN', 'Aspect_MEAN', 'TopographicWetnessIndex_MEAN']\n",
    "    climate_features = ['PRE2022_mean_MEAN', 'TMP2022_mean_MEAN', 'ETP2022_mean_MEAN']\n",
    "    vegetation_features = ['ndvi_MEAN', 'evi_MEAN']\n",
    "    \n",
    "    # 识别分类特征和数值特征\n",
    "    categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    numeric_features = [f for f in numeric_features if f not in terrain_features + climate_features + vegetation_features + ['TZ']]\n",
    "\n",
    "    # 对分类特征进行编码\n",
    "    le_dict = {}\n",
    "    for cat_feat in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        df[cat_feat] = le.fit_transform(df[cat_feat])\n",
    "        le_dict[cat_feat] = le\n",
    "\n",
    "    # 对数值特征进行标准化\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "    # 合并所有特征\n",
    "    all_features = numeric_features + categorical_features + terrain_features + climate_features + vegetation_features\n",
    "    \n",
    "    other_features = [col for col in all_features if col not in terrain_features + climate_features + vegetation_features]\n",
    "\n",
    "    return df, label_encoder, terrain_features, climate_features, vegetation_features, other_features, le_dict\n",
    "\n",
    "# 创建异构图\n",
    "def create_hetero_data(df, terrain_features, climate_features, vegetation_features, other_features):\n",
    "    data = HeteroData()\n",
    "    \n",
    "    # 添加节点\n",
    "    data['sample'].x = torch.tensor(df[other_features].values, dtype=torch.float)\n",
    "    data['terrain'].x = torch.tensor(df[terrain_features].values, dtype=torch.float)\n",
    "    data['climate'].x = torch.tensor(df[climate_features].values, dtype=torch.float)\n",
    "    data['vegetation'].x = torch.tensor(df[vegetation_features].values, dtype=torch.float)\n",
    "    \n",
    "    # 确保所有节点类型都有特征，即使是空特征\n",
    "    for node_type in ['sample', 'terrain', 'climate', 'vegetation']:\n",
    "        if data[node_type].x is None:\n",
    "            data[node_type].x = torch.zeros((len(df), 1), dtype=torch.float)\n",
    "    \n",
    "    # 添加边\n",
    "    num_samples = len(df)\n",
    "    edge_index = torch.stack([torch.arange(num_samples), torch.arange(num_samples)], dim=0)\n",
    "    \n",
    "    data['sample', 'has', 'terrain'].edge_index = edge_index\n",
    "    data['terrain', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    data['sample', 'has', 'climate'].edge_index = edge_index\n",
    "    data['climate', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    data['sample', 'has', 'vegetation'].edge_index = edge_index\n",
    "    data['vegetation', 'belongs_to', 'sample'].edge_index = edge_index.flip([0])\n",
    "    \n",
    "    # 添加标签\n",
    "    data['sample'].y = torch.tensor(df['TZ'].values, dtype=torch.long)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 定义模型\n",
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_layers, metadata):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({\n",
    "                edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "                for edge_type in metadata[1]\n",
    "            })\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() if x is not None else x for key, x in x_dict.items()}\n",
    "        return {key: self.lin(x) if x is not None else x for key, x in x_dict.items()}\n",
    "\n",
    "class SoilClassifier(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, metadata, num_classes):\n",
    "        super().__init__()\n",
    "        self.gnn = HeteroGNN(hidden_channels, hidden_channels, num_layers=2, metadata=metadata)\n",
    "        self.classifier = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        x_dict = self.gnn(x_dict, edge_index_dict)\n",
    "        x = x_dict['sample']\n",
    "        return self.classifier(x)\n",
    "\n",
    "# 训练函数\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        loss = F.cross_entropy(out, data['sample'].y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "# 评估函数\n",
    "@torch.no_grad()\n",
    "def test(model, loader, device):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_examples = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data.x_dict, data.edge_index_dict)\n",
    "        pred = out.argmax(dim=-1)\n",
    "        total_correct += int((pred == data['sample'].y).sum())\n",
    "        total_examples += data['sample'].y.size(0)\n",
    "        predictions.extend(pred.cpu().numpy())\n",
    "        true_labels.extend(data['sample'].y.cpu().numpy())\n",
    "    return total_correct / total_examples, predictions, true_labels\n",
    "\n",
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(y_true, y_pred, classes):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "# 主函数\n",
    "def main(data_path):\n",
    "    # 数据预处理\n",
    "    df, label_encoder, terrain_features, climate_features, vegetation_features, other_features, le_dict = preprocess_data(data_path)\n",
    "    \n",
    "    # 创建异构图数据\n",
    "    data = create_hetero_data(df, terrain_features, climate_features, vegetation_features, other_features)\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    num_samples = df.shape[0]\n",
    "    indices = list(range(num_samples))\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 为每种节点类型创建子图索引\n",
    "    train_subset = {\n",
    "        node_type: torch.tensor(train_indices)\n",
    "        for node_type in data.node_types\n",
    "    }\n",
    "    test_subset = {\n",
    "        node_type: torch.tensor(test_indices)\n",
    "        for node_type in data.node_types\n",
    "    }\n",
    "\n",
    "    # 使用索引创建训练集和测试集\n",
    "    train_data = data.subgraph(train_subset)\n",
    "    test_data = data.subgraph(test_subset)\n",
    "\n",
    "    train_loader = DataLoader([train_data], batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader([test_data], batch_size=32, shuffle=False)\n",
    "\n",
    "    # 定义模型\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    model = SoilClassifier(hidden_channels=64, metadata=data.metadata(), num_classes=num_classes).to(device)\n",
    "    \n",
    "    # 训练模型\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(100):\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "        train_acc, _, _ = test(model, train_loader, device)\n",
    "        test_acc, test_pred, test_true = test(model, test_loader, device)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "    # 打印分类报告\n",
    "    print(classification_report(test_true, test_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "    # 绘制混淆矩阵\n",
    "    plot_confusion_matrix(test_true, test_pred, label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 001, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 002, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 003, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 004, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 005, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 006, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 007, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 008, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 009, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 010, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 011, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 012, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 013, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 014, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 015, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 016, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 017, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 018, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 019, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 020, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 021, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 022, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 023, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 024, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 025, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 026, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 027, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 028, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 029, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 030, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 031, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 032, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 033, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 034, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 035, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 036, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 037, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 038, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 039, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 040, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 041, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 042, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 043, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 044, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 045, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 046, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 047, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 048, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 049, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 050, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 051, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 052, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 053, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 054, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 055, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 056, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 057, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 058, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 059, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 060, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 061, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 062, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 063, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 064, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 065, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 066, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 067, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 068, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 069, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 070, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 071, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 072, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 073, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 074, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 075, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 076, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 077, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 078, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 079, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 080, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 081, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 082, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 083, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 084, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 085, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 086, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 087, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 088, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 089, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 090, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 091, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 092, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 093, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 094, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 095, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 096, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 097, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 098, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n",
      "Epoch: 099, Loss: nan, Train Acc: 0.0063, Test Acc: 0.0250\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 24, does not match size of target_names, 40. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mRunker\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain_polygon.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 202\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(data_path)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# 打印分类报告\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# 绘制混淆矩阵\u001b[39;00m\n\u001b[0;32m    205\u001b[0m plot_confusion_matrix(test_true, test_pred, label_encoder\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32md:\\worker_code\\.venvgis\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\worker_code\\.venvgis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2614\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2608\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels size, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of target_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2610\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names)\n\u001b[0;32m   2611\u001b[0m             )\n\u001b[0;32m   2612\u001b[0m         )\n\u001b[0;32m   2613\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2614\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2615\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes, \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, does not match size of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2616\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_names, \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m. Try specifying the labels \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2617\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(target_names))\n\u001b[0;32m   2618\u001b[0m         )\n\u001b[0;32m   2619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2620\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m l \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 24, does not match size of target_names, 40. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\Runker\\Desktop\\train_polygon.csv\"\n",
    "main(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
