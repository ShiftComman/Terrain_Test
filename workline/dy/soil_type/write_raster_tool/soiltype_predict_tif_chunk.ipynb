{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from rasterio.windows import Window\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import psutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TIFPredictor:\n",
    "    def __init__(self, model_path, model_name, input_folder, chunk_size=(100, 100)):\n",
    "        self.model = TabularPredictor.load(model_path)\n",
    "        self.select_model = model_name\n",
    "        self.input_folder = input_folder\n",
    "        self.feature_columns = self.model.feature_metadata_in.get_features()\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def read_tif_info(self, file_path):\n",
    "        with rasterio.open(file_path) as src:\n",
    "            return src.profile, src.shape\n",
    "\n",
    "    def read_tif_chunk(self, file_path, row_start, row_end, col_start, col_end):\n",
    "        with rasterio.open(file_path) as src:\n",
    "            return src.read(1, window=((row_start, row_end), (col_start, col_end)))\n",
    "\n",
    "    def generate_chunks(self, shape):\n",
    "        rows, cols = shape\n",
    "        for row in range(0, rows, self.chunk_size[0]):\n",
    "            for col in range(0, cols, self.chunk_size[1]):\n",
    "                yield (row, min(row + self.chunk_size[0], rows),\n",
    "                       col, min(col + self.chunk_size[1], cols))\n",
    "\n",
    "    def predict(self, output_path):\n",
    "        # Get metadata from the first TIF file\n",
    "        first_tif = os.path.join(self.input_folder, f\"{self.feature_columns[0]}.tif\")\n",
    "        profile, shape = self.read_tif_info(first_tif)\n",
    "\n",
    "        # Prepare the output file\n",
    "        profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "        total_chunks = sum(1 for _ in self.generate_chunks(shape))\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            with tqdm(total=total_chunks, desc=\"处理进度\") as pbar:\n",
    "                for row_start, row_end, col_start, col_end in self.generate_chunks(shape):\n",
    "                    chunk_data = {}\n",
    "                    for feature in self.feature_columns:\n",
    "                        tif_path = os.path.join(self.input_folder, f\"{feature}.tif\")\n",
    "                        chunk = self.read_tif_chunk(tif_path, row_start, row_end, col_start, col_end)\n",
    "                        chunk_data[feature] = chunk.flatten()\n",
    "                    print(\"完成区块特征数据拾取\")\n",
    "                    # Prepare input data for the model\n",
    "                    X = pd.DataFrame(chunk_data)\n",
    "\n",
    "                    # Make predictions\n",
    "                    predictions = self.model.predict(X, model=self.select_model)\n",
    "                    print(\"完成区块预测\")\n",
    "                    # Reshape predictions to match the chunk size\n",
    "                    predictions = predictions.values.reshape((row_end - row_start, col_end - col_start))\n",
    "\n",
    "                    # Write the predictions to the output file\n",
    "                    dst.write(predictions.astype(rasterio.float32), 1, window=((row_start, row_end), (col_start, col_end)))\n",
    "                pbar.update(1)\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressTrackingTIFPredictor:\n",
    "    def __init__(self, model_path, model_name, input_folder, num_workers=None):\n",
    "        self.model = TabularPredictor.load(model_path)\n",
    "        self.select_model = model_name\n",
    "        self.input_folder = input_folder\n",
    "        self.feature_columns = self.model.feature_metadata_in.get_features()\n",
    "        self.num_workers = num_workers or max(1, psutil.cpu_count(logical=False) - 1)\n",
    "        self.tif_data = {}\n",
    "        self.shape = None\n",
    "        self.profile = None\n",
    "\n",
    "    def preload_tif_data(self):\n",
    "        total_memory = psutil.virtual_memory().total\n",
    "        memory_limit = 0.8 * total_memory  # Use up to 80% of available memory\n",
    "\n",
    "        cumulative_size = 0\n",
    "        for feature in tqdm(self.feature_columns, desc=\"Preloading TIF data\"):\n",
    "            tif_path = os.path.join(self.input_folder, f\"{feature}.tif\")\n",
    "            with rasterio.open(tif_path) as src:\n",
    "                if self.shape is None:\n",
    "                    self.shape = src.shape\n",
    "                    self.profile = src.profile\n",
    "                data = src.read(1)\n",
    "                cumulative_size += data.nbytes\n",
    "                if cumulative_size > memory_limit:\n",
    "                    print(f\"Warning: Memory limit reached. Some data will be read on-demand.\")\n",
    "                    break\n",
    "                self.tif_data[feature] = data\n",
    "\n",
    "        print(\"TIF data preloading completed\")\n",
    "\n",
    "    def read_chunk(self, feature, window):\n",
    "        if feature in self.tif_data:\n",
    "            return self.tif_data[feature][window.row_off:window.row_off+window.height, \n",
    "                                          window.col_off:window.col_off+window.width]\n",
    "        else:\n",
    "            tif_path = os.path.join(self.input_folder, f\"{feature}.tif\")\n",
    "            with rasterio.open(tif_path) as src:\n",
    "                return src.read(1, window=window)\n",
    "\n",
    "    def process_chunk(self, chunk_info):\n",
    "        row_start, row_end, col_start, col_end = chunk_info\n",
    "        window = Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        chunk_data = {}\n",
    "        for feature in self.feature_columns:\n",
    "            chunk = self.read_chunk(feature, window)\n",
    "            chunk_data[feature] = chunk.flatten()\n",
    "\n",
    "        X = pd.DataFrame(chunk_data)\n",
    "        predictions = self.model.predict(X, model=self.select_model)\n",
    "        return predictions.values.reshape((row_end - row_start, col_end - col_start)), chunk_info\n",
    "\n",
    "    def predict(self, output_path):\n",
    "        start_time = time.time()\n",
    "        self.preload_tif_data()\n",
    "\n",
    "        if self.shape is None or self.profile is None:\n",
    "            first_tif = os.path.join(self.input_folder, f\"{self.feature_columns[0]}.tif\")\n",
    "            with rasterio.open(first_tif) as src:\n",
    "                self.shape = src.shape\n",
    "                self.profile = src.profile\n",
    "\n",
    "        self.profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "        # Determine optimal chunk size\n",
    "        total_pixels = self.shape[0] * self.shape[1]\n",
    "        chunk_pixels = max(1000000, total_pixels // (self.num_workers * 10))  # Aim for at least 10 chunks per worker\n",
    "        chunk_side = int(np.sqrt(chunk_pixels))\n",
    "        chunks = list(self.generate_chunks(self.shape, (chunk_side, chunk_side)))\n",
    "\n",
    "        # Pre-allocate the entire output array in memory\n",
    "        output_data = np.zeros(self.shape, dtype=np.float32)\n",
    "\n",
    "        total_chunks = len(chunks)\n",
    "        processed_chunks = 0\n",
    "        total_time = 0\n",
    "\n",
    "        with ProcessPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "            futures = {executor.submit(self.process_chunk, chunk): chunk for chunk in chunks}\n",
    "            \n",
    "            with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "                for future in as_completed(futures):\n",
    "                    chunk_start_time = time.time()\n",
    "                    predictions, (row_start, row_end, col_start, col_end) = future.result()\n",
    "                    output_data[row_start:row_end, col_start:col_end] = predictions\n",
    "                    \n",
    "                    processed_chunks += 1\n",
    "                    chunk_time = time.time() - chunk_start_time\n",
    "                    total_time += chunk_time\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # Estimate remaining time\n",
    "                    avg_time_per_chunk = total_time / processed_chunks\n",
    "                    estimated_total_time = avg_time_per_chunk * total_chunks\n",
    "                    remaining_time = estimated_total_time - total_time\n",
    "                    \n",
    "                    # Update progress bar description with time estimate\n",
    "                    pbar.set_description(f\"Processing chunks - ETA: {remaining_time:.2f}s\")\n",
    "\n",
    "        # Write the entire output at once\n",
    "        with rasterio.open(output_path, 'w', **self.profile) as dst:\n",
    "            dst.write(output_data, 1)\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_runtime = end_time - start_time\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "        print(f\"Total runtime: {total_runtime:.2f} seconds\")\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_chunks(shape, chunk_size):\n",
    "        rows, cols = shape\n",
    "        for row in range(0, rows, chunk_size[0]):\n",
    "            for col in range(0, cols, chunk_size[1]):\n",
    "                yield (row, min(row + chunk_size[0], rows),\n",
    "                       col, min(col + chunk_size[1], cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeScaleTIFPredictor:\n",
    "    def __init__(self, model_path, model_name, input_folder, num_workers=None, chunk_size=(1000, 1000)):\n",
    "        self.model = TabularPredictor.load(model_path)\n",
    "        self.select_model = model_name\n",
    "        self.input_folder = input_folder\n",
    "        self.feature_columns = self.model.feature_metadata_in.get_features()\n",
    "        self.num_workers = num_workers or max(1, psutil.cpu_count(logical=False) - 1)\n",
    "        self.chunk_size = chunk_size\n",
    "        self.shape = None\n",
    "        self.profile = None\n",
    "\n",
    "    def get_tif_info(self):\n",
    "        first_tif = os.path.join(self.input_folder, f\"{self.feature_columns[0]}.tif\")\n",
    "        with rasterio.open(first_tif) as src:\n",
    "            self.shape = src.shape\n",
    "            self.profile = src.profile\n",
    "        print(f\"TIF dimensions: {self.shape[0]} x {self.shape[1]} pixels\")\n",
    "\n",
    "    def read_chunk(self, feature, window):\n",
    "        tif_path = os.path.join(self.input_folder, f\"{feature}.tif\")\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            return src.read(1, window=window)\n",
    "\n",
    "    def process_chunk(self, chunk_info):\n",
    "        row_start, row_end, col_start, col_end = chunk_info\n",
    "        window = Window(col_start, row_start, col_end - col_start, row_end - row_start)\n",
    "        chunk_data = {}\n",
    "        for feature in self.feature_columns:\n",
    "            chunk = self.read_chunk(feature, window)\n",
    "            chunk_data[feature] = chunk.flatten()\n",
    "\n",
    "        X = pd.DataFrame(chunk_data)\n",
    "        predictions = self.model.predict(X, model=self.select_model)\n",
    "        return predictions.values.reshape((row_end - row_start, col_end - col_start)), chunk_info\n",
    "\n",
    "    def predict(self, output_path):\n",
    "        start_time = time.time()\n",
    "        self.get_tif_info()\n",
    "\n",
    "        self.profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "        chunks = list(self.generate_chunks(self.shape, self.chunk_size))\n",
    "        total_chunks = len(chunks)\n",
    "\n",
    "        print(f\"Total number of chunks to process: {total_chunks}\")\n",
    "        print(f\"Estimated memory usage per chunk: {self.estimate_memory_usage_per_chunk()} MB\")\n",
    "\n",
    "        processed_chunks = 0\n",
    "        total_processing_time = 0\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **self.profile) as dst:\n",
    "            with ProcessPoolExecutor(max_workers=self.num_workers) as executor:\n",
    "                futures = {executor.submit(self.process_chunk, chunk): chunk for chunk in chunks}\n",
    "                \n",
    "                with tqdm(total=total_chunks, desc=\"Processing chunks\") as pbar:\n",
    "                    for future in as_completed(futures):\n",
    "                        chunk_start_time = time.time()\n",
    "                        predictions, (row_start, row_end, col_start, col_end) = future.result()\n",
    "                        dst.write(predictions, 1, window=Window(col_start, row_start, col_end - col_start, row_end - row_start))\n",
    "                        \n",
    "                        processed_chunks += 1\n",
    "                        chunk_time = time.time() - chunk_start_time\n",
    "                        total_processing_time += chunk_time\n",
    "                        \n",
    "                        # Update progress bar\n",
    "                        pbar.update(1)\n",
    "                        \n",
    "                        # Estimate remaining time\n",
    "                        avg_time_per_chunk = total_processing_time / processed_chunks\n",
    "                        estimated_total_time = avg_time_per_chunk * total_chunks\n",
    "                        remaining_time = estimated_total_time - total_processing_time\n",
    "                        \n",
    "                        # Update progress bar description with time estimate\n",
    "                        pbar.set_description(f\"Processing chunks - ETA: {remaining_time/60:.2f} minutes\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_runtime = end_time - start_time\n",
    "        print(f\"Predictions saved to {output_path}\")\n",
    "        print(f\"Total runtime: {total_runtime/60:.2f} minutes\")\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_chunks(shape, chunk_size):\n",
    "        rows, cols = shape\n",
    "        for row in range(0, rows, chunk_size[0]):\n",
    "            for col in range(0, cols, chunk_size[1]):\n",
    "                yield (row, min(row + chunk_size[0], rows),\n",
    "                       col, min(col + chunk_size[1], cols))\n",
    "\n",
    "    def estimate_memory_usage_per_chunk(self):\n",
    "        # Estimate memory usage for one chunk (in MB)\n",
    "        num_features = len(self.feature_columns)\n",
    "        chunk_pixels = self.chunk_size[0] * self.chunk_size[1]\n",
    "        bytes_per_pixel = 4  # Assuming float32\n",
    "        return (chunk_pixels * num_features * bytes_per_pixel) / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.features import geometry_mask\n",
    "from rasterio.windows import Window\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from shapely.geometry import shape, box\n",
    "import fiona\n",
    "import logging\n",
    "import warnings\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "# Set sklearn logging level to WARNING\n",
    "logging.getLogger('sklearn').setLevel(logging.WARNING)\n",
    "\n",
    "# Ignore specific sklearn warnings\n",
    "warnings.filterwarnings('ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings('ignore', message='X does not have valid feature names')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class OptimizedSingleProcessVectorMaskedTIFPredictor:\n",
    "    def __init__(self, model_path, model_name, input_folder, vector_path, chunk_size=(1000, 1000)):\n",
    "        self.model = TabularPredictor.load(model_path)\n",
    "        self.select_model = model_name\n",
    "        self.input_folder = input_folder\n",
    "        self.vector_path = vector_path\n",
    "        self.chunk_size = chunk_size\n",
    "        self.feature_columns = self.model.feature_metadata_in.get_features()\n",
    "        self.shape = None\n",
    "        self.profile = None\n",
    "        self.vector_mask = None\n",
    "        self.valid_windows = []\n",
    "\n",
    "    def get_tif_info_and_create_mask(self):\n",
    "        first_tif = os.path.join(self.input_folder, f\"{self.feature_columns[0]}.tif\")\n",
    "        with rasterio.open(first_tif) as src:\n",
    "            self.shape = src.shape\n",
    "            self.profile = src.profile\n",
    "\n",
    "            with fiona.open(self.vector_path, \"r\") as vector_file:\n",
    "                shapes = [shape(feature['geometry']) for feature in vector_file]\n",
    "                raster_bounds = box(*src.bounds)\n",
    "                total_vector_area = sum(s.area for s in shapes)\n",
    "                clipped_shapes = [shape.intersection(raster_bounds) for shape in shapes]\n",
    "                clipped_shapes = [s for s in clipped_shapes if not s.is_empty]\n",
    "                \n",
    "                if not clipped_shapes:\n",
    "                    raise ValueError(\"The vector area does not intersect with the raster extent.\")\n",
    "                \n",
    "                clipped_area = sum(s.area for s in clipped_shapes)\n",
    "                self.vector_mask = geometry_mask(clipped_shapes, out_shape=self.shape, transform=src.transform, invert=True)\n",
    "\n",
    "        logging.info(f\"TIF dimensions: {self.shape[0]} x {self.shape[1]} pixels\")\n",
    "        logging.info(f\"Total raster area: {raster_bounds.area}\")\n",
    "        logging.info(f\"Total vector area: {total_vector_area}\")\n",
    "        logging.info(f\"Intersection area: {clipped_area}\")\n",
    "        logging.info(f\"Percentage of vector area within raster: {(clipped_area / total_vector_area) * 100:.2f}%\")\n",
    "        logging.info(f\"Area to process: {np.sum(self.vector_mask)} pixels\")\n",
    "\n",
    "        self.valid_windows = self.generate_valid_windows()\n",
    "        logging.info(f\"Number of chunks to process: {len(self.valid_windows)}\")\n",
    "\n",
    "    def generate_valid_windows(self):\n",
    "        valid_windows = []\n",
    "        for window in self.generate_windows(self.shape, self.chunk_size):\n",
    "            if np.any(self.vector_mask[window.row_off:window.row_off+window.height, \n",
    "                                       window.col_off:window.col_off+window.width]):\n",
    "                valid_windows.append(window)\n",
    "        return valid_windows\n",
    "\n",
    "    def read_masked_chunk(self, feature, window):\n",
    "        tif_path = os.path.join(self.input_folder, f\"{feature}.tif\")\n",
    "        with rasterio.open(tif_path) as src:\n",
    "            chunk = src.read(1, window=window)\n",
    "            mask = self.vector_mask[window.row_off:window.row_off+window.height, \n",
    "                                    window.col_off:window.col_off+window.width]\n",
    "            return chunk[mask]\n",
    "\n",
    "    def process_chunk(self, window):\n",
    "        try:\n",
    "            chunk_data = {}\n",
    "            for feature in self.feature_columns:\n",
    "                chunk = self.read_masked_chunk(feature, window)\n",
    "                chunk_data[feature] = chunk.flatten()\n",
    "\n",
    "            X = pd.DataFrame(chunk_data)\n",
    "            predictions = self.model.predict(X, model=self.select_model)\n",
    "\n",
    "            full_chunk = np.zeros((window.height, window.width), dtype=np.float32)\n",
    "            mask = self.vector_mask[window.row_off:window.row_off+window.height, \n",
    "                                    window.col_off:window.col_off+window.width]\n",
    "            full_chunk[mask] = predictions\n",
    "\n",
    "            return full_chunk, window\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing chunk {window}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, output_path):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            self.get_tif_info_and_create_mask()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in get_tif_info_and_create_mask: {str(e)}\")\n",
    "            return\n",
    "\n",
    "        self.profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
    "\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "        total_chunks = len(self.valid_windows)\n",
    "        processed_chunks = 0\n",
    "        total_processing_time = 0\n",
    "\n",
    "        with rasterio.open(output_path, 'w', **self.profile) as dst:\n",
    "            for window in tqdm(self.valid_windows, desc=\"Processing chunks\"):\n",
    "                chunk_start_time = time.time()\n",
    "                result = self.process_chunk(window)\n",
    "                if result is not None:\n",
    "                    predictions, window = result\n",
    "                    dst.write(predictions, 1, window=window)\n",
    "                    processed_chunks += 1\n",
    "                    chunk_time = time.time() - chunk_start_time\n",
    "                    total_processing_time += chunk_time\n",
    "\n",
    "                    avg_time_per_chunk = total_processing_time / processed_chunks\n",
    "                    estimated_total_time = avg_time_per_chunk * total_chunks\n",
    "                    remaining_time = estimated_total_time - total_processing_time\n",
    "\n",
    "        end_time = time.time()\n",
    "        total_runtime = end_time - start_time\n",
    "        logging.info(f\"Predictions saved to {output_path}\")\n",
    "        logging.info(f\"Total runtime: {total_runtime/60:.2f} minutes\")\n",
    "        logging.info(f\"Processed {processed_chunks} out of {total_chunks} chunks\")\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_windows(shape, chunk_size):\n",
    "        rows, cols = shape\n",
    "        for row in range(0, rows, chunk_size[0]):\n",
    "            for col in range(0, cols, chunk_size[1]):\n",
    "                yield Window(col, row, \n",
    "                             min(chunk_size[1], cols - col),\n",
    "                             min(chunk_size[0], rows - row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例\n",
    "model_path = r'F:\\cache_data\\model_path\\sb\\soil_type\\autogluon\\autogluon_20240902'\n",
    "model_name = 'WeightedEnsemble_L2'  # 例如 'WeightedEnsemble_L2'\n",
    "input_folder = r'F:\\tif_features\\county_feature\\sb'\n",
    "output_path = r'C:\\Users\\Runker\\Desktop\\test\\CSC\\prediction_wl2.tif'\n",
    "shp_extent_path = r'C:\\Users\\Runker\\Desktop\\test\\SHp\\SB_EXTENT.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 13:55:43,494 - INFO - TIF dimensions: 12573 x 12150 pixels\n",
      "2024-09-04 13:55:43,494 - INFO - Total raster area: 3819048750.0\n",
      "2024-09-04 13:55:43,494 - INFO - Total vector area: 1697098094.7289455\n",
      "2024-09-04 13:55:43,494 - INFO - Intersection area: 1695684300.7598128\n",
      "2024-09-04 13:55:43,494 - INFO - Percentage of vector area within raster: 99.92%\n",
      "2024-09-04 13:55:43,566 - INFO - Area to process: 67827322 pixels\n",
      "2024-09-04 13:55:43,577 - INFO - Number of chunks to process: 95\n",
      "Processing chunks:   2%|▏         | 2/95 [04:00<3:20:29, 129.35s/it]"
     ]
    }
   ],
   "source": [
    "# 矢量范围裁剪预测\n",
    "predictor = OptimizedSingleProcessVectorMaskedTIFPredictor(model_path, model_name, input_folder, shp_extent_path, chunk_size=(1000, 1000))\n",
    "predictor.predict(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = LargeScaleTIFPredictor(model_path, model_name, input_folder, chunk_size=(20, 20))\n",
    "predictor.predict(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ProgressTrackingTIFPredictor(model_path, model_name, input_folder)\n",
    "predictor.predict(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TIFPredictor(model_path, model_name, input_folder)\n",
    "predictor.predict(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
