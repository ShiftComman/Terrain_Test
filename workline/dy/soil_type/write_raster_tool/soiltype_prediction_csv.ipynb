{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征表格存放文件\n",
    "csv_path = r\"F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344 F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_000.csv\n"
     ]
    }
   ],
   "source": [
    "# 获取所有的特征表格列表\n",
    "def get_all_csv_list(path):\n",
    "    csv_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_list.append(os.path.join(root, file))\n",
    "    sorted_files = sorted(csv_list, key=lambda x: int(x.rsplit('_', 1)[-1].split('.')[0]))\n",
    "    return sorted_files\n",
    "csv_list = get_all_csv_list(csv_path)\n",
    "print(len(csv_list),csv_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入训练好的模型\n",
    "# predictor = TabularPredictor.load(r\"F:\\cache_data\\model_path\\dy\\soil_type\\cart\\cart_tree.pkl\")\n",
    "model_path = r\"F:\\cache_data\\model_path\\dy\\soil_type\\cart\\cart_tree.pkl\"\n",
    "# 加载模型\n",
    "with open(model_path, 'rb') as f:\n",
    "    predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入autogluon模型\n",
    "predictor = TabularPredictor.load(r\"F:\\cache_data\\model_path\\dy\\soil_type\\autogluon\\have_dz_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('WeightedEnsemble_L2',\n",
       " ['KNeighborsUnif',\n",
       "  'KNeighborsDist',\n",
       "  'NeuralNetFastAI',\n",
       "  'LightGBMXT',\n",
       "  'LightGBM',\n",
       "  'RandomForestGini',\n",
       "  'RandomForestEntr',\n",
       "  'CatBoost',\n",
       "  'WeightedEnsemble_L2'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best,predictor.model_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEM', 'Mean', 'ndvi', 'PCA_0', 'LON', 'LAT', 'PH', 'DL', 'DZ']\n"
     ]
    }
   ],
   "source": [
    "# 获取特征\n",
    "feature_names = predictor.feature_metadata_in.get_features()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存放预测结果的路径\n",
    "result_path =  r\"F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\predict_csv\"\n",
    "pred_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cart训练\n",
    "predictions = []\n",
    "for idx,one_pred_csv in enumerate(csv_list):\n",
    "    data_df = pd.read_csv(one_pred_csv)\n",
    "    data_df = data_df[data_df.columns[1:]]\n",
    "    temp_pred = predictor.predict(data_df)\n",
    "\n",
    "    # 将预测结果添加到列表中\n",
    "    # 如果 temp_pred 不是一个 pandas Series 或 DataFrame，可以先将其转换\n",
    "    predictions.append(pd.Series(temp_pred, name=f'prediction_{idx}'))\n",
    "    print(one_pred_csv)\n",
    "\n",
    "# 一次性将所有预测结果合并为一个 DataFrame\n",
    "pred_df = pd.concat(predictions, axis=1)\n",
    "\n",
    "# 保存 pred_df 到新的 CSV 文件\n",
    "pred_df.to_csv(os.path.join(result_path, 'prediction_.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_000.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_001.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_002.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_003.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_004.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_005.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_006.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_007.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_008.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_009.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_010.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_011.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_012.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_013.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_014.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_015.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_016.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_017.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_018.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_019.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_020.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_021.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_022.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_023.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_024.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_025.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_026.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_027.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_028.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_029.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_030.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_031.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\autogluon\\feature_csv\\data_chunk_032.csv\n"
     ]
    }
   ],
   "source": [
    "# 使用autogluon训练\n",
    "predictions = []\n",
    "for idx,one_pred_csv in enumerate(csv_list):\n",
    "    # data_df = pd.read_csv(one_pred_csv)\n",
    "    # data_df = data_df[feature_names]\n",
    "    # temp_pred = predictor.predict(data_df, model='RandomForestEntr')\n",
    "    # # 将预测结果添加到列表中\n",
    "    # # 如果 temp_pred 不是一个 pandas Series 或 DataFrame，可以先将其转换\n",
    "    # predictions.append(pd.Series(temp_pred, name=f'prediction_{idx}'))\n",
    "    # print(one_pred_csv)\n",
    "\n",
    "    try:\n",
    "        data_df = pd.read_csv(one_pred_csv)\n",
    "        data_df = data_df[feature_names]\n",
    "        # 对所有列进行通用的数据清洗\n",
    "        for col in data_df.columns:\n",
    "            # 检查列是否为数值类型，如果不是，则尝试清洗和转换\n",
    "            if not pd.api.types.is_numeric_dtype(data_df[col]):\n",
    "                # 移除非数字字符\n",
    "                data_df[col] = data_df[col].replace(to_replace=r'[^\\d.]+', value='', regex=True)\n",
    "                # 尝试转换为浮点数，无法转换的设置为NaN\n",
    "                # data_df[col] = pd.to_numeric(data_df[col], errors='coerce')\n",
    "\n",
    "        # 丢弃或填充NaN值，视您的需求而定\n",
    "        # data_df.dropna(inplace=True)  # 丢弃任何包含NaN的行\n",
    "        # 或者\n",
    "        # data_df.fillna(0, inplace=True)  # 用0填充NaN值\n",
    "\n",
    "        # 对数据进行预测\n",
    "        temp_pred = predictor.predict(data_df, model='RandomForestEntr')\n",
    "\n",
    "        # 将预测结果添加到列表中\n",
    "        predictions.append(pd.Series(temp_pred, name=f'prediction_{idx}'))\n",
    "        print(one_pred_csv)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {one_pred_csv} 时发生错误: {e}\")\n",
    "\n",
    "# 一次性将所有预测结果合并为一个 DataFrame\n",
    "pred_df = pd.concat(predictions, axis=1)\n",
    "\n",
    "# 保存 pred_df 到新的 CSV 文件\n",
    "pred_df.to_csv(os.path.join(result_path, 'prediction_ph_RandomForestEntr_20240221.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_000.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_001.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_002.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_003.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_004.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_005.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_006.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_007.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_008.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_009.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_010.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_011.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_012.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_013.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_014.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_015.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_016.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_017.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_018.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_019.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_020.csv\n",
      "F:\\cache_data\\pre_soiltype_table\\dy\\cart\\features_csv\\data_chunk_021.csv\n"
     ]
    }
   ],
   "source": [
    "# 使用autogluon训练\n",
    "predictions = []\n",
    "for idx,one_pred_csv in enumerate(csv_list):\n",
    "    data_df = pd.read_csv(one_pred_csv)\n",
    "    data_df = data_df[data_df.columns[1:]]\n",
    "    temp_pred = predictor.predict(data_df, model='RandomForestGini')\n",
    "    # 将预测结果添加到列表中\n",
    "    # 如果 temp_pred 不是一个 pandas Series 或 DataFrame，可以先将其转换\n",
    "    predictions.append(pd.Series(temp_pred, name=f'prediction_{idx}'))\n",
    "    print(one_pred_csv)\n",
    "\n",
    "# 一次性将所有预测结果合并为一个 DataFrame\n",
    "pred_df = pd.concat(predictions, axis=1) \n",
    "\n",
    "# 保存 pred_df 到新的 CSV 文件\n",
    "pred_df.to_csv(os.path.join(result_path, 'prediction_ph_RandomForestGini_dldz.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
