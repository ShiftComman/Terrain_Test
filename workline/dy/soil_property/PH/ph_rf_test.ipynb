{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,roc_auc_score,roc_curve,precision_recall_curve,r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error,root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV,RandomizedSearchCV\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "import shutil\n",
    "import graphviz\n",
    "import dtreeviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv(r\"F:\\cache_data\\pre_property_table\\dy\\feature_ph_dy.csv\")\n",
    "print(len(data))\n",
    "# 删除有缺失值的行\n",
    "# data.dropna(inplace=True)\n",
    "# len(data),data.columns\n",
    "\n",
    "# 选择数值列并计算它们的均值\n",
    "numeric_cols = data.select_dtypes(include=[np.number])\n",
    "means = numeric_cols.mean()\n",
    "# 使用均值填充每个数值列的缺失值\n",
    "data[numeric_cols.columns] = data[numeric_cols.columns].fillna(means)\n",
    "len(data),data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = data.duplicated(subset=list(data.columns)[1:], keep='first')\n",
    "df_duplicates = data[duplicates]\n",
    "df_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除重复数据\n",
    "data.drop_duplicates(subset=list(data.columns)[1:], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取单数行（偶数索引）和双数行（奇数索引）的pH值\n",
    "even_index_pH = df_duplicates.iloc[::2]['ph']  # 偶数索引行\n",
    "odd_index_pH = df_duplicates.iloc[1::2]['ph']  # 奇数索引行\n",
    "\n",
    "# 创建折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(even_index_pH.index, even_index_pH, label='Even Index Rows')\n",
    "plt.plot(odd_index_pH.index, odd_index_pH, label='Odd Index Rows')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Comparison of pH Values in Even and Odd Rows')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('pH Value')\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改写分类字段的类型\n",
    "data['DL'] = data['DL'].astype(\"category\")\n",
    "data['DZ'] = data['DZ'].astype(\"category\")\n",
    "data['SlopeClass'] = data['SlopeClass'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['DEM', 'AnalyticalHillshading', 'Aspect',\n",
    "       'ChannelNetworkBaseLevel', 'ChannelNetworkDistance',\n",
    "       'ClosedDepressions', 'ConvergenceIndex', 'LSFactor', 'MRRTF', 'MRVBF',\n",
    "       'PlanCurvature', 'ProfileCurvature', 'RelativeSlopePosition', 'Slope',\n",
    "       'TopographicWetnessIndex', 'TotalCatchmentArea', 'ValleyDepth',\n",
    "       'NIGHT2022', 'ETP2022_mean', 'TMP2022_mean', 'PRE2022_mean',\n",
    "       'PRE2022_3', 'PRE2022_11', 'ETP2022_3', 'ETP2022_11', 'TMP2022_3',\n",
    "       'TMP2022_11', 'evi', 'lswi', 'mndwi', 'ndmi', 'ndvi', 'ndwi', 'PCA_0',\n",
    "       'PCA_1', 'savi', 'vari', 'DL', 'DZ', 'LON', 'LAT', 'SlopeClass']]\n",
    "y = data['ph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "# 输出训练集和测试集的形状\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义随机森林超参数的取值范围\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(10, 1000, 10),\n",
    "    'max_features': [1.0],\n",
    "    'max_depth': [None] + list(np.arange(1, 28)),\n",
    "    'min_samples_split': np.arange(2, 21),\n",
    "    'min_samples_leaf': np.arange(1, 21),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# 创建随机森林回归器\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "# 使用RandomizedSearchCV来寻找最佳参数\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=100, cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 打印最佳参数\n",
    "print('Best Parameters: \\n', random_search.best_params_)\n",
    "\n",
    "# 使用最佳参数对测试集进行评估\n",
    "best_clf = random_search.best_estimator_\n",
    "score = best_clf.score(X_test, y_test)\n",
    "print('Test accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最优参数训练RandomForestRegressor模型\n",
    "rf = RandomForestRegressor(n_estimators=90,criterion='squared_error', min_samples_split=6, min_samples_leaf= 8, max_features=1.0, max_depth=21, bootstrap= True)\n",
    "rf.fit(X_train,y_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "y_train_pred = rf.predict(X_train)\n",
    "r2_score(y_test,y_test_pred),r2_score(y_train,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test,y_test_pred)\n",
    "# 画图\n",
    "plt.scatter(y_test, y_test_pred, c='b', alpha=0.5)\n",
    "\n",
    "fit = np.polyfit(y_test, y_test_pred,deg=1)\n",
    "fit_fn = np.poly1d(fit) \n",
    "plt.plot(y_test, fit_fn(y_test), c='r')\n",
    "\n",
    "plt.xlim([min(y_test)-0.5, max(y_test)+0.5])\n",
    "plt.ylim([min(y_test_pred)-0.5, max(y_test_pred)+0.5])\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('R^2: %.2f' % r2)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(len(y_test[:100])),y_test[:100],c='r',label='True value')\n",
    "plt.plot(range(len(y_test_pred[:100])),y_test_pred[:100],c='c',label = 'Prediction value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_score = mean_squared_error(y_test, y_test_pred)\n",
    "mae_score = mean_absolute_error(y_test, y_test_pred)\n",
    "mape_score = mean_absolute_percentage_error(y_test, y_test_pred)\n",
    "rmse_score = root_mean_squared_error(y_test, y_test_pred)\n",
    "r2score = r2_score(y_test, y_test_pred)\n",
    "print('Mse:', mse_score,'Mae',mae_score,'Mape',mape_score,'Rmse',rmse_score,'r2score',r2score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rf.feature_importances_\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制特征重要性柱状图\n",
    "plt.figure(figsize=(10, 8.5))\n",
    "plt.barh(X.columns, a)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据标准化后再训练\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# 实例化标准化器\n",
    "\n",
    "# scaler = StandardScaler()  # Z得分标准化（Standard Scaling）:将数据按属性（按列进行）减去其均值，并除以其标准差。结果的分布将具有均值为 0 和标准差为 1。\n",
    "\n",
    "scaler = MinMaxScaler()  # 最小-最大标准化（Min-Max Scaling）:将所有特征缩放到 [0, 1] 范围内，或者是其他指定的范围。对异常值非常敏感。\n",
    "\n",
    "# 加载数据\n",
    "# scaler = RobustScaler()  # 稳健标准化（Robust Scaling）:使用四分位数范围来缩放数据，因此它对异常值不敏感。\n",
    "for model in [StandardScaler(),MinMaxScaler(),RobustScaler()]:\n",
    "    scaler = model\n",
    "\n",
    "    # 对训练数据进行拟合和转换\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "    # 对测试数据进行转换\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # 训练随机森林模型\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 模型评估（例如，使用 R2 分数）\n",
    "    r2score = rf.score(X_test_scaled, y_test)\n",
    "    print(\"R2 Score: \", r2score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 克里金残差训练\n",
    "# 计算残差\n",
    "residuals_test =y_train - y_train_pred\n",
    "# 克里金残差测试\n",
    "OK = OrdinaryKriging(X_train['LON'], X_train['LAT'], residuals_test, variogram_model='spherical')  #variogram_model:linear,gaussian,exponential,spherical\n",
    "kriging_predictions_test, _ = OK.execute('points', X_test['LON'], X_test['LAT'])\n",
    "predictions_test = y_test_pred + kriging_predictions_test\n",
    "# 计算R2\n",
    "r2 = r2_score(y_test, predictions_test)\n",
    "r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算R2\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归特征消除 (选择最佳组合特征)\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "\n",
    "# RFE\n",
    "selector = RFECV(RandomForestRegressor(n_jobs=4),step=1,cv=5,n_jobs=4)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# 查看选中的特征\n",
    "selected_features = selector.support_\n",
    "# 计算测试集的 R2 分数\n",
    "y_pred = selector.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Selected Features: \", selected_features)\n",
    "print(\"Number of Selected Features: \", selector.n_features_)\n",
    "print(\"R2 Score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features,selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代优化 (选择最佳组合特征)\n",
    "\n",
    "best_score = 0\n",
    "best_features = None\n",
    "\n",
    "# 尝试不同数量的特征\n",
    "for i in range(1, X_train.shape[1] + 1):\n",
    "    # RFE 选择特征\n",
    "    selector = RFE(RandomForestRegressor(n_jobs=4), n_features_to_select=i, step=1)\n",
    "    selector = selector.fit(X_train, y_train)\n",
    "\n",
    "    # 预测并计算 R2 分数\n",
    "    y_pred = selector.predict(X_test)\n",
    "    score = r2_score(y_test, y_pred)\n",
    "\n",
    "    # 更新最佳分数和特征\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_features = selector.support_\n",
    "\n",
    "print(\"Best R2 Score: \", best_score)\n",
    "print(\"Best Features: \", best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [True,  True, False, False,  True, False, False, False,  True,  True,  True,  True,\n",
    " False, False,  True, False, False, False, False, False, False, False,  True,  True,\n",
    " False, False,  True,  True, False, False, False,  True,  True,  True]\n",
    "features_list = list(data.columns)\n",
    "features_list.remove('pH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [features_list[index] for index, item in enumerate(a) if item == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features),len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "def regression_prediction_cc(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    n_iter_search = 50\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_params['n_estimators'] - 50), best_params['n_estimators'], min(1000, best_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_params['max_depth'] - 5), best_params['max_depth'], best_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_params['min_samples_split'] - 2), best_params['min_samples_split'], best_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_params['min_samples_leaf'] - 1), best_params['min_samples_leaf'], best_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    plt.show()\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "def regression_prediction(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    \n",
    "    # 获取选择的特征索引\n",
    "    selected_features =  np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    print(X_train_selected.shape)\n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv=5, n_iter=100, random_state=42, n_jobs=-1, verbose=1)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_params['n_estimators'] - 50), best_params['n_estimators'], min(1000, best_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_params['max_depth'] - 5), best_params['max_depth'], best_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_params['min_samples_split'] - 2), best_params['min_samples_split'], best_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_params['min_samples_leaf'] - 1), best_params['min_samples_leaf'], best_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    \n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    plt.show()\n",
    "\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv(r\"F:\\cache_data\\pre_property_table\\dy\\feature_ph_dy.csv\")\n",
    "print(len(data))\n",
    "# 删除有缺失值的行\n",
    "# data.dropna(inplace=True)\n",
    "# len(data),data.columns\n",
    "\n",
    "# 选择数值列并计算它们的均值\n",
    "numeric_cols = data.select_dtypes(include=[np.number])\n",
    "means = numeric_cols.mean()\n",
    "# 使用均值填充每个数值列的缺失值\n",
    "data[numeric_cols.columns] = data[numeric_cols.columns].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用户上传的DataFrame\n",
    "df = data\n",
    "\n",
    "coord_cols = [\"LON\", \"LAT\"]\n",
    "# 用户选择的标签列和特征列\n",
    "label_col = \"yjz\"\n",
    "feature_cols = ['DEM', 'AnalyticalHillshading', 'Aspect',\n",
    "       'ChannelNetworkBaseLevel', 'ChannelNetworkDistance',\n",
    "       'ClosedDepressions', 'ConvergenceIndex', 'LSFactor', 'MRRTF', 'MRVBF',\n",
    "       'PlanCurvature', 'ProfileCurvature', 'RelativeSlopePosition', 'Slope',\n",
    "       'TopographicWetnessIndex', 'TotalCatchmentArea', 'ValleyDepth',\n",
    "       'NIGHT2022', 'ETP2022_mean', 'TMP2022_mean', 'PRE2022_mean',\n",
    "       'PRE2022_3', 'PRE2022_11', 'ETP2022_3', 'ETP2022_11', 'TMP2022_3',\n",
    "       'TMP2022_11', 'evi', 'lswi', 'mndwi', 'ndmi', 'ndvi', 'ndwi', 'PCA_0',\n",
    "       'PCA_1', 'savi', 'vari', 'DL', 'DZ','SlopeClass']\n",
    "\n",
    "# 用户指定的超参数调优范围\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(10, 1000, 10),\n",
    "    'max_depth': [None] + list(np.arange(1, 100)),\n",
    "    'min_samples_split': np.arange(2, 21),\n",
    "    'min_samples_leaf': np.arange(1, 21),\n",
    "}\n",
    "\n",
    "# 用户指定的保存模型路径\n",
    "save_model_path = r\"C:\\Users\\Runker\\Desktop\\testrf\\best_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = regression_prediction(df, label_col, feature_cols,coord_cols, param_grid, save_model_path)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = regression_prediction_cc(df, label_col, feature_cols,coord_cols, param_grid, save_model_path)\n",
    "print(scores2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
