{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from pykrige.rk import RegressionKriging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rf_classics(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    rf = RandomForestRegressor()\n",
    "    n_iter_search = 100\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # 打印最佳参数\n",
    "    best_random_params = random_search.best_params_\n",
    "    print('Best Random Parameters: \\n', best_random_params)\n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    best_randomrf = random_search.best_estimator_\n",
    "    testrandom_score = best_randomrf.score(X_test, y_test)\n",
    "    trainrandom_score = best_randomrf.score(X_train, y_train)\n",
    "\n",
    "    print('RandomSearch Test accuracy:', testrandom_score,'RandomSearch Train accuracy:',trainrandom_score)\n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    print(f\"Random search best params: {best_random_params}\")\n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_random_params['n_estimators'] - 50), best_random_params['n_estimators'], min(1000, best_random_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_random_params['max_depth'] - 5), best_random_params['max_depth'], best_random_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_random_params['min_samples_split'] - 2), best_random_params['min_samples_split'], best_random_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_random_params['min_samples_leaf'] - 1), best_random_params['min_samples_leaf'], best_random_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=best_randomrf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    # 最优参数\n",
    "    best_gr_params = grid_search.best_params_\n",
    "    best_gr_rf = grid_search.best_estimator_\n",
    "    # 打印最佳参数\n",
    "    print('Best Grid Parameters: \\n', best_gr_params)\n",
    "    # 使用最佳参数对测试集进行评估\n",
    "    test_gr_score = best_gr_rf.score(X_test, y_test)\n",
    "    train_gr_score = best_gr_rf.score(X_train, y_train)\n",
    "    print('GridSearch Test accuracy:', test_gr_score,'GridSearch Train accuracy:',train_gr_score)\n",
    "    # 特征重要性\n",
    "    feature_gr_importances = best_gr_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': feature_gr_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_gr_rf.predict(X_train)\n",
    "    y_test_pred = best_gr_rf.predict(X_test)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_gr_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": feature_cols,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFRK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regression_prediction_cc(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    n_iter_search = 50\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [max(10, best_params['n_estimators'] - 50), best_params['n_estimators'], min(1000, best_params['n_estimators'] + 50)],\n",
    "        'max_depth': [max(1, best_params['max_depth'] - 5), best_params['max_depth'], best_params['max_depth'] + 5],\n",
    "        'min_samples_split': [max(2, best_params['min_samples_split'] - 2), best_params['min_samples_split'], best_params['min_samples_split'] + 2],\n",
    "        'min_samples_leaf': [max(1, best_params['min_samples_leaf'] - 1), best_params['min_samples_leaf'], best_params['min_samples_leaf'] + 1]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "    # 计算残差\n",
    "    residuals_train = y_train - y_train_pred\n",
    "    \n",
    "    # 克里金残差训练\n",
    "    OK = OrdinaryKriging(X_train[coord_cols[0]], X_train[coord_cols[1]], residuals_train, variogram_model='spherical')\n",
    "    kriging_predictions_test, _ = OK.execute('points', X_test[coord_cols[0]], X_test[coord_cols[1]])\n",
    "    \n",
    "    # 最终预测\n",
    "    predictions_test = y_test_pred + kriging_predictions_test\n",
    "    \n",
    "    # 计算克里金残差评估分数\n",
    "    r2_rk = r2_score(y_test, predictions_test)\n",
    "    mae_rk = mean_absolute_error(y_test, predictions_test)\n",
    "    mse_rk = mean_squared_error(y_test, predictions_test)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "    \n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def regression_prediction(df, label_col, feature_cols, coord_cols, param_grid, save_model_path):\n",
    "    # 分离特征和标签\n",
    "    X = df[feature_cols + coord_cols]\n",
    "    y = df[label_col]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 初始化随机森林回归器\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # 迭代特征优化\n",
    "    selector = RFECV(rf, step=1, cv=5)\n",
    "    selector = selector.fit(X_train[feature_cols], y_train)\n",
    "    X_train_selected = selector.transform(X_train[feature_cols])\n",
    "    X_test_selected = selector.transform(X_test[feature_cols])\n",
    "    \n",
    "    # 获取选择的特征\n",
    "    selected_features = np.array(feature_cols)[selector.support_]\n",
    "    print(f\"Selected features: {selected_features}\")\n",
    "    \n",
    "    # 初步超参数搜索（随机搜索）\n",
    "    n_iter_search = 50\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=n_iter_search, cv=5, random_state=42, n_jobs=-1, verbose=2)\n",
    "    random_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 基于随机搜索结果的超参数范围\n",
    "    best_params = random_search.best_params_\n",
    "    print(f\"Random search best params: {best_params}\")\n",
    "    \n",
    "    param_grid_fine = {\n",
    "        'n_estimators': [_ for _ in range(best_params['n_estimators'] - 5, best_params['n_estimators'] + 5,2)],\n",
    "        'max_depth': [_ for _ in range(best_params['max_depth'] - 2, best_params['max_depth'] + 2)],\n",
    "        'min_samples_split': [_ for _ in range(best_params['min_samples_split'] - 2, best_params['min_samples_split'] + 2)],\n",
    "        'min_samples_leaf': [_ for _ in range(best_params['min_samples_leaf'] - 2, best_params['min_samples_leaf'] + 2)]\n",
    "    }\n",
    "    \n",
    "    # 精细超参数搜索（网格搜索）\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid_fine, cv=5, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # 最优参数\n",
    "    best_params = grid_search.best_params_\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    \n",
    "    # 特征重要性\n",
    "    feature_importances = best_rf.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': selected_features,\n",
    "        'Importance': feature_importances\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    # 保存特征重要性\n",
    "    importance_df.to_csv(os.path.join(os.path.dirname(save_model_path), 'feature_importance.csv'), index=False)\n",
    "    \n",
    "    # 绘制特征重要性图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'feature_importance_importance.png'))\n",
    "    \n",
    "    # 预测与评估\n",
    "    y_train_pred = best_rf.predict(X_train_selected)\n",
    "    y_test_pred = best_rf.predict(X_test_selected)\n",
    "    \n",
    "    r2_rf = r2_score(y_test, y_test_pred)\n",
    "    mae_rf = mean_absolute_error(y_test, y_test_pred)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred)\n",
    "    rmse_rf = np.sqrt(mse_rf)\n",
    "    \n",
    "    # 输出随机森林评估分数\n",
    "    print(f\"Random Forest R2: {r2_rf}\")\n",
    "    print(f\"Random Forest MAE: {mae_rf}\")\n",
    "    print(f\"Random Forest MSE: {mse_rf}\")\n",
    "    print(f\"Random Forest RMSE: {rmse_rf}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # 使用克里回归模型训练\n",
    "    rk = RegressionKriging(regression_model=best_rf,n_closest_points=36)\n",
    "    rk.fit(X_train_selected, X_train[coord_cols].values, y_train)\n",
    "    y_pred_rk = rk.predict(X_test_selected, X_test[coord_cols].values)\n",
    "\n",
    "    r2_rk = r2_score(y_test, y_pred_rk)\n",
    "    mae_rk = mean_absolute_error(y_test, y_pred_rk)\n",
    "    mse_rk = mean_squared_error(y_test, y_pred_rk)\n",
    "    rmse_rk = np.sqrt(mse_rk)\n",
    "\n",
    "    # 输出克里金残差评估分数\n",
    "    print(f\"Regression Kriging R2: {r2_rk}\")\n",
    "    print(f\"Regression Kriging MAE: {mae_rk}\")\n",
    "    print(f\"Regression Kriging MSE: {mse_rk}\")\n",
    "    print(f\"Regression Kriging RMSE: {rmse_rk}\")\n",
    "\n",
    "    # 绘制随机森林评估分数图\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    metrics = ['R2', 'MAE', 'MSE', 'RMSE']\n",
    "    values_rf = [r2_rf, mae_rf, mse_rf, rmse_rf]\n",
    "    values_rk = [r2_rk, mae_rk, mse_rk, rmse_rk]\n",
    "\n",
    "    # 随机森林评估分数图\n",
    "    plt.subplot(2, 1, 1)\n",
    "    bars_rf = plt.bar(metrics, values_rf)\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Random Forest Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rf, values_rf):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rf) - min(values_rf)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    # 克里金回归评估分数图\n",
    "    plt.subplot(2, 1, 2)\n",
    "    bars_rk = plt.bar(metrics, values_rk)\n",
    "    plt.xlabel('Metrics')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title('Regression Kriging Evaluation Scores')\n",
    "\n",
    "    # 在条形图上标注值\n",
    "    for bar, value in zip(bars_rk, values_rk):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05 * (max(values_rk) - min(values_rk)), \n",
    "                f'{value:.2f}', ha='center', va='bottom')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.path.dirname(save_model_path), 'evaluation_scores.png'))\n",
    "    # 保存模型\n",
    "    with open(save_model_path, 'wb') as f:\n",
    "        pickle.dump(best_rf, f)\n",
    "    \n",
    "    return {\n",
    "        \"SelectedFeatures\": selected_features,\n",
    "        \"FeatureImportance\": importance_df,\n",
    "        \"RandomForest\": {\n",
    "            \"R2\": r2_rf,\n",
    "            \"MAE\": mae_rf,\n",
    "            \"MSE\": mse_rf,\n",
    "            \"RMSE\": rmse_rf\n",
    "        },\n",
    "        \"RegressionKriging\": {\n",
    "            \"R2\": r2_rk,\n",
    "            \"MAE\": mae_rk,\n",
    "            \"MSE\": mse_rk,\n",
    "            \"RMSE\": rmse_rk\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1159\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "data = pd.read_csv(r\"F:\\cache_data\\pre_property_table\\dy\\feature_ph_dy.csv\")\n",
    "print(len(data))\n",
    "# 删除有缺失值的行\n",
    "# data.dropna(inplace=True)\n",
    "# len(data),data.columns\n",
    "\n",
    "# 选择数值列并计算它们的均值\n",
    "numeric_cols = data.select_dtypes(include=[np.number])\n",
    "means = numeric_cols.mean()\n",
    "# 使用均值填充每个数值列的缺失值\n",
    "data[numeric_cols.columns] = data[numeric_cols.columns].fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DL'] = data['DL'].astype(\"category\")\n",
    "data['DZ'] = data['DZ'].astype(\"category\")\n",
    "data['SlopeClass'] = data['SlopeClass'].astype(\"category\")\n",
    "# 用户上传的DataFrame\n",
    "df = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coord_cols = [\"LON\", \"LAT\"]\n",
    "# 用户选择的标签列和特征列\n",
    "# label_col = \"ph\"\n",
    "feature_cols = ['DEM', 'AnalyticalHillshading', 'Aspect',\n",
    "       'ChannelNetworkBaseLevel', 'ChannelNetworkDistance',\n",
    "       'ClosedDepressions', 'ConvergenceIndex', 'LSFactor', 'MRRTF', 'MRVBF',\n",
    "       'PlanCurvature', 'ProfileCurvature', 'RelativeSlopePosition', 'Slope',\n",
    "       'TopographicWetnessIndex', 'TotalCatchmentArea', 'ValleyDepth',\n",
    "       'NIGHT2022', 'ETP2022_mean', 'TMP2022_mean', 'PRE2022_mean',\n",
    "       'PRE2022_3', 'PRE2022_11', 'ETP2022_3', 'ETP2022_11', 'TMP2022_3',\n",
    "       'TMP2022_11', 'evi', 'lswi', 'mndwi', 'ndmi', 'ndvi', 'ndwi', 'PCA_0',\n",
    "       'PCA_1', 'savi', 'vari', 'DL', 'DZ','SlopeClass']\n",
    "\n",
    "# 用户指定的超参数调优范围\n",
    "param_grid = {\n",
    "    'n_estimators': np.arange(10, 1000, 10),\n",
    "    'max_depth': [None] + list(np.arange(1, 100)),\n",
    "    'min_samples_split': np.arange(2, 100),\n",
    "    'min_samples_leaf': np.arange(1, 100),\n",
    "}\n",
    "\n",
    "# 用户指定的保存模型路径\n",
    "# save_model_path = r\"C:\\Users\\Runker\\Desktop\\testrf\\best_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐个训练并导出\n",
    "label_cols_list = ['zge', 'zge2', 'znie',\n",
    "       'jxzc11', 'jxzc12', 'jxzc13', 'jxzc14']\n",
    "# rf模型目录\n",
    "rf_dir = r\"F:\\cache_data\\model_path\\dy\\rfrk\"\n",
    "for col in label_cols_list:\n",
    "    print(col)\n",
    "    # 选取符合条件的数据\n",
    "    pre_data = df[df[f\"{col}_Status\"]=='Normal']\n",
    "    X = pre_data[feature_cols+coord_cols]\n",
    "    y = pre_data[col]\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    # 输出训练集和测试集的形状\n",
    "    print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "    # 模型存放位置,检查是否存在该目录,不存在则创建\n",
    "    temp_dir_path = os.path.join(rf_dir,col)\n",
    "    if not os.path.exists(temp_dir_path):\n",
    "        os.makedirs(temp_dir_path)\n",
    "    # 模型存放路径\n",
    "    save_model_path =os.path.join(temp_dir_path,f\"{col}_rf_model.pkl\") \n",
    "    # 训练模型\n",
    "    train_log = rf_classics(pre_data,col,feature_cols,coord_cols,param_grid,save_model_path)\n",
    "    print(train_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
