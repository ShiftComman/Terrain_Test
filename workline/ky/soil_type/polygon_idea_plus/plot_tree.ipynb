{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import dtreeviz\n",
    "import matplotlib.pyplot as plt\n",
    "from pypinyin import pinyin, lazy_pinyin, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_py(word):\n",
    "    temp = pinyin(word,style=Style.FIRST_LETTER)\n",
    "    result = \"\"\n",
    "    for one_word in [_[0] for _ in temp]:\n",
    "        result+=str(one_word).upper()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "data = pd.read_csv(r\"F:\\cache_data\\zone_ana\\sb\\train_data\\train_20240905.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[\"土类\"] = word_to_py(dataset[\"土类\"])\n",
    "data[\"NEW_TL\"] =data['NEW_TL'].apply(word_to_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"TL_label\"] = data.NEW_TL.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TL_label'] = data['TL_label'].astype('category')\n",
    "data['DLMC'] = data['DLMC'].astype('category')\n",
    "data['MZMC'] = data['MZMC'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data.groupby('TL_label', observed=True)[\"NEW_TL\"].apply(lambda x: list(x.unique())).to_dict()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'NEW_TL'\n",
    "features = ['DLMC','MZMC','Centroid_X','Centroid_Y','aligned_AnalyticalHillshading_MEAN','aligned_ChannelNetworkBaseLevel_MEAN','aligned_ChannelNetworkDistance_MEAN','aligned_ConvergenceIndex_MEAN',\n",
    " 'aligned_Analytical_Hillshading_MEAN','aligned_Aspect_MEAN','aligned_Channel_Network_Base_Level_MEAN','aligned_Channel_Network_Distance_MEAN','aligned_Convergence_Index_MEAN',\n",
    " 'aligned_dem_MEAN','aligned_ETP2022_3_MEAN','aligned_ETP2022_8_MEAN','aligned_ETP2022_mean_MEAN','aligned_evi_MEAN','aligned_LS_Factor_MEAN','aligned_lswi_MEAN','aligned_mndwi_MEAN',\n",
    " 'aligned_ndmi_MEAN','aligned_ndvi_MEAN','aligned_ndwi_MEAN','aligned_NIGHT2022_MEAN','aligned_pca_1_MEAN','aligned_pca_2_MEAN','aligned_Plan_Curvature_MEAN','aligned_PRE2022_3_MEAN',\n",
    " 'aligned_PRE2022_8_MEAN','aligned_PRE2022_mean_MEAN','aligned_Profile_Curvature_MEAN','aligned_Relative_Slope_Position_MEAN','aligned_savi_MEAN','aligned_Slope_MEAN','aligned_TMP2022_3_MEAN',\n",
    " 'aligned_TMP2022_8_MEAN','aligned_TMP2022_mean_MEAN','aligned_Topographic_Wetness_Index_MEAN','aligned_Total_Catchment_Area_MEAN','aligned_Valley_Depth_MEAN','aligned_vari_MEAN',\n",
    " 'MRRTF_MEAN','MRVBF_MEAN','slope_postion_101_smooth_MAJORITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = data[[label]+features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(r\"C:\\Users\\Runker\\Desktop\\TEST.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分离特征和标签\n",
    "X = data[features]  \n",
    "y = data[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先识别数值特征列\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 使用 .loc 将每个数值列的 NaN 值填充为该列的平均值\n",
    "for col in numerical_cols:\n",
    "    X.loc[:, col] = X[col].fillna(X[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 X 是一个 pandas DataFrame\n",
    "# 首先识别分类特征列\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_cols = X.columns.difference(categorical_cols)\n",
    "# 创建一个 ColumnTransformer，它将应用于数据的转换\n",
    "transformers = [\n",
    "    ('num', 'passthrough', numerical_cols),  # 数值列直接传递\n",
    "    ('cat', OneHotEncoder(), categorical_cols)  # 分类列使用独热编码\n",
    "]\n",
    "ct = ColumnTransformer(transformers)\n",
    "\n",
    "# 应用转换\n",
    "X_encoded = ct.fit_transform(X)\n",
    "# 训练决策树模型\n",
    "clf = DecisionTreeClassifier()\n",
    "# 现在 X_encoded 包含了编码后的特征，可以用于训练决策树\n",
    "clf = clf.fit(X_encoded, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 可视化决策树\n",
    "viz = dtreeviz.model(clf, \n",
    "               X_encoded, \n",
    "               y, \n",
    "               target_name=label, \n",
    "               feature_names=X_encoded.columns, \n",
    "               class_names=list(clf.classes_))\n",
    "\n",
    "# 显示决策树\n",
    "viz.view()\n",
    "\n",
    "# 如果需要保存决策树图像，可以使用以下代码\n",
    "# viz.save(\"decision_tree.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Runker\\Desktop\\TEST.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode text columns to numerical values\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Impute missing values in numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[data.select_dtypes(include=['float64', 'int64']).columns] = num_imputer.fit_transform(data.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop('NEW_TL', axis=1)\n",
    "y = data['NEW_TL']\n",
    "\n",
    "# Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20,10))\n",
    "tree.plot_tree(dt_model, feature_names=X.columns, class_names=label_encoders['NEW_TL'].classes_, filled=True, rounded=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import dtreeviz\n",
    "import warnings\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Runker\\Desktop\\TEST.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode text columns to numerical values\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object','category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Impute missing values in numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[data.select_dtypes(include=['float64', 'int64']).columns] = num_imputer.fit_transform(data.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop('NEW_TL', axis=1)\n",
    "y = data['NEW_TL']\n",
    "\n",
    "# Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "\n",
    "# Visualize the decision tree using dtreeviz\n",
    "viz = dtreeviz.model(dt_model, X, y, target_name='NEW_TL', feature_names=X.columns, class_names=list(label_encoders['NEW_TL'].classes_))\n",
    "\n",
    "# Display the visualization\n",
    "viz.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import dtreeviz\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Runker\\Desktop\\TEST.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode text columns to numerical values\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object', 'category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Impute missing values in numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[data.select_dtypes(include=['float64', 'int64']).columns] = num_imputer.fit_transform(data.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop('NEW_TL', axis=1)\n",
    "y = data['NEW_TL']\n",
    "\n",
    "# Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Extract feature names and class names as lists\n",
    "feature_names = X.columns.tolist()\n",
    "class_names = [str(cls) for cls in label_encoders['NEW_TL'].classes_]\n",
    "\n",
    "# Visualize the decision tree using dtreeviz\n",
    "viz = dtreeviz.model(dt_model, X, y, target_name='NEW_TL', feature_names=feature_names, class_names=class_names)\n",
    "\n",
    "# Display the visualization\n",
    "viz.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import warnings\n",
    "from plotly.offline import plot\n",
    "import plotly.io as pio\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Runker\\Desktop\\TEST.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Encode text columns to numerical values\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object', 'category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Impute missing values in numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[data.select_dtypes(include=['float64', 'int64']).columns] = num_imputer.fit_transform(data.select_dtypes(include=['float64', 'int64']))\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop('NEW_TL', axis=1)\n",
    "y = data['NEW_TL']\n",
    "\n",
    "# Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Extract tree structure\n",
    "n_nodes = dt_model.tree_.node_count\n",
    "children_left = dt_model.tree_.children_left\n",
    "children_right = dt_model.tree_.children_right\n",
    "feature = dt_model.tree_.feature\n",
    "threshold = dt_model.tree_.threshold\n",
    "value = dt_model.tree_.value\n",
    "\n",
    "# Create node labels\n",
    "feature_names = X.columns.tolist()\n",
    "class_names = [str(cls) for cls in label_encoders['NEW_TL'].classes_]\n",
    "\n",
    "def create_node_label(node, feature, threshold, value):\n",
    "    if feature[node] != -2:  # not a leaf node\n",
    "        return f\"{feature_names[feature[node]]} <= {threshold[node]:.2f}\"\n",
    "    else:\n",
    "        class_counts = value[node][0]\n",
    "        majority_class = class_names[np.argmax(class_counts)]\n",
    "        return f\"Class: {majority_class}\"\n",
    "\n",
    "node_labels = [create_node_label(i, feature, threshold, value) for i in range(n_nodes)]\n",
    "\n",
    "# Create edges\n",
    "edges = []\n",
    "for i in range(n_nodes):\n",
    "    if children_left[i] != children_right[i]:\n",
    "        edges.extend([(i, children_left[i]), (i, children_right[i])])\n",
    "\n",
    "# Function to compute node depths\n",
    "def compute_node_depths(n_nodes, children_left, children_right):\n",
    "    node_depth = np.zeros(n_nodes, dtype=np.int64)\n",
    "    stack = [(0, 0)]  # start with the root node id and its depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "        if children_left[node_id] != children_right[node_id]:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "    return node_depth\n",
    "\n",
    "# Compute node depths\n",
    "node_depths = compute_node_depths(n_nodes, children_left, children_right)\n",
    "\n",
    "# Create node coordinates\n",
    "def hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None, parsed = []):\n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root, parsed = parsed)\n",
    "        return pos\n",
    "\n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "pos = hierarchy_pos(G, 0)\n",
    "\n",
    "# Create Plotly figure\n",
    "edge_trace = go.Scatter(\n",
    "    x=[], y=[], line=dict(width=0.5, color='#888'), hoverinfo='none', mode='lines')\n",
    "\n",
    "for edge in edges:\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_trace['x'] += tuple([x0, x1, None])\n",
    "    edge_trace['y'] += tuple([y0, y1, None])\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=[], y=[], text=[], mode='markers+text', textposition=\"top center\",\n",
    "    hoverinfo='text', marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=10,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='节点深度',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2))\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_trace['x'] += tuple([x])\n",
    "    node_trace['y'] += tuple([y])\n",
    "\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_trace['marker']['color'] += tuple([node_depths[node]])\n",
    "    node_info = f'节点 {node}<br>{node_labels[node]}<br>深度: {node_depths[node]}'\n",
    "    node_trace['text'] += tuple([node_info])\n",
    "\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>决策树可视化',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[ dict(\n",
    "                    text=\"基于用户数据的决策树\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002 ) ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "# 保存为交互式 HTML 文件\n",
    "plot(fig, filename='decision_tree_interactive.html', auto_open=False)\n",
    "# Display the visualization\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "import warnings\n",
    "\n",
    "# Ignore specific warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Glyph .* missing from current font.\")\n",
    "\n",
    "# Load the data\n",
    "file_path = r\"C:\\Users\\Runker\\Desktop\\TEST.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Identify categorical and continuous variables\n",
    "categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "continuous_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Encode text columns to numerical values\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Impute missing values in numerical columns with the median\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "data[continuous_columns] = num_imputer.fit_transform(data[continuous_columns])\n",
    "\n",
    "# Split data into features and target variable\n",
    "X = data.drop('NEW_TL', axis=1)\n",
    "y = data['NEW_TL']\n",
    "\n",
    "# Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X, y)\n",
    "\n",
    "# Extract tree structure\n",
    "n_nodes = dt_model.tree_.node_count\n",
    "children_left = dt_model.tree_.children_left\n",
    "children_right = dt_model.tree_.children_right\n",
    "feature = dt_model.tree_.feature\n",
    "threshold = dt_model.tree_.threshold\n",
    "value = dt_model.tree_.value\n",
    "\n",
    "# Create node labels\n",
    "feature_names = X.columns.tolist()\n",
    "class_names = [str(cls) for cls in label_encoders['NEW_TL'].classes_]\n",
    "\n",
    "def create_node_label(node, feature, threshold, value):\n",
    "    if feature[node] != -2:  # not a leaf node\n",
    "        feature_name = feature_names[feature[node]]\n",
    "        if feature_name in categorical_columns:\n",
    "            return f\"[类别] {feature_name} = {threshold[node]:.0f}\"\n",
    "        else:\n",
    "            return f\"[连续] {feature_name} <= {threshold[node]:.2f}\"\n",
    "    else:\n",
    "        class_counts = value[node][0]\n",
    "        majority_class = class_names[np.argmax(class_counts)]\n",
    "        return f\"Class: {majority_class}\"\n",
    "\n",
    "node_labels = [create_node_label(i, feature, threshold, value) for i in range(n_nodes)]\n",
    "\n",
    "# Create edges\n",
    "edges = []\n",
    "for i in range(n_nodes):\n",
    "    if children_left[i] != children_right[i]:\n",
    "        edges.extend([(i, children_left[i]), (i, children_right[i])])\n",
    "\n",
    "# Function to compute node depths\n",
    "def compute_node_depths(n_nodes, children_left, children_right):\n",
    "    node_depth = np.zeros(n_nodes, dtype=np.int64)\n",
    "    stack = [(0, 0)]  # start with the root node id and its depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "        if children_left[node_id] != children_right[node_id]:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "    return node_depth\n",
    "\n",
    "# Compute node depths\n",
    "node_depths = compute_node_depths(n_nodes, children_left, children_right)\n",
    "\n",
    "# Create node coordinates\n",
    "def hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5):\n",
    "    def _hierarchy_pos(G, root, width=1., vert_gap = 0.2, vert_loc = 0, xcenter = 0.5, pos = None, parent = None, parsed = []):\n",
    "        if pos is None:\n",
    "            pos = {root:(xcenter,vert_loc)}\n",
    "        else:\n",
    "            pos[root] = (xcenter, vert_loc)\n",
    "        children = list(G.neighbors(root))\n",
    "        if not isinstance(G, nx.DiGraph) and parent is not None:\n",
    "            children.remove(parent)  \n",
    "        if len(children)!=0:\n",
    "            dx = width/len(children) \n",
    "            nextx = xcenter - width/2 - dx/2\n",
    "            for child in children:\n",
    "                nextx += dx\n",
    "                pos = _hierarchy_pos(G,child, width = dx, vert_gap = vert_gap, \n",
    "                                    vert_loc = vert_loc-vert_gap, xcenter=nextx,\n",
    "                                    pos=pos, parent = root, parsed = parsed)\n",
    "        return pos\n",
    "\n",
    "    return _hierarchy_pos(G, root, width, vert_gap, vert_loc, xcenter)\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(edges)\n",
    "pos = hierarchy_pos(G, 0)\n",
    "\n",
    "# Create Plotly figure\n",
    "edge_trace = go.Scatter(\n",
    "    x=[], y=[], line=dict(width=0.5, color='#888'), hoverinfo='none', mode='lines')\n",
    "\n",
    "for edge in edges:\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_trace['x'] += tuple([x0, x1, None])\n",
    "    edge_trace['y'] += tuple([y0, y1, None])\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=[], y=[], text=[], mode='markers+text', textposition=\"top center\",\n",
    "    hoverinfo='text', marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlOrRd',\n",
    "        reversescale=True,\n",
    "        color=[],\n",
    "        size=15,\n",
    "        colorbar=dict(\n",
    "            thickness=15,\n",
    "            title='节点深度',\n",
    "            xanchor='left',\n",
    "            titleside='right'\n",
    "        ),\n",
    "        line_width=2,\n",
    "        symbol=[],\n",
    "    ))\n",
    "\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_trace['x'] += tuple([x])\n",
    "    node_trace['y'] += tuple([y])\n",
    "\n",
    "for node, adjacencies in enumerate(G.adjacency()):\n",
    "    node_trace['marker']['color'] += tuple([node_depths[node]])\n",
    "    if feature[node] != -2:  # not a leaf node\n",
    "        feature_name = feature_names[feature[node]]\n",
    "        if feature_name in categorical_columns:\n",
    "            node_trace['marker']['symbol'] += tuple(['square'])\n",
    "        else:\n",
    "            node_trace['marker']['symbol'] += tuple(['circle'])\n",
    "    else:\n",
    "        node_trace['marker']['symbol'] += tuple(['diamond'])\n",
    "    \n",
    "    node_info = f'节点 {node}<br>{node_labels[node]}<br>深度: {node_depths[node]}'\n",
    "    node_trace['text'] += tuple([node_info])\n",
    "\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "             layout=go.Layout(\n",
    "                title='<br>决策树可视化 (区分变量类型)',\n",
    "                titlefont_size=16,\n",
    "                showlegend=False,\n",
    "                hovermode='closest',\n",
    "                margin=dict(b=20,l=5,r=5,t=40),\n",
    "                annotations=[\n",
    "                    dict(text=\"基于用户数据的决策树\", showarrow=False, xref=\"paper\", yref=\"paper\", x=0.005, y=-0.002),\n",
    "                    dict(text=\"○ 连续变量  □ 类别变量  ◇ 叶节点\", showarrow=False, xref=\"paper\", yref=\"paper\", x=0.5, y=1.05, xanchor='center', yanchor='bottom')\n",
    "                ],\n",
    "                xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "\n",
    "# Display the visualization\n",
    "fig.show()\n",
    "\n",
    "# Save as interactive HTML file\n",
    "from plotly.offline import plot\n",
    "plot(fig, filename='decision_tree_variable_types.html', auto_open=False)\n",
    "\n",
    "# Save as static PNG file\n",
    "import plotly.io as pio\n",
    "pio.write_image(fig, 'decision_tree_variable_types.png')\n",
    "\n",
    "print(\"可视化已保存为 'decision_tree_variable_types.html' 和 'decision_tree_variable_types.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
