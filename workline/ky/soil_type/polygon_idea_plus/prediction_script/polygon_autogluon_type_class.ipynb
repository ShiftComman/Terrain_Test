{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor,export_graphviz\n",
    "import graphviz\n",
    "import dtreeviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn import tree\n",
    "from pypinyin import pinyin, lazy_pinyin, Style\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件夹已存在\n"
     ]
    }
   ],
   "source": [
    "# autogluon保存路径\n",
    "model_path = r\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\"\n",
    "# 检查路径是否存在，否则便创建\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "else:\n",
    "    print(\"文件夹已存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"F:\\cache_data\\zone_ana\\ky\\train_data\\pca_soil_type_train_point.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 筛选满足条件的记录\n",
    "# pr = dataset[(dataset['MZMC'] == \"河流冲积物\") & (dataset['NEW_TZ'] == \"中层砂质灰潮土\")]\n",
    "\n",
    "# # 如果筛选出的记录少于 5 个，我们将修改所有记录\n",
    "# num_to_change = min(5, len(pr))\n",
    "\n",
    "# if num_to_change > 0:\n",
    "#     # 随机选择 num_to_change 个索引\n",
    "#     random_indices = np.random.choice(pr.index, num_to_change, replace=False)\n",
    "#     # 修改选中记录的 NEW_TZ 值\n",
    "#     dataset.loc[random_indices, 'NEW_TZ'] = \"厚层砂质灰潮土\"\n",
    "\n",
    "#     print(f\"已随机修改 {num_to_change} 条记录的 NEW_TZ 值为 '厚层砂质灰潮土'\")\n",
    "# else:\n",
    "#     print(\"没有找到满足条件的记录\")\n",
    "\n",
    "# # 验证修改结果\n",
    "# modified_records = dataset[(dataset['MZMC'] == \"河流冲积物\") & (dataset['NEW_TZ'] == \"厚层砂质灰潮土\")]\n",
    "# print(f\"修改后，符合新条件的记录数：{len(modified_records)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['point_id',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'TL',\n",
       " 'YL',\n",
       " 'TS',\n",
       " 'TZ',\n",
       " 'label',\n",
       " 'LON',\n",
       " 'LAT',\n",
       " 'DH',\n",
       " 'NEW_TZ',\n",
       " 'DL',\n",
       " 'DZ',\n",
       " 'PW',\n",
       " 'LB',\n",
       " 'analyticalhillshading',\n",
       " 'aspect',\n",
       " 'bio',\n",
       " 'channelnetworkbaselevel',\n",
       " 'channelnetworkdistance',\n",
       " 'closeddepressions',\n",
       " 'contrast',\n",
       " 'convergenceindex',\n",
       " 'correlation',\n",
       " 'dem',\n",
       " 'dissimilarity',\n",
       " 'dl',\n",
       " 'dz',\n",
       " 'entropy',\n",
       " 'etp2022_1',\n",
       " 'etp2022_10',\n",
       " 'etp2022_11',\n",
       " 'etp2022_12',\n",
       " 'etp2022_2',\n",
       " 'etp2022_3',\n",
       " 'etp2022_4',\n",
       " 'etp2022_5',\n",
       " 'etp2022_6',\n",
       " 'etp2022_7',\n",
       " 'etp2022_8',\n",
       " 'etp2022_9',\n",
       " 'etp2022_mean',\n",
       " 'evi',\n",
       " 'homogeneity',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'lsfactor',\n",
       " 'lswi',\n",
       " 'mean',\n",
       " 'mndwi',\n",
       " 'mrttf',\n",
       " 'mrvbf',\n",
       " 'ndmi',\n",
       " 'ndvi',\n",
       " 'ndwi',\n",
       " 'night2022',\n",
       " 'pc1',\n",
       " 'pc2',\n",
       " 'plancurvature',\n",
       " 'pre',\n",
       " 'pre2022_1',\n",
       " 'pre2022_10',\n",
       " 'pre2022_11',\n",
       " 'pre2022_12',\n",
       " 'pre2022_2',\n",
       " 'pre2022_3',\n",
       " 'pre2022_4',\n",
       " 'pre2022_5',\n",
       " 'pre2022_6',\n",
       " 'pre2022_7',\n",
       " 'pre2022_8',\n",
       " 'pre2022_9',\n",
       " 'pre2022_mean',\n",
       " 'profilecurvature',\n",
       " 'relativeslopeposition',\n",
       " 'savi',\n",
       " 'secondmoment',\n",
       " 'slope',\n",
       " 'slope_postion',\n",
       " 'sra',\n",
       " 'tmp',\n",
       " 'tmp2022_1',\n",
       " 'tmp2022_10',\n",
       " 'tmp2022_11',\n",
       " 'tmp2022_12',\n",
       " 'tmp2022_2',\n",
       " 'tmp2022_3',\n",
       " 'tmp2022_4',\n",
       " 'tmp2022_5',\n",
       " 'tmp2022_6',\n",
       " 'tmp2022_7',\n",
       " 'tmp2022_8',\n",
       " 'tmp2022_9',\n",
       " 'tmp2022_mean',\n",
       " 'topographicpositionindex',\n",
       " 'topographicwetnessindex',\n",
       " 'totalcatchmentarea',\n",
       " 'tpi3_a',\n",
       " 'tpi5_a',\n",
       " 'twi3_a',\n",
       " 'twi5_a',\n",
       " 'valleydepth',\n",
       " 'vap',\n",
       " 'vari',\n",
       " 'variance',\n",
       " 'wind']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_ for _ in dataset.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6689, 107)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"TZ_label\"] = dataset.NEW_TZ.astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['dl'] = dataset['dl'].astype('category')\n",
    "dataset['dz'] = dataset['dz'].astype('category')\n",
    "dataset['slope_postion'] = dataset['slope_postion'].astype('category')\n",
    "dataset['TZ_label'] = dataset['TZ_label'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '中层壤质中性紫色土', 1: '中层壤质灰潮土', 2: '中层壤质黄色石灰土', 3: '中层壤质黑色石灰土', 4: '中层暗泥质黄壤', 5: '中层泥质黄壤', 6: '中层泥质黄壤性土', 7: '中层灰泥质黄壤', 8: '中层砂泥质黄壤', 9: '中层砂质中性紫色土', 10: '中层砂质酸性紫色土', 11: '中层硅质黄壤', 12: '中层红泥质黄壤', 13: '中层黏质黄色石灰土', 14: '厚层壤质灰潮土', 15: '厚层壤质黄色石灰土', 16: '厚层暗泥质黄壤', 17: '厚层泥质黄壤', 18: '厚层泥质黄壤性土', 19: '厚层灰泥质黄壤', 20: '厚层砂泥质黄壤', 21: '厚层硅质黄壤', 22: '厚层红泥质黄壤', 23: '浅石灰泥田', 24: '渗紫泥田', 25: '潮泥田', 26: '潮泥砂田', 27: '石灰泥田', 28: '紫泥田', 29: '腐中层壤质中性紫色土', 30: '腐中层壤质黄色石灰土', 31: '腐中层壤质黑色石灰土', 32: '腐中层暗泥质黄壤', 33: '腐中层泥质黄壤', 34: '腐中层泥质黄棕壤', 35: '腐中层灰泥质黄壤', 36: '腐中层灰泥质黄棕壤', 37: '腐中层砂泥质黄壤', 38: '腐中层砂泥质黄棕壤', 39: '腐中层砂质中性紫色土', 40: '腐中层砂质灰潮土', 41: '腐中层砂质酸性紫色土', 42: '腐中层硅质黄壤', 43: '腐中层红泥质黄壤', 44: '腐中层黏质黄色石灰土', 45: '腐厚层壤质黄色石灰土', 46: '腐厚层壤质黑色石灰土', 47: '腐厚层暗泥质黄壤', 48: '腐厚层泥质黄壤', 49: '腐厚层泥质黄棕壤', 50: '腐厚层灰泥质黄壤', 51: '腐厚层灰泥质黄棕壤', 52: '腐厚层砂泥质黄壤', 53: '腐厚层砂质灰潮土', 54: '腐厚层砂质酸性紫色土', 55: '腐厚层硅质黄壤', 56: '腐厚层硅质黄壤土', 57: '腐厚层硅黄壤', 58: '腐厚层红泥质黄壤', 59: '腐薄层壤质黄色石灰土', 60: '腐薄层壤质黑色石灰土', 61: '腐薄层暗泥质黄壤', 62: '腐薄层泥质黄壤', 63: '腐薄层灰泥质黄壤', 64: '腐薄层砂泥质黄壤', 65: '腐薄层砂质酸性紫色土', 66: '腐薄层硅质黄壤', 67: '薄层壤质黄色石灰土', 68: '薄层壤质黑色石灰土', 69: '薄层泥质黄壤', 70: '薄层泥质黄壤性土', 71: '薄层灰泥质黄壤', 72: '薄层砂泥质黄壤', 73: '薄层硅质黄壤', 74: '轻漂白粉泥田', 75: '轻漂石灰泥田', 76: '轻漂鳝泥田', 77: '青石灰泥田', 78: '黄暗泥田', 79: '黄浅白粉泥田', 80: '黄浅砂泥田', 81: '黄浅鳝泥田', 82: '黄渗暗泥田', 83: '黄渗红泥田', 84: '黄灰泥田', 85: '黄白粉泥田', 86: '黄石灰泥田', 87: '黄砂泥田', 88: '黄红泥田', 89: '黄青砂泥田', 90: '黄青鳝泥田', 91: '黄鳝泥田'}\n"
     ]
    }
   ],
   "source": [
    "result = dataset.groupby('TZ_label', observed=True)[\"NEW_TZ\"].apply(lambda x: list(x.unique())).to_dict()\n",
    "for one_type in result:\n",
    "    result[one_type] = result[one_type][0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存映射关系\n",
    "with open(r'D:\\worker_code\\Terrain_Test\\data\\soil_dict_20241216_ky.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LB</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>自然土</th>\n",
       "      <td>3884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>非自然土</th>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>水稻土</th>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "LB         \n",
       "自然土    3884\n",
       "非自然土   2059\n",
       "水稻土     746"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看地类类别\n",
    "tdlylx_df = pd.DataFrame(dataset['LB'].value_counts())\n",
    "tdlylx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>乔木林地</th>\n",
       "      <td>2585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>旱地</th>\n",
       "      <td>1774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>灌木林地</th>\n",
       "      <td>1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>水田</th>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>果园</th>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他林地</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>茶园</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他草地</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>设施农用地</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>水浇地</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>其他园地</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>竹林地</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>裸岩石砾地</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "DL          \n",
       "乔木林地    2585\n",
       "旱地      1774\n",
       "灌木林地    1178\n",
       "水田       737\n",
       "果园       201\n",
       "其他林地      69\n",
       "茶园        63\n",
       "其他草地      49\n",
       "设施农用地     15\n",
       "水浇地        9\n",
       "其他园地       5\n",
       "竹林地        3\n",
       "裸岩石砾地      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看地类类别\n",
    "dl_df = pd.DataFrame(dataset['DL'].value_counts())\n",
    "dl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>白云岩</th>\n",
       "      <td>2306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>灰岩</th>\n",
       "      <td>1439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>泥(页)岩</th>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>页岩</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>粘土岩</th>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>砂页岩</th>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>砂岩</th>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>紫色砂岩</th>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>变余凝灰岩</th>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>玄武岩</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>河流冲积物</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>变余砂岩</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>第四纪粘土</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>板岩</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>砾岩</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count\n",
       "DZ          \n",
       "白云岩     2306\n",
       "灰岩      1439\n",
       "泥(页)岩    627\n",
       "页岩       599\n",
       "粘土岩      383\n",
       "砂页岩      333\n",
       "砂岩       310\n",
       "紫色砂岩     243\n",
       "变余凝灰岩    133\n",
       "玄武岩      118\n",
       "河流冲积物     79\n",
       "变余砂岩      71\n",
       "第四纪粘土     37\n",
       "板岩         6\n",
       "砾岩         5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看母质类别\n",
    "mz_df = pd.DataFrame(dataset['DZ'].value_counts())\n",
    "mz_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂岩、变余砂岩土种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄白粉泥田', '黄浅白粉泥田', '轻漂白粉泥田'], dtype=object),)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂岩类水稻土数据\n",
    "sy_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                      & ((dataset['DZ'] == '砂岩') | (dataset['DZ'] == '变余砂岩'))]\n",
    "pd.unique(sy_sdt_data['NEW_TZ']),#pd.unique(sy_sdt_data['NEW_TS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层硅质黄壤', '薄层硅质黄壤', '厚层硅质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛砂岩选非自然土数据  \n",
    "sy_fzrt_data = dataset[(dataset['LB']=='非自然土') \n",
    "                       & ((dataset['DZ'] == '砂岩') | (dataset['DZ'] == '变余砂岩'))]\n",
    "pd.unique(sy_fzrt_data['NEW_TZ']),#pd.unique(sy_fzrt_data['NEW_TS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层硅质黄壤', '腐薄层硅质黄壤', '腐厚层硅质黄壤', '腐厚层硅质黄壤土', '腐厚层硅黄壤'],\n",
       "       dtype=object),)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选自然土数据\n",
    "sy_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                   & ((dataset['DZ'] == '砂岩') | (dataset['DZ'] == '变余砂岩'))]\n",
    "pd.unique(sy_zrt_data['NEW_TZ']),#pd.unique(sy_zrt_data['NEW_TS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 碳酸岩土种"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['石灰泥田', '青石灰泥田', '黄灰泥田', '浅石灰泥田', '轻漂石灰泥田', '黄石灰泥田'], dtype=object),)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩水稻土数据\n",
    "tsy_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                      & ((dataset['DZ'] == '白云岩')|(dataset['DZ'] == '灰岩') | (dataset['DZ'] == '变余凝灰岩'))]\n",
    "pd.unique(tsy_sdt_data['NEW_TZ']),#pd.unique(tsy_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层灰泥质黄壤', '薄层灰泥质黄壤', '厚层灰泥质黄壤', '中层壤质黄色石灰土', '薄层壤质黄色石灰土',\n",
       "        '薄层壤质黑色石灰土', '厚层壤质黄色石灰土', '中层壤质黑色石灰土', '中层黏质黄色石灰土'], dtype=object),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩选非自然土数据\n",
    "tsy_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '白云岩')|(dataset['DZ'] == '灰岩') | (dataset['DZ'] == '变余凝灰岩'))]\n",
    "\n",
    "pd.unique(tsy_fzrt_data['NEW_TZ']),#pd.unique(tsy_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层灰泥质黄壤', '腐中层壤质黄色石灰土', '腐厚层灰泥质黄壤', '腐薄层壤质黄色石灰土', '腐薄层灰泥质黄壤',\n",
       "        '腐薄层壤质黑色石灰土', '腐厚层壤质黄色石灰土', '腐中层壤质黑色石灰土', '腐中层黏质黄色石灰土',\n",
       "        '腐厚层壤质黑色石灰土', '腐中层灰泥质黄棕壤', '腐厚层灰泥质黄棕壤'], dtype=object),)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选碳酸岩自然土数据\n",
    "\n",
    "tsy_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '白云岩')|(dataset['DZ'] == '灰岩') | (dataset['DZ'] == '变余凝灰岩'))]\n",
    "pd.unique(tsy_zrt_data['NEW_TZ']),#pd.unique(tsy_zrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四系红粘土"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄红泥田', '黄渗红泥田'], dtype=object),)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土水稻土数据\n",
    "hnt_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & ((dataset['DZ'] == '第四纪粘土'))]\n",
    "pd.unique(hnt_sdt_data['NEW_TZ']),#pd.unique(hnt_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层红泥质黄壤', '厚层红泥质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土非自然土数据\n",
    "hnt_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '第四纪粘土'))]\n",
    "pd.unique(hnt_fzrt_data['NEW_TZ']),#pd.unique(hnt_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层红泥质黄壤', '腐厚层红泥质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选第四系红粘土自然土数据\n",
    "hnt_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '第四纪粘土'))]\n",
    "pd.unique(hnt_zrt_data['NEW_TZ']),#pd.unique(hnt_zrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泥(页)岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄鳝泥田', '黄浅鳝泥田', '黄青鳝泥田', '轻漂鳝泥田'], dtype=object),)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩水稻土数据\n",
    "nyy_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & ((dataset['DZ'] == '泥(页)岩') | (dataset['DZ'] == '页岩') | (dataset['DZ'] == '粘土岩') | (dataset['DZ'] == '板岩'))]\n",
    "pd.unique(nyy_sdt_data['NEW_TZ']),#pd.unique(nyy_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层泥质黄壤', '厚层泥质黄壤', '薄层泥质黄壤', '薄层泥质黄壤性土', '中层泥质黄壤性土', '厚层泥质黄壤性土'],\n",
       "       dtype=object),)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩非自然土数据\n",
    "nyy_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '泥(页)岩') | (dataset['DZ'] == '页岩') | (dataset['DZ'] == '粘土岩') | (dataset['DZ'] == '板岩'))]\n",
    "pd.unique(nyy_fzrt_data['NEW_TZ']),#pd.unique(nyy_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层泥质黄壤', '腐厚层泥质黄壤', '腐薄层泥质黄壤', '腐中层泥质黄棕壤', '腐厚层泥质黄棕壤'],\n",
       "       dtype=object),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选泥(页)岩自然土数据    \n",
    "nyy_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '泥(页)岩') | (dataset['DZ'] == '页岩') | (dataset['DZ'] == '粘土岩') | (dataset['DZ'] == '板岩'))]\n",
    "pd.unique(nyy_zrt_data['NEW_TZ']),#pd.unique(nyy_zrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 紫红色砂页岩\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['紫泥田', '渗紫泥田'], dtype=object),)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩水稻土数据\n",
    "zhsyy_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & ((dataset['DZ'] == '紫色砂岩'))]\n",
    "pd.unique(zhsyy_sdt_data['NEW_TZ']),#pd.unique(zhsyy_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层砂质酸性紫色土', '中层壤质中性紫色土', '中层砂质中性紫色土'], dtype=object),)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩非自然土数据\n",
    "zhsyy_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '紫色砂岩'))]\n",
    "pd.unique(zhsyy_fzrt_data['NEW_TZ']),#pd.unique(zhsyy_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层壤质中性紫色土', '腐中层砂质酸性紫色土', '腐中层砂质中性紫色土', '腐薄层砂质酸性紫色土',\n",
       "        '腐厚层砂质酸性紫色土'], dtype=object),)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选紫红色砂页岩自然土数据\n",
    "zhsyy_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '紫色砂岩'))]\n",
    "pd.unique(zhsyy_zrt_data['NEW_TZ']),#pd.unique(zhsyy_zrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 河流冲积物"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['潮泥田', '潮泥砂田'], dtype=object),)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选河流冲积物水稻土数据\n",
    "hlcjw_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & (dataset['DZ'] == '河流冲积物')]\n",
    "pd.unique(hlcjw_sdt_data['NEW_TZ']),#pd.unique(hlcjw_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['厚层壤质灰潮土', '中层壤质灰潮土'], dtype=object),)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选河流冲积物非自然土数据\n",
    "hlcjw_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & (dataset['DZ'] == '河流冲积物')]\n",
    "pd.unique(hlcjw_fzrt_data['NEW_TZ']),#pd.unique(hlcjw_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层砂质灰潮土', '腐厚层砂质灰潮土'], dtype=object),)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选河流冲积物自然土数据\n",
    "hlcjw_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & (dataset['DZ'] == '河流冲积物')]\n",
    "pd.unique(hlcjw_zrt_data['NEW_TZ']),#pd.unique(hlcjw_zrt_data['NEW_TS']),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂页岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄砂泥田', '黄浅砂泥田', '黄青砂泥田'], dtype=object),)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩水稻土数据\n",
    "syy_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & ((dataset['DZ'] == '砂页岩') | (dataset['DZ'] == '砾岩'))]\n",
    "pd.unique(syy_sdt_data['NEW_TZ']),#pd.unique(syy_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层砂泥质黄壤', '厚层砂泥质黄壤', '薄层砂泥质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩非自然土数据\n",
    "syy_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '砂页岩') | (dataset['DZ'] == '砾岩'))]\n",
    "pd.unique(syy_fzrt_data['NEW_TZ']),#pd.unique(syy_fzrt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层砂泥质黄壤', '腐厚层砂泥质黄壤', '腐薄层砂泥质黄壤', '腐中层砂泥质黄棕壤'], dtype=object),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选砂页岩物自然土数据\n",
    "syy_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '砂页岩') | (dataset['DZ'] == '砾岩'))]\n",
    "pd.unique(syy_zrt_data['NEW_TZ']),#pd.unique(syy_zrt_data['NEW_TS']),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 玄武岩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['黄渗暗泥田', '黄暗泥田'], dtype=object),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选玄武岩水稻土数据\n",
    "xw_sdt_data = dataset[(dataset['LB']=='水稻土')\n",
    "                       & ((dataset['DZ'] == '玄武岩'))]\n",
    "pd.unique(xw_sdt_data['NEW_TZ']),#pd.unique(xw_sdt_data['NEW_TS']),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['腐中层暗泥质黄壤', '腐厚层暗泥质黄壤', '腐薄层暗泥质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选玄武岩自然土数据\n",
    "xw_zrt_data = dataset[(dataset['LB']=='自然土')\n",
    "                       & ((dataset['DZ'] == '玄武岩'))]\n",
    "pd.unique(xw_zrt_data['NEW_TZ']),#pd.unique(xw_zrt_data['NEW_TS']),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['中层暗泥质黄壤', '厚层暗泥质黄壤'], dtype=object),)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选玄武岩非自然土数据\n",
    "xw_fzrt_data = dataset[(dataset['LB']=='非自然土')\n",
    "                       & ((dataset['DZ'] == '玄武岩'))]\n",
    "pd.unique(xw_fzrt_data['NEW_TZ']),#pd.unique(xw_fzrt_data['NEW_TS']),\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['point_id',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'TL',\n",
       " 'YL',\n",
       " 'TS',\n",
       " 'TZ',\n",
       " 'label',\n",
       " 'LON',\n",
       " 'LAT',\n",
       " 'DH',\n",
       " 'NEW_TZ',\n",
       " 'DL',\n",
       " 'DZ',\n",
       " 'PW',\n",
       " 'LB',\n",
       " 'analyticalhillshading',\n",
       " 'aspect',\n",
       " 'bio',\n",
       " 'channelnetworkbaselevel',\n",
       " 'channelnetworkdistance',\n",
       " 'closeddepressions',\n",
       " 'contrast',\n",
       " 'convergenceindex',\n",
       " 'correlation',\n",
       " 'dem',\n",
       " 'dissimilarity',\n",
       " 'dl',\n",
       " 'dz',\n",
       " 'entropy',\n",
       " 'etp2022_1',\n",
       " 'etp2022_10',\n",
       " 'etp2022_11',\n",
       " 'etp2022_12',\n",
       " 'etp2022_2',\n",
       " 'etp2022_3',\n",
       " 'etp2022_4',\n",
       " 'etp2022_5',\n",
       " 'etp2022_6',\n",
       " 'etp2022_7',\n",
       " 'etp2022_8',\n",
       " 'etp2022_9',\n",
       " 'etp2022_mean',\n",
       " 'evi',\n",
       " 'homogeneity',\n",
       " 'lat',\n",
       " 'lon',\n",
       " 'lsfactor',\n",
       " 'lswi',\n",
       " 'mean',\n",
       " 'mndwi',\n",
       " 'mrttf',\n",
       " 'mrvbf',\n",
       " 'ndmi',\n",
       " 'ndvi',\n",
       " 'ndwi',\n",
       " 'night2022',\n",
       " 'pc1',\n",
       " 'pc2',\n",
       " 'plancurvature',\n",
       " 'pre',\n",
       " 'pre2022_1',\n",
       " 'pre2022_10',\n",
       " 'pre2022_11',\n",
       " 'pre2022_12',\n",
       " 'pre2022_2',\n",
       " 'pre2022_3',\n",
       " 'pre2022_4',\n",
       " 'pre2022_5',\n",
       " 'pre2022_6',\n",
       " 'pre2022_7',\n",
       " 'pre2022_8',\n",
       " 'pre2022_9',\n",
       " 'pre2022_mean',\n",
       " 'profilecurvature',\n",
       " 'relativeslopeposition',\n",
       " 'savi',\n",
       " 'secondmoment',\n",
       " 'slope',\n",
       " 'slope_postion',\n",
       " 'sra',\n",
       " 'tmp',\n",
       " 'tmp2022_1',\n",
       " 'tmp2022_10',\n",
       " 'tmp2022_11',\n",
       " 'tmp2022_12',\n",
       " 'tmp2022_2',\n",
       " 'tmp2022_3',\n",
       " 'tmp2022_4',\n",
       " 'tmp2022_5',\n",
       " 'tmp2022_6',\n",
       " 'tmp2022_7',\n",
       " 'tmp2022_8',\n",
       " 'tmp2022_9',\n",
       " 'tmp2022_mean',\n",
       " 'topographicpositionindex',\n",
       " 'topographicwetnessindex',\n",
       " 'totalcatchmentarea',\n",
       " 'tpi3_a',\n",
       " 'tpi5_a',\n",
       " 'twi3_a',\n",
       " 'twi5_a',\n",
       " 'valleydepth',\n",
       " 'vap',\n",
       " 'vari',\n",
       " 'variance',\n",
       " 'wind',\n",
       " 'TZ_label']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_List = [_ for _ in dataset.columns]\n",
    "columns_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_use = ['analyticalhillshading','aspect','channelnetworkbaselevel','channelnetworkdistance',\n",
    " 'convergenceindex','dem','dz','dl','etp2022_1','etp2022_10','etp2022_11','etp2022_12','etp2022_2','etp2022_3',\n",
    " 'etp2022_4','etp2022_5','etp2022_6','etp2022_7','etp2022_8','etp2022_9','etp2022_mean','evi','lat','lon','lswi',\n",
    " 'lsfactor','mndwi','mrttf','mrvbf','ndmi','ndvi','ndwi','night2022','pc1','pc2','plancurvature',\n",
    " 'pre2022_1','pre2022_10','pre2022_11','pre2022_12','pre2022_2','pre2022_3','pre2022_4','pre2022_5','pre2022_6',\n",
    " 'pre2022_7','pre2022_8','pre2022_9','pre2022_mean','profilecurvature','relativeslopeposition','savi','slope',\n",
    " 'slope_postion','tmp2022_1','tmp2022_10','tmp2022_11','tmp2022_12',\n",
    " 'tmp2022_2','tmp2022_3','tmp2022_4','tmp2022_5','tmp2022_6','tmp2022_7','tmp2022_8','tmp2022_9','tmp2022_mean',\n",
    " 'topographicwetnessindex','totalcatchmentarea','valleydepth','vari']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdt_features = features_use\n",
    "fzrt_features = features_use\n",
    "zrt_features = features_use\n",
    "target = \"TZ_label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "sy_sdt_data = sy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "sy_fzrt_data = sy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "sy_zrt_data = sy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 碳酸岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "tsy_sdt_data = tsy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "tsy_fzrt_data = tsy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "tsy_zrt_data = tsy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第四系红粘土数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "hnt_sdt_data = hnt_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "hnt_fzrt_data = hnt_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "hnt_zrt_data = hnt_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泥(页)岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "nyy_sdt_data = nyy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "nyy_fzrt_data = nyy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "nyy_zrt_data = nyy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 紫红色砂页岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "zhsyy_sdt_data = zhsyy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "zhsyy_fzrt_data = zhsyy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "zhsyy_zrt_data = zhsyy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 河流冲积物数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "hlcjw_sdt_data = hlcjw_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土\n",
    "hlcjw_fzrt_data = hlcjw_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土\n",
    "hlcjw_zrt_data = hlcjw_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 砂页岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取sdt数据集\n",
    "syy_sdt_data = syy_sdt_data[sdt_features+[target]]\n",
    "# 获取非自然土数据集\n",
    "syy_fzrt_data = syy_fzrt_data[fzrt_features+[target]]\n",
    "# 获取自然土数据集\n",
    "syy_zrt_data = syy_zrt_data[zrt_features+[target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 玄武岩数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取水稻土数据集\n",
    "xw_sdt_data = xw_sdt_data[sdt_features+[target]]\n",
    "# 获取峨嵋山玄武岩数据集\n",
    "xw_zrt_data = xw_zrt_data[zrt_features+[target]]\n",
    "# 获取峨嵋山玄武岩非自然土数据集\n",
    "xw_fzrt_data = xw_fzrt_data[fzrt_features+[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "砂岩 (76, 72) (100, 72) (205, 72)\n",
      "碳酸岩 (343, 72) (1242, 72) (2293, 72)\n",
      "第四系红粘土 (11, 72) (14, 72) (12, 72)\n",
      "泥页岩 (196, 72) (477, 72) (942, 72)\n",
      "紫红色砂页岩 (17, 72) (35, 72) (191, 72)\n",
      "河流冲积物 (26, 72) (30, 72) (23, 72)\n",
      "砂页岩 (58, 72) (121, 72) (159, 72)\n",
      "峨嵋山玄武岩 (19, 72) (59, 72) (40, 72)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((6689, 72), 6689)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看各个数据集的大小\n",
    "print('砂岩',sy_sdt_data.shape,sy_fzrt_data.shape,sy_zrt_data.shape)\n",
    "print('碳酸岩',tsy_sdt_data.shape,tsy_fzrt_data.shape,tsy_zrt_data.shape)\n",
    "print('第四系红粘土',hnt_sdt_data.shape,hnt_fzrt_data.shape,hnt_zrt_data.shape)\n",
    "print('泥页岩',nyy_sdt_data.shape,nyy_fzrt_data.shape,nyy_zrt_data.shape)\n",
    "print('紫红色砂页岩',zhsyy_sdt_data.shape,zhsyy_fzrt_data.shape,zhsyy_zrt_data.shape)\n",
    "print('河流冲积物',hlcjw_sdt_data.shape,hlcjw_fzrt_data.shape,hlcjw_zrt_data.shape)\n",
    "print('砂页岩',syy_sdt_data.shape,syy_fzrt_data.shape,syy_zrt_data.shape)\n",
    "print('峨嵋山玄武岩',xw_sdt_data.shape,xw_zrt_data.shape,xw_fzrt_data.shape)\n",
    "\n",
    "# 计算总数\n",
    "total_data = pd.concat([sy_sdt_data,sy_fzrt_data,sy_zrt_data,tsy_sdt_data,tsy_fzrt_data,tsy_zrt_data,hnt_sdt_data,hnt_fzrt_data,hnt_zrt_data,nyy_sdt_data,nyy_fzrt_data,nyy_zrt_data,zhsyy_sdt_data,zhsyy_fzrt_data,zhsyy_zrt_data,hlcjw_sdt_data,hlcjw_fzrt_data,hlcjw_zrt_data,syy_sdt_data,syy_fzrt_data,syy_zrt_data,xw_sdt_data,xw_zrt_data,xw_fzrt_data])\n",
    "total_data.shape,dataset.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定标签\n",
    "label = \"TZ_label\"\n",
    "eval_metric = 'f1_weighted'\n",
    "problem_type = 'multiclass'\n",
    "# # 10折交叉验证\n",
    "# cv_num = 10\n",
    "# 初始化模型和超参数\n",
    "hyperparameters={\n",
    "\t'NN_TORCH': {},\n",
    "\t'FASTAI': {},\n",
    "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
    "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,label,eval_metric,hyperparameters,problem_type,model_master,model_branch,model_root):\n",
    "    # 训练model\n",
    "    temp_master_path =os.path.join(model_root,model_master)\n",
    "    temp_branch_path = os.path.join(temp_master_path,model_branch)\n",
    "    # 检查路径是否存在，否则便创建\n",
    "    if not os.path.exists(temp_branch_path):\n",
    "        os.makedirs(temp_branch_path)\n",
    "    else:\n",
    "        print(\"文件夹已存在\")\n",
    "    # 执行训练\n",
    "    train_predictor = TabularPredictor(label=label,path=temp_branch_path,eval_metric=eval_metric,problem_type=problem_type).fit(train_data,hyperparameters=hyperparameters)\n",
    "    train_predictor.fit_summary()\n",
    "    return train_predictor.model_best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.89 GB / 63.81 GB (67.2%)\n",
      "Disk Space Avail:   286.51 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    76\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 5 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43919.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['dl']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dz', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dz', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t69 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 60, Val Rows: 16\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.5885\t = Validation score   (f1_weighted)\n",
      "\t3.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6111\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6111\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6111\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6111\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 6.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\sdt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch   0.642857  f1_weighted       0.009091  1.322595                0.009091           1.322595            1       True          6\n",
      "1  WeightedEnsemble_L2   0.642857  f1_weighted       0.013214  1.414037                0.004123           0.091442            2       True          7\n",
      "2       ExtraTreesGini   0.611111  f1_weighted       0.024468  0.359447                0.024468           0.359447            1       True          4\n",
      "3       ExtraTreesEntr   0.611111  f1_weighted       0.028930  0.363950                0.028930           0.363950            1       True          5\n",
      "4     RandomForestGini   0.611111  f1_weighted       0.029641  0.356213                0.029641           0.356213            1       True          2\n",
      "5     RandomForestEntr   0.611111  f1_weighted       0.030522  0.356037                0.030522           0.356037            1       True          3\n",
      "6      NeuralNetFastAI   0.588542  f1_weighted       0.008657  3.070318                0.008657           3.070318            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  2 | ['dz', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.67 GB / 63.81 GB (66.9%)\n",
      "Disk Space Avail:   286.50 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    100\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43696.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.05 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 80, Val Rows: 20\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4073\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.3912\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.3445\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.3867\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.385\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5011\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.875, 'ExtraTreesGini': 0.125}\n",
      "\t0.5211\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.69 GB / 63.81 GB (66.9%)\n",
      "Disk Space Avail:   286.50 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    205\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9804878048780488\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43716.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 160, Val Rows: 41\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.521053  f1_weighted       0.037195  0.852652                0.000000           0.094481            2       True          7\n",
      "1       NeuralNetTorch   0.501053  f1_weighted       0.008298  0.404215                0.008298           0.404215            1       True          6\n",
      "2      NeuralNetFastAI   0.407308  f1_weighted       0.009244  0.451887                0.009244           0.451887            1       True          1\n",
      "3     RandomForestGini   0.391212  f1_weighted       0.027155  0.360201                0.027155           0.360201            1       True          2\n",
      "4       ExtraTreesGini   0.386667  f1_weighted       0.028897  0.353956                0.028897           0.353956            1       True          4\n",
      "5       ExtraTreesEntr   0.385000  f1_weighted       0.028936  0.359957                0.028936           0.359957            1       True          5\n",
      "6     RandomForestEntr   0.344545  f1_weighted       0.027292  0.381991                0.027292           0.381991            1       True          3\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4859\t = Validation score   (f1_weighted)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5302\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5437\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4884\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5888\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5568\t = Validation score   (f1_weighted)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 0.667, 'NeuralNetTorch': 0.333}\n",
      "\t0.6084\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.23s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.69 GB / 63.81 GB (66.9%)\n",
      "Disk Space Avail:   286.49 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    343\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43714.78 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 274, Val Rows: 69\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.608390  f1_weighted       0.037590  1.888427                0.000000           0.091483            2       True          7\n",
      "1       ExtraTreesEntr   0.588807  f1_weighted       0.029483  0.363431                0.029483           0.363431            1       True          5\n",
      "2       NeuralNetTorch   0.556794  f1_weighted       0.008106  1.433512                0.008106           1.433512            1       True          6\n",
      "3     RandomForestEntr   0.543699  f1_weighted       0.027097  0.363005                0.027097           0.363005            1       True          3\n",
      "4     RandomForestGini   0.530168  f1_weighted       0.029923  0.364184                0.029923           0.364184            1       True          2\n",
      "5       ExtraTreesGini   0.488359  f1_weighted       0.032103  0.358510                0.032103           0.358510            1       True          4\n",
      "6      NeuralNetFastAI   0.485929  f1_weighted       0.008897  0.952015                0.008897           0.952015            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\sy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7113\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7121\t = Validation score   (f1_weighted)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7121\t = Validation score   (f1_weighted)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7121\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7121\t = Validation score   (f1_weighted)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6872\t = Validation score   (f1_weighted)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'RandomForestGini': 0.5}\n",
      "\t0.73\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.66 GB / 63.81 GB (66.9%)\n",
      "Disk Space Avail:   286.47 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    1242\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 8 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9935587761674718\n",
      "Train Data Class Count: 8\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43685.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.64 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 987, Val Rows: 247\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.729952  f1_weighted       0.035514  0.920525                0.000000           0.096081            2       True          7\n",
      "1       ExtraTreesEntr   0.712125  f1_weighted       0.027312  0.460466                0.027312           0.460466            1       True          5\n",
      "2     RandomForestGini   0.712125  f1_weighted       0.027399  0.458466                0.027399           0.458466            1       True          2\n",
      "3       ExtraTreesGini   0.712125  f1_weighted       0.029197  0.451195                0.029197           0.451195            1       True          4\n",
      "4     RandomForestEntr   0.712125  f1_weighted       0.030858  0.438847                0.030858           0.438847            1       True          3\n",
      "5      NeuralNetFastAI   0.711275  f1_weighted       0.008114  0.365979                0.008114           0.365979            1       True          1\n",
      "6       NeuralNetTorch   0.687169  f1_weighted       0.009090  0.594379                0.009090           0.594379            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.3551\t = Validation score   (f1_weighted)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.3526\t = Validation score   (f1_weighted)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.3626\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.3843\t = Validation score   (f1_weighted)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.3735\t = Validation score   (f1_weighted)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.3674\t = Validation score   (f1_weighted)\n",
      "\t4.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.4, 'ExtraTreesGini': 0.2, 'ExtraTreesEntr': 0.2, 'RandomForestGini': 0.133, 'RandomForestEntr': 0.067}\n",
      "\t0.4158\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.4s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.62 GB / 63.81 GB (66.8%)\n",
      "Disk Space Avail:   286.37 GB / 1406.25 GB (20.4%)\n",
      "===================================================\n",
      "Train Data Rows:    2293\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 11 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9965111208024422\n",
      "Train Data Class Count: 11\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43640.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.19 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.415841  f1_weighted       0.153191  6.210062                0.000000           0.102691            2       True          7\n",
      "1       ExtraTreesGini   0.384328  f1_weighted       0.029250  0.484104                0.029250           0.484104            1       True          4\n",
      "2       ExtraTreesEntr   0.373465  f1_weighted       0.042955  0.490019                0.042955           0.490019            1       True          5\n",
      "3       NeuralNetTorch   0.367389  f1_weighted       0.008248  4.116374                0.008248           4.116374            1       True          6\n",
      "4     RandomForestEntr   0.362576  f1_weighted       0.041973  0.511880                0.041973           0.511880            1       True          3\n",
      "5      NeuralNetFastAI   0.355073  f1_weighted       0.008059  0.739417                0.008059           0.739417            1       True          1\n",
      "6     RandomForestGini   0.352563  f1_weighted       0.030765  0.504995                0.030765           0.504995            1       True          2\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTrain Data (Processed) Memory Usage: 1.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1828, Val Rows: 457\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.3396\t = Validation score   (f1_weighted)\n",
      "\t1.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.3554\t = Validation score   (f1_weighted)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.3554\t = Validation score   (f1_weighted)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.3607\t = Validation score   (f1_weighted)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.3696\t = Validation score   (f1_weighted)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.3027\t = Validation score   (f1_weighted)\n",
      "\t4.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 0.714, 'RandomForestEntr': 0.286}\n",
      "\t0.3729\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 9.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.47 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.16 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    11\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 4 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 4 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43488.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 3): ['dz', 'dl', 'slope_postion']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])   : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 36 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['pre2022_1', 'pre2022_12']\n",
      "\t0.0s = Fit runtime\n",
      "\t67 features in original data used to generate 67 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 8, Val Rows: 3\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.372850  f1_weighted       0.075714  1.336927                0.000000           0.113036            2       True          7\n",
      "1       ExtraTreesEntr   0.369623  f1_weighted       0.043326  0.546351                0.043326           0.546351            1       True          5\n",
      "2       ExtraTreesGini   0.360747  f1_weighted       0.032845  0.546914                0.032845           0.546914            1       True          4\n",
      "3     RandomForestGini   0.355413  f1_weighted       0.045608  0.633280                0.045608           0.633280            1       True          2\n",
      "4     RandomForestEntr   0.355361  f1_weighted       0.032388  0.677541                0.032388           0.677541            1       True          3\n",
      "5      NeuralNetFastAI   0.339633  f1_weighted       0.006437  1.515261                0.006437           1.515261            1       True          1\n",
      "6       NeuralNetTorch   0.302748  f1_weighted       0.010436  4.494924                0.010436           4.494924            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\tsy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.94s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.46 GB / 63.81 GB (66.5%)\n",
      "Disk Space Avail:   286.16 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    14\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43480.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 26 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 4): ['dz', 'dl', 'etp2022_11', 'pre2022_10']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 22): ['etp2022_10', 'etp2022_12', 'etp2022_3', 'etp2022_5', 'etp2022_6', 'etp2022_8', 'ndmi', 'pre2022_11', 'pre2022_12', 'pre2022_2', 'pre2022_3', 'pre2022_9', 'tmp2022_1', 'tmp2022_10', 'tmp2022_11', 'tmp2022_12', 'tmp2022_3', 'tmp2022_5', 'tmp2022_6', 'tmp2022_7', 'tmp2022_8', 'tmp2022_9']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) :  1 | ['ndmi']\n",
      "\t\t('int', [])   : 21 | ['etp2022_10', 'etp2022_12', 'etp2022_3', 'etp2022_5', 'etp2022_6', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 15 | ['etp2022_1', 'etp2022_2', 'etp2022_4', 'etp2022_7', 'etp2022_9', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 12 | ['etp2022_2', 'etp2022_4', 'etp2022_7', 'lat', 'lon', ...]\n",
      "\t\t('int', ['bool']) :  5 | ['etp2022_1', 'etp2022_9', 'mrttf', 'pre2022_8', 'slope_postion']\n",
      "\t0.0s = Fit runtime\n",
      "\t45 features in original data used to generate 45 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.00 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 11, Val Rows: 3\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.008434  0.230320                0.000000           0.089633            2       True          7\n",
      "1       NeuralNetTorch   1.000000  f1_weighted       0.008434  0.140687                0.008434           0.140687            1       True          6\n",
      "2     RandomForestEntr   1.000000  f1_weighted       0.027606  0.322580                0.027606           0.322580            1       True          2\n",
      "3     RandomForestGini   1.000000  f1_weighted       0.029061  0.325419                0.029061           0.325419            1       True          1\n",
      "4       ExtraTreesGini   1.000000  f1_weighted       0.030306  0.329193                0.030306           0.329193            1       True          3\n",
      "5       ExtraTreesEntr   1.000000  f1_weighted       0.030889  0.333981                0.030889           0.333981            1       True          4\n",
      "6      NeuralNetFastAI   0.533333  f1_weighted       0.008184  0.112848                0.008184           0.112848            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 36 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  2 | ['pre2022_1', 'pre2022_12']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.1667\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.1667\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.1667\t = Validation score   (f1_weighted)\n",
      "\t0.32s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.1667\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tfloat division by zero\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 208, in _fit\n",
      "    self._train_net(\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 367, in _train_net\n",
      "    f\"Train loss: {round(total_train_loss / total_train_size, 4)}, \"\n",
      "ZeroDivisionError: float division by zero\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.667, 'RandomForestGini': 0.333}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.93s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.48 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.16 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    12\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 5 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 5 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43498.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['dz']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['mrvbf']\n",
      "\t0.0s = Fit runtime\n",
      "\t69 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 9, Val Rows: 3\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.038075  0.530962                0.000000           0.078116            2       True          6\n",
      "1      NeuralNetFastAI   0.533333  f1_weighted       0.005101  0.116127                0.005101           0.116127            1       True          5\n",
      "2       ExtraTreesEntr   0.166667  f1_weighted       0.030686  0.331634                0.030686           0.331634            1       True          4\n",
      "3     RandomForestGini   0.166667  f1_weighted       0.032974  0.336719                0.032974           0.336719            1       True          1\n",
      "4       ExtraTreesGini   0.166667  f1_weighted       0.033052  0.323480                0.033052           0.323480            1       True          3\n",
      "5     RandomForestEntr   0.166667  f1_weighted       0.034965  0.331133                0.034965           0.331133            1       True          2\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'RFModel', 'XTModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 12 | ['etp2022_2', 'etp2022_4', 'etp2022_7', 'lat', 'lon', ...]\n",
      "('int', ['bool']) :  5 | ['etp2022_1', 'etp2022_9', 'mrttf', 'pre2022_8', 'slope_postion']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.01s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.48 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.16 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    196\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 4 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43500.90 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 156, Val Rows: 40\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   1.000000  f1_weighted       0.012018  0.267698                0.000000           0.089256            2       True          7\n",
      "1       NeuralNetTorch   1.000000  f1_weighted       0.012018  0.178442                0.012018           0.178442            1       True          6\n",
      "2     RandomForestGini   1.000000  f1_weighted       0.028559  0.328051                0.028559           0.328051            1       True          1\n",
      "3       ExtraTreesGini   1.000000  f1_weighted       0.029161  0.330493                0.029161           0.330493            1       True          3\n",
      "4       ExtraTreesEntr   1.000000  f1_weighted       0.030407  0.340915                0.030407           0.340915            1       True          4\n",
      "5     RandomForestEntr   1.000000  f1_weighted       0.033834  0.327890                0.033834           0.327890            1       True          2\n",
      "6      NeuralNetFastAI   0.533333  f1_weighted       0.005041  0.128706                0.005041           0.128706            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['mrvbf']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hnt\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.5337\t = Validation score   (f1_weighted)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6492\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.627\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6312\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.627\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.578\t = Validation score   (f1_weighted)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.667, 'ExtraTreesGini': 0.333}\n",
      "\t0.6765\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.42s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.51 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.15 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    477\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 6 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43528.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.25 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 381, Val Rows: 96\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.676531  f1_weighted       0.062011  0.842053                0.000000           0.091126            2       True          7\n",
      "1     RandomForestGini   0.649159  f1_weighted       0.032137  0.372845                0.032137           0.372845            1       True          2\n",
      "2       ExtraTreesGini   0.631206  f1_weighted       0.029874  0.378082                0.029874           0.378082            1       True          4\n",
      "3     RandomForestEntr   0.626998  f1_weighted       0.029113  0.373006                0.029113           0.373006            1       True          3\n",
      "4       ExtraTreesEntr   0.626998  f1_weighted       0.029479  0.364783                0.029479           0.364783            1       True          5\n",
      "5       NeuralNetTorch   0.578000  f1_weighted       0.008213  0.711674                0.008213           0.711674            1       True          6\n",
      "6      NeuralNetFastAI   0.533696  f1_weighted       0.004510  0.835251                0.004510           0.835251            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.4975\t = Validation score   (f1_weighted)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5087\t = Validation score   (f1_weighted)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5017\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5017\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5017\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.4808\t = Validation score   (f1_weighted)\n",
      "\t0.82s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 0.5, 'ExtraTreesGini': 0.5}\n",
      "\t0.5225\t = Validation score   (f1_weighted)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.62 GB / 63.81 GB (66.8%)\n",
      "Disk Space Avail:   286.12 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    942\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43640.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 753, Val Rows: 189\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.522478  f1_weighted       0.106256  1.184399                0.000000           0.095252            2       True          7\n",
      "1     RandomForestGini   0.508730  f1_weighted       0.030036  0.577647                0.030036           0.577647            1       True          2\n",
      "2     RandomForestEntr   0.501702  f1_weighted       0.041128  0.517567                0.041128           0.517567            1       True          3\n",
      "3       ExtraTreesEntr   0.501702  f1_weighted       0.050193  0.508819                0.050193           0.508819            1       True          5\n",
      "4       ExtraTreesGini   0.501702  f1_weighted       0.076220  0.511499                0.076220           0.511499            1       True          4\n",
      "5      NeuralNetFastAI   0.497451  f1_weighted       0.007399  0.602781                0.007399           0.602781            1       True          1\n",
      "6       NeuralNetTorch   0.480769  f1_weighted       0.007674  0.820933                0.007674           0.820933            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.531\t = Validation score   (f1_weighted)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5526\t = Validation score   (f1_weighted)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5492\t = Validation score   (f1_weighted)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5451\t = Validation score   (f1_weighted)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5577\t = Validation score   (f1_weighted)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5619\t = Validation score   (f1_weighted)\n",
      "\t7.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 0.471, 'ExtraTreesGini': 0.294, 'ExtraTreesEntr': 0.235}\n",
      "\t0.605\t = Validation score   (f1_weighted)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 10.33s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.48 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.07 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    17\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 7 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 7 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43497.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 37 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['dz', 'dl', 'pre2022_1', 'slope_postion']\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 13, Val Rows: 4\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.604979  f1_weighted       0.076272  8.356124                0.001998           0.197384            2       True          7\n",
      "1       NeuralNetTorch   0.561915  f1_weighted       0.012816  7.235081                0.012816           7.235081            1       True          6\n",
      "2       ExtraTreesEntr   0.557662  f1_weighted       0.030971  0.455859                0.030971           0.455859            1       True          5\n",
      "3     RandomForestGini   0.552630  f1_weighted       0.033397  0.487351                0.033397           0.487351            1       True          2\n",
      "4     RandomForestEntr   0.549195  f1_weighted       0.032408  0.469024                0.032408           0.469024            1       True          3\n",
      "5       ExtraTreesGini   0.545068  f1_weighted       0.030487  0.467799                0.030487           0.467799            1       True          4\n",
      "6      NeuralNetFastAI   0.530978  f1_weighted       0.009960  0.606014                0.009960           0.606014            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\nyy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.7333\t = Validation score   (f1_weighted)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7333\t = Validation score   (f1_weighted)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.7333\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.7333\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.3333\t = Validation score   (f1_weighted)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tfloat division by zero\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 208, in _fit\n",
      "    self._train_net(\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 367, in _train_net\n",
      "    f\"Train loss: {round(total_train_loss / total_train_size, 4)}, \"\n",
      "ZeroDivisionError: float division by zero\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 1.0}\n",
      "\t0.7333\t = Validation score   (f1_weighted)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.59s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.36 GB / 63.81 GB (66.4%)\n",
      "Disk Space Avail:   286.07 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    35\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43379.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['dl']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dz', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  1 | ['slope_postion']\n",
      "\t\t('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['dz', 'mrttf']\n",
      "\t0.1s = Fit runtime\n",
      "\t69 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 28, Val Rows: 7\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       ExtraTreesGini   0.733333  f1_weighted       0.028494  0.454591                0.028494           0.454591            1       True          3\n",
      "1     RandomForestGini   0.733333  f1_weighted       0.029240  0.509675                0.029240           0.509675            1       True          1\n",
      "2     RandomForestEntr   0.733333  f1_weighted       0.029421  0.418953                0.029421           0.418953            1       True          2\n",
      "3  WeightedEnsemble_L2   0.733333  f1_weighted       0.031241  0.674783                0.002001           0.165108            2       True          6\n",
      "4       ExtraTreesEntr   0.733333  f1_weighted       0.033612  0.382867                0.033612           0.382867            1       True          4\n",
      "5      NeuralNetFastAI   0.333333  f1_weighted       0.007840  0.163247                0.007840           0.163247            1       True          5\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'RFModel', 'XTModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 37 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  4 | ['dz', 'dl', 'pre2022_1', 'slope_postion']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 0: early stopping\n",
      "\t0.1429\t = Validation score   (f1_weighted)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4156\t = Validation score   (f1_weighted)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4156\t = Validation score   (f1_weighted)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4156\t = Validation score   (f1_weighted)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.4156\t = Validation score   (f1_weighted)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5429\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t0.5714\t = Validation score   (f1_weighted)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.93s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.38 GB / 63.81 GB (66.4%)\n",
      "Disk Space Avail:   286.07 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    191\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 5 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 5\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43395.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['dz']\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.10 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.571429  f1_weighted       0.028264  0.780175                0.002002           0.194940            2       True          7\n",
      "1       NeuralNetTorch   0.542857  f1_weighted       0.013806  0.357871                0.013806           0.357871            1       True          6\n",
      "2     RandomForestGini   0.415584  f1_weighted       0.045856  0.704896                0.045856           0.704896            1       True          2\n",
      "3     RandomForestEntr   0.415584  f1_weighted       0.046909  0.638213                0.046909           0.638213            1       True          3\n",
      "4       ExtraTreesEntr   0.415584  f1_weighted       0.048075  0.698735                0.048075           0.698735            1       True          5\n",
      "5       ExtraTreesGini   0.415584  f1_weighted       0.052930  0.638012                0.052930           0.638012            1       True          4\n",
      "6      NeuralNetFastAI   0.142857  f1_weighted       0.012456  0.227364                0.012456           0.227364            1       True          1\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  1 | ['slope_postion']\n",
      "('float', [])     : 28 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  2 | ['dz', 'mrttf']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 152, Val Rows: 39\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 3: early stopping\n",
      "\t0.495\t = Validation score   (f1_weighted)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4391\t = Validation score   (f1_weighted)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.3784\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.4491\t = Validation score   (f1_weighted)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.4373\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.4836\t = Validation score   (f1_weighted)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.6, 'ExtraTreesGini': 0.4}\n",
      "\t0.6082\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.18s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.39 GB / 63.81 GB (66.4%)\n",
      "Disk Space Avail:   286.06 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    26\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43411.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['dz']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 20, Val Rows: 6\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.608153  f1_weighted       0.046459  1.888016                0.000000           0.094748            2       True          7\n",
      "1      NeuralNetFastAI   0.494991  f1_weighted       0.017371  1.342187                0.017371           1.342187            1       True          1\n",
      "2       NeuralNetTorch   0.483566  f1_weighted       0.013573  1.088177                0.013573           1.088177            1       True          6\n",
      "3       ExtraTreesGini   0.449083  f1_weighted       0.029088  0.451082                0.029088           0.451082            1       True          4\n",
      "4     RandomForestGini   0.439085  f1_weighted       0.035480  0.777000                0.035480           0.777000            1       True          2\n",
      "5       ExtraTreesEntr   0.437292  f1_weighted       0.029988  0.524300                0.029988           0.524300            1       True          5\n",
      "6     RandomForestEntr   0.378376  f1_weighted       0.026854  0.523972                0.026854           0.523972            1       True          3\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['dz']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\zhsyy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8381\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8381\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8381\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8381\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.6667\t = Validation score   (f1_weighted)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.43s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.56 GB / 63.81 GB (66.7%)\n",
      "Disk Space Avail:   286.06 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    30\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43574.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['dz']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       NeuralNetTorch   1.000000  f1_weighted       0.008279  0.274381                0.008279           0.274381            1       True          6\n",
      "1  WeightedEnsemble_L2   1.000000  f1_weighted       0.009319  0.383975                0.001040           0.109594            2       True          7\n",
      "2     RandomForestGini   0.838095  f1_weighted       0.026689  0.354202                0.026689           0.354202            1       True          1\n",
      "3     RandomForestEntr   0.838095  f1_weighted       0.028258  0.404389                0.028258           0.404389            1       True          2\n",
      "4       ExtraTreesGini   0.838095  f1_weighted       0.029017  0.431031                0.029017           0.431031            1       True          3\n",
      "5       ExtraTreesEntr   0.838095  f1_weighted       0.033129  0.389877                0.033129           0.389877            1       True          4\n",
      "6      NeuralNetFastAI   0.666667  f1_weighted       0.010896  0.157705                0.010896           0.157705            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['dz']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t69 features in original data used to generate 69 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 24, Val Rows: 6\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.1667\t = Validation score   (f1_weighted)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.5333\t = Validation score   (f1_weighted)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.67s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.50 GB / 63.81 GB (66.6%)\n",
      "Disk Space Avail:   286.05 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    23\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 7 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 7 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43522.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['dz']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 18, Val Rows: 5\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.533333  f1_weighted       0.004175  0.275776                0.000000           0.133446            2       True          7\n",
      "1       NeuralNetTorch   0.533333  f1_weighted       0.004175  0.142330                0.004175           0.142330            1       True          6\n",
      "2       ExtraTreesGini   0.533333  f1_weighted       0.025717  0.387002                0.025717           0.387002            1       True          3\n",
      "3       ExtraTreesEntr   0.533333  f1_weighted       0.031692  0.363794                0.031692           0.363794            1       True          4\n",
      "4     RandomForestEntr   0.533333  f1_weighted       0.037976  0.520373                0.037976           0.520373            1       True          2\n",
      "5     RandomForestGini   0.533333  f1_weighted       0.060653  0.572468                0.060653           0.572468            1       True          1\n",
      "6      NeuralNetFastAI   0.166667  f1_weighted       0.007332  0.162354                0.007332           0.162354            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  2 | ['dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.781\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.781\t = Validation score   (f1_weighted)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.781\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.781\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.6\t = Validation score   (f1_weighted)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8\t = Validation score   (f1_weighted)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetTorch': 1.0}\n",
      "\t0.8\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.35s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.54 GB / 63.81 GB (66.7%)\n",
      "Disk Space Avail:   286.05 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    58\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43546.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.800000  f1_weighted       0.005876  0.250617                0.000000           0.092616            2       True          7\n",
      "1       NeuralNetTorch   0.800000  f1_weighted       0.005876  0.158001                0.005876           0.158001            1       True          6\n",
      "2       ExtraTreesEntr   0.780952  f1_weighted       0.032995  0.401711                0.032995           0.401711            1       True          4\n",
      "3       ExtraTreesGini   0.780952  f1_weighted       0.033142  0.374975                0.033142           0.374975            1       True          3\n",
      "4     RandomForestGini   0.780952  f1_weighted       0.035084  0.387462                0.035084           0.387462            1       True          1\n",
      "5     RandomForestEntr   0.780952  f1_weighted       0.048081  0.481130                0.048081           0.481130            1       True          2\n",
      "6      NeuralNetFastAI   0.600000  f1_weighted       0.008096  0.131253                0.008096           0.131253            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['dz']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\hlcjw\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 46, Val Rows: 12\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7718\t = Validation score   (f1_weighted)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.75\t = Validation score   (f1_weighted)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.75\t = Validation score   (f1_weighted)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.75\t = Validation score   (f1_weighted)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.75\t = Validation score   (f1_weighted)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7165\t = Validation score   (f1_weighted)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.7718\t = Validation score   (f1_weighted)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.13s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.56 GB / 63.81 GB (66.7%)\n",
      "Disk Space Avail:   286.05 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    121\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43574.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI   0.771795  f1_weighted       0.007999  0.659687                0.007999           0.659687            1       True          1\n",
      "1  WeightedEnsemble_L2   0.771795  f1_weighted       0.010004  0.784436                0.002004           0.124750            2       True          7\n",
      "2       ExtraTreesEntr   0.750000  f1_weighted       0.035322  0.502505                0.035322           0.502505            1       True          5\n",
      "3       ExtraTreesGini   0.750000  f1_weighted       0.044781  0.619376                0.044781           0.619376            1       True          4\n",
      "4     RandomForestGini   0.750000  f1_weighted       0.048462  0.622307                0.048462           0.622307            1       True          2\n",
      "5     RandomForestEntr   0.750000  f1_weighted       0.049482  0.611702                0.049482           0.611702            1       True          3\n",
      "6       NeuralNetTorch   0.716503  f1_weighted       0.011757  0.527189                0.011757           0.527189            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 96, Val Rows: 25\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t0.5851\t = Validation score   (f1_weighted)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5533\t = Validation score   (f1_weighted)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4981\t = Validation score   (f1_weighted)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5\t = Validation score   (f1_weighted)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.5201\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5462\t = Validation score   (f1_weighted)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.5, 'NeuralNetTorch': 0.5}\n",
      "\t0.5878\t = Validation score   (f1_weighted)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4.06s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\fzrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.45 GB / 63.81 GB (66.5%)\n",
      "Disk Space Avail:   286.04 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    159\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9937106918238994\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43462.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 126, Val Rows: 32\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.587765  f1_weighted       0.025050  1.997828                0.002059           0.129479            2       True          7\n",
      "1      NeuralNetFastAI   0.585098  f1_weighted       0.010204  1.092027                0.010204           1.092027            1       True          1\n",
      "2     RandomForestGini   0.553333  f1_weighted       0.031292  0.429809                0.031292           0.429809            1       True          2\n",
      "3       NeuralNetTorch   0.546154  f1_weighted       0.012787  0.776322                0.012787           0.776322            1       True          6\n",
      "4       ExtraTreesEntr   0.520060  f1_weighted       0.032378  0.371251                0.032378           0.371251            1       True          5\n",
      "5       ExtraTreesGini   0.500000  f1_weighted       0.026516  0.424672                0.026516           0.424672            1       True          4\n",
      "6     RandomForestEntr   0.498095  f1_weighted       0.029759  0.465582                0.029759           0.465582            1       True          3\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 4: early stopping\n",
      "\t0.6478\t = Validation score   (f1_weighted)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.671\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6228\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6228\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6228\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5602\t = Validation score   (f1_weighted)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 1.0}\n",
      "\t0.671\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.78s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\sdt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\sdt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.39 GB / 63.81 GB (66.4%)\n",
      "Disk Space Avail:   286.04 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    19\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 8 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 8 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43404.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 2): ['dz', 'dl']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t68 features in original data used to generate 68 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 15, Val Rows: 4\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     RandomForestGini   0.671016  f1_weighted       0.027971  0.398126                0.027971           0.398126            1       True          2\n",
      "1  WeightedEnsemble_L2   0.671016  f1_weighted       0.028971  0.490766                0.001000           0.092640            2       True          7\n",
      "2      NeuralNetFastAI   0.647771  f1_weighted       0.007423  0.527019                0.007423           0.527019            1       True          1\n",
      "3       ExtraTreesEntr   0.622838  f1_weighted       0.027443  0.393389                0.027443           0.393389            1       True          5\n",
      "4       ExtraTreesGini   0.622838  f1_weighted       0.031383  0.386893                0.031383           0.386893            1       True          4\n",
      "5     RandomForestEntr   0.622838  f1_weighted       0.032081  0.392434                0.032081           0.392434            1       True          3\n",
      "6       NeuralNetTorch   0.560185  f1_weighted       0.010057  0.279940                0.010057           0.279940            1       True          6\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\syy\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 0: early stopping\n",
      "\t0.3333\t = Validation score   (f1_weighted)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\tfloat division by zero\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 208, in _fit\n",
      "    self._train_net(\n",
      "  File \"d:\\worker_code\\.venvgis\\lib\\site-packages\\autogluon\\tabular\\models\\tabular_nn\\torch\\tabular_nn_torch.py\", line 367, in _train_net\n",
      "    f\"Train loss: {round(total_train_loss / total_train_size, 4)}, \"\n",
      "ZeroDivisionError: float division by zero\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'RandomForestGini': 1.0}\n",
      "\t1.0\t = Validation score   (f1_weighted)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.11s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\sdt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\zrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\zrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.40 GB / 63.81 GB (66.4%)\n",
      "Disk Space Avail:   286.03 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    59\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 6 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 6 examples. AutoGluon will only keep 3 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43413.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['dz']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 47, Val Rows: 12\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: NeuralNetFastAI ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       ExtraTreesGini   1.000000  f1_weighted       0.024948  0.374025                0.024948           0.374025            1       True          3\n",
      "1     RandomForestEntr   1.000000  f1_weighted       0.028866  0.386088                0.028866           0.386088            1       True          2\n",
      "2       ExtraTreesEntr   1.000000  f1_weighted       0.032455  0.367698                0.032455           0.367698            1       True          4\n",
      "3     RandomForestGini   1.000000  f1_weighted       0.032816  0.376179                0.032816           0.376179            1       True          1\n",
      "4  WeightedEnsemble_L2   1.000000  f1_weighted       0.036951  0.451444                0.004135           0.075265            2       True          6\n",
      "5      NeuralNetFastAI   0.333333  f1_weighted       0.008030  0.120910                0.008030           0.120910            1       True          5\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'RFModel', 'XTModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) :  1 | ['slope_postion']\n",
      "('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\sdtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 3: early stopping\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesEntr': 1.0}\n",
      "\t0.6429\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\zrt\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\fzrt\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\fzrt\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          20\n",
      "Memory Avail:       42.44 GB / 63.81 GB (66.5%)\n",
      "Disk Space Avail:   286.03 GB / 1406.25 GB (20.3%)\n",
      "===================================================\n",
      "Train Data Rows:    40\n",
      "Train Data Columns: 71\n",
      "Label Column:       TZ_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 7 to avoid cutting too many classes.\n",
      "Warning: Some classes in the training set have fewer than 7 examples. AutoGluon will only keep 2 out of 92 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Train Data Class Count: 2\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    43461.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ndmi']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 1 | ['ndmi']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  3 | ['dz', 'dl', 'slope_postion']\n",
      "\t\t('float', [])    : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])      : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "\t\t('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "\t\t('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['dz']\n",
      "\t0.0s = Fit runtime\n",
      "\t70 features in original data used to generate 70 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_weighted'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 32, Val Rows: 8\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 6 L1 models ...\n",
      "Fitting model: RandomForestGini ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI   0.642857  f1_weighted       0.004014  0.272080                0.004014           0.272080            1       True          1\n",
      "1       NeuralNetTorch   0.642857  f1_weighted       0.012533  0.202199                0.012533           0.202199            1       True          6\n",
      "2       ExtraTreesGini   0.642857  f1_weighted       0.027076  0.387155                0.027076           0.387155            1       True          4\n",
      "3     RandomForestGini   0.642857  f1_weighted       0.028547  0.386343                0.028547           0.386343            1       True          2\n",
      "4     RandomForestEntr   0.642857  f1_weighted       0.028731  0.381423                0.028731           0.381423            1       True          3\n",
      "5  WeightedEnsemble_L2   0.642857  f1_weighted       0.029291  0.469846                0.000000           0.090680            2       True          7\n",
      "6       ExtraTreesEntr   0.642857  f1_weighted       0.029291  0.379166                0.029291           0.379166            1       True          5\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['dz']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\zrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.8167\t = Validation score   (f1_weighted)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8167\t = Validation score   (f1_weighted)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8167\t = Validation score   (f1_weighted)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8167\t = Validation score   (f1_weighted)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 6: early stopping\n",
      "\t0.891\t = Validation score   (f1_weighted)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.8167\t = Validation score   (f1_weighted)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 1.0}\n",
      "\t0.891\t = Validation score   (f1_weighted)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2.34s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\fzrt\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  eval_metric  pred_time_val  fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      NeuralNetFastAI   0.891026  f1_weighted       0.007521  0.277569                0.007521           0.277569            1       True          5\n",
      "1  WeightedEnsemble_L2   0.891026  f1_weighted       0.008560  0.368524                0.001038           0.090955            2       True          7\n",
      "2       NeuralNetTorch   0.816667  f1_weighted       0.006941  0.205652                0.006941           0.205652            1       True          6\n",
      "3     RandomForestGini   0.816667  f1_weighted       0.029089  0.352210                0.029089           0.352210            1       True          1\n",
      "4       ExtraTreesGini   0.816667  f1_weighted       0.029212  0.355592                0.029212           0.355592            1       True          3\n",
      "5     RandomForestEntr   0.816667  f1_weighted       0.032785  0.404094                0.032785           0.404094            1       True          2\n",
      "6       ExtraTreesEntr   0.816667  f1_weighted       0.033173  0.366616                0.033173           0.366616            1       True          4\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'RFModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel', 'XTModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  2 | ['dl', 'slope_postion']\n",
      "('float', [])     : 29 | ['analyticalhillshading', 'aspect', 'channelnetworkbaselevel', 'channelnetworkdistance', 'convergenceindex', ...]\n",
      "('int', [])       : 38 | ['etp2022_1', 'etp2022_10', 'etp2022_11', 'etp2022_12', 'etp2022_2', ...]\n",
      "('int', ['bool']) :  1 | ['dz']\n",
      "Plot summary of models saved to file: F:\\cache_data\\zone_ana\\ky\\modle\\autogluon_type\\xw\\fzrtSummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "# 砂岩\n",
    "sy_sdt_predictor = train_model(sy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='sdt',model_root=model_path) \n",
    "sy_fzrt_predictor = train_model(sy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='fzrt',model_root=model_path) \n",
    "sy_zrt_predictor = train_model(sy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='sy',model_branch='zrt',model_root=model_path) \n",
    "# 碳酸岩\n",
    "tsy_sdt_predictor = train_model(tsy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='sdt',model_root=model_path) \n",
    "tsy_fzrt_predictor = train_model(tsy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='fzrt',model_root=model_path) \n",
    "tsy_zrt_predictor = train_model(tsy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='tsy',model_branch='zrt',model_root=model_path) \n",
    "# 第四系红粘土\n",
    "hnt_sdt_predictor = train_model(hnt_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='sdt',model_root=model_path) \n",
    "hnt_fzrt_predictor = train_model(hnt_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='fzrt',model_root=model_path) \n",
    "hnt_zrt_predictor = train_model(hnt_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hnt',model_branch='zrt',model_root=model_path) \n",
    "# 泥页岩\n",
    "nyy_sdt_predictor = train_model(nyy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='sdt',model_root=model_path) \n",
    "nyy_fzrt_predictor = train_model(nyy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='fzrt',model_root=model_path) \n",
    "nyy_zrt_predictor = train_model(nyy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='nyy',model_branch='zrt',model_root=model_path) \n",
    "# 紫红色砂页岩\n",
    "zhsyy_sdt_predictor = train_model(zhsyy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='sdt',model_root=model_path) \n",
    "zhsyy_fzrt_predictor = train_model(zhsyy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='fzrt',model_root=model_path) \n",
    "zhsyy_zrt_predictor = train_model(zhsyy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='zhsyy',model_branch='zrt',model_root=model_path) \n",
    "# 河流冲积物\n",
    "hlcjw_sdt_predictor = train_model(hlcjw_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hlcjw',model_branch='sdt',model_root=model_path)\n",
    "hlcjw_fzrt_predictor = train_model(hlcjw_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hlcjw',model_branch='fzrt',model_root=model_path)\n",
    "hlcjw_zrt_predictor = train_model(hlcjw_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='hlcjw',model_branch='zrt',model_root=model_path)\n",
    "# 砂页岩\n",
    "syy_sdt_predictor = train_model(syy_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='sdt',model_root=model_path) \n",
    "syy_fzrt_predictor = train_model(syy_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='fzrt',model_root=model_path) \n",
    "syy_zrt_predictor = train_model(syy_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='syy',model_branch='zrt',model_root=model_path) \n",
    "# 峨嵋山玄武岩\n",
    "xw_sdt_predictor = train_model(xw_sdt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='xw',model_branch='sdt',model_root=model_path) \n",
    "xw_zrt_predictor = train_model(xw_zrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='xw',model_branch='zrt',model_root=model_path) \n",
    "xw_fzrt_predictor = train_model(xw_fzrt_data,label=label,eval_metric=eval_metric,hyperparameters=hyperparameters,problem_type=problem_type,model_master='xw',model_branch='fzrt',model_root=model_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
