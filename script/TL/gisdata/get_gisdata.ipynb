{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.management import *\n",
    "from arcpy.sa import *\n",
    "from arcpy.da import *\n",
    "from arcpy.conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析函数\n",
    "# 取消并行处理\n",
    "def disable_parallel_processing(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with arcpy.EnvManager(parallelProcessingFactor=\"0\"):\n",
    "            return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "# 采样\n",
    "def sample_point(point_,raster_,out_name):\n",
    "    \"\"\"根据栅格采样点,输出为表格\"\"\"\n",
    "    Sample(raster_,point_,out_name,\"NEAREST\", \"OBJECTID\", \"CURRENT_SLICE\", None, '', None, None, \"ROW_WISE\", \"TABLE\")\n",
    "    return None\n",
    "\n",
    "# 导出CSV\n",
    "def export_csv(table_,out_path,out_name):\n",
    "    TableToTable(table_,out_path,out_name)\n",
    "    return None\n",
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster\n",
    "# 数组整形\n",
    "def resize_arrays(A, B, fill_value=0):\n",
    "    \"\"\"调整数组形状一致,A为参考数组, B为待调整数组, fill_value为填充值\"\"\"\n",
    "    # new_shape = (max(A.shape[0], B.shape[0]), max(A.shape[1], B.shape[1]))\n",
    "    new_shape = (A.shape[0], A.shape[1])\n",
    "\n",
    "    if A.shape != new_shape:\n",
    "        if A.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - A.shape[0]\n",
    "            padding = np.full((padding_rows, A.shape[1]), fill_value)\n",
    "            A = np.vstack((A, padding))\n",
    "        elif A.shape[0] > new_shape[0]:\n",
    "            A = A[:new_shape[0], :]\n",
    "\n",
    "        if A.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - A.shape[1]))\n",
    "            A = np.pad(A, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif A.shape[1] > new_shape[1]:\n",
    "            A = A[:, :new_shape[1]]\n",
    "    \n",
    "    if B.shape != new_shape:\n",
    "        if B.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - B.shape[0]\n",
    "            padding = np.full((padding_rows, B.shape[1]), fill_value)\n",
    "            B = np.vstack((B, padding))\n",
    "        elif B.shape[0] > new_shape[0]:\n",
    "            B = B[:new_shape[0], :]\n",
    "\n",
    "        if B.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - B.shape[1]))\n",
    "            B = np.pad(B, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif B.shape[1] > new_shape[1]:\n",
    "            B = B[:, :new_shape[1]]\n",
    "    \n",
    "    return A, B\n",
    "# rf寻找最优参数\n",
    "def rf_best_param(X_train,y_train,n_estimators_range,k=5):\n",
    "    \"\"\"默认为5折交叉验证,评价指标为R2\"\"\"\n",
    "    # 设置树的数目范围\n",
    "    n_estimators_range = n_estimators_range\n",
    "    cv_scores = []\n",
    "    # 使用交叉验证\n",
    "    for n_estimators in n_estimators_range:\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
    "        scores = cross_val_score(rf,X_train, y_train, cv=k, scoring='accuracy')  # K折交叉验证 分类问题默认使用accuracy\n",
    "        cv_scores.append(scores.mean())\n",
    "    # 选择最优数量的树\n",
    "    optimal_n_estimators = n_estimators_range[cv_scores.index(max(cv_scores))]\n",
    "    return optimal_n_estimators\n",
    "\n",
    "# arcpy栅格众数滤波\n",
    "@disable_parallel_processing\n",
    "def mode_filter(in_raster,filter_size=\"FOUR\",filter_method=\"MAJORITY\"):\n",
    "    \"\"\"栅格众数滤波,filter_size:滤波窗口大小,filter_method:滤波方法\"\"\"\n",
    "    result_raster = MajorityFilter(in_raster, filter_size, filter_method) # 默认为4邻域 众数滤波  可选为8邻域 半数滤波\n",
    "    return result_raster\n",
    "    \n",
    "# arcpy栅格边界清理\n",
    "@disable_parallel_processing\n",
    "def clean_boundary(in_raster,sort_method=\"NO_SORT\",clean_method=\"TWO_WAY\"):\n",
    "    \"\"\"栅格边界清理,sort_method:排序方法,clean_method:清理方法\"\"\"\n",
    "    result_raster = BoundaryClean(in_raster, \"NO_SORT\", \"TWO_WAY\") # 默认为不排序 两边清理 可选为排序 一边清理\n",
    "    return result_raster\n",
    "# arcpy栅格区域分组\n",
    "@disable_parallel_processing\n",
    "def region_group(in_raster,group_size=\"FOUR\",method=\"WITHIN\",add_link=\"ADD_LINK\",clear=None):\n",
    "    \"\"\"栅格区域分组,group_size:分组大小,method:分组方法,add_link:添加链接,clear:排除的值\"\"\"\n",
    "    result_raster = RegionGroup(in_raster, group_size, method, add_link, clear) # 默认为4邻域 分组方法为WITHIN 可选为8邻域 分组方法为CROSS\n",
    "    return result_raster\n",
    "# arcpy栅格按属性提取\n",
    "@disable_parallel_processing\n",
    "def extract_by_attributes(in_raster,where_clause=\"count >= 100\"):\n",
    "    \"\"\"栅格按属性提取,where_clause:属性条件\"\"\"\n",
    "    result_raster = ExtractByAttributes(in_raster, where_clause) # 默认为count >= 100\n",
    "    return result_raster\n",
    "\n",
    "# arcpy栅格Nibble\n",
    "@disable_parallel_processing\n",
    "def nibble(in_raster,mask_raster, nibble_mask=\"ALL_VALUES\", nibble_values=\"PRESERVE_NODATA\"):\n",
    "    \"\"\"栅格Nibble,nibble_mask:掩膜,nibble_values:填充值\"\"\"\n",
    "    result_raster = Nibble(in_raster, mask_raster,nibble_mask, nibble_values) # 默认为ALL_VALUES PRESERVE_NODATA 可选为DATA_ONLY PRESERVE_DATA\n",
    "    return result_raster\n",
    "\n",
    "# arcpy栅格查找表\n",
    "@disable_parallel_processing\n",
    "def lookup(in_raster,lookup_field=\"LINK\"):\n",
    "    \"\"\"栅格查找表,lookup_field:查找字段\"\"\"\n",
    "    result_raster = Lookup(in_raster, lookup_field) # 默认为LINK\n",
    "    return result_raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地理数据库路径\n",
    "base_gdb_5m = r\"D:\\ArcgisData\\basedata\\basetrain_5m.gdb\"\n",
    "base_gdb_30m = r\"D:\\ArcgisData\\basedata\\basetrain_30m.gdb\"\n",
    "base_gdb_deep = r\"D:\\ArcgisData\\pred_soildeep\\pre_database\\pred_soildeep_gz.gdb\"\n",
    "# 用于采样的标准数据库\n",
    "stander_raster_gdb = base_gdb_deep\n",
    "# 数据点文件路径\n",
    "point_data = r\"D:\\ArcgisData\\basedata\\soildeep.gdb\\soildeep_point_P\"  # 需要改变\n",
    "# 存储采样数据表的文件地理数据库\n",
    "sample_gdb_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\test.gdb\" # 需要改变\n",
    "# 存储采样结果CSV文件的路径\n",
    "sample_csv = r\"D:\\ArcgisData\\pred_soildeep\\feature_result\"\n",
    "# 输出CSV文件的名称\n",
    "sample_csv_name = \"feature_soildeep.csv\" # 需要改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'code', 'lon', 'lat', 'deep_range', 'deep']\n",
      "['OBJECTID', 'lon', 'lat', 'deep']\n"
     ]
    }
   ],
   "source": [
    "# 采样点数据名称\n",
    "sample_name = 'soildeep_point_P'\n",
    "filed_list = [_.name for _ in arcpy.ListFields(point_data)]\n",
    "print(filed_list)\n",
    "elements_yes = ['OBJECTID', 'deep','lon','lat']\n",
    "filter_list = [_ for _ in filed_list if _ in elements_yes]\n",
    "print(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_list = ['LON','LAT','TWI5','TPI201','TPI101','TPI11','TPI3','TMP','SOILQS','SLOP','PRE','NIGTH','NDVI','DEM','CUR','ASP','PLCUR','POCUR','PH','DL','SC2','OSJL','SOM','DZ']\n",
    "feature_list = ['AP','PRE','TMP','SOILQS','NIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练点数据集采样并输出到csv文件\n",
    "# 选择用于采样的数据库\n",
    "env.workspace = stander_raster_gdb # 切换工作空间用于采样\n",
    "# 选择用于采样的要素类\n",
    "point_data = point_data\n",
    "# 使用Delete_management函数删除数据库中的所有内容\n",
    "try:\n",
    "    arcpy.Delete_management(sample_gdb_path)\n",
    "except:\n",
    "    pass\n",
    "# 再创建一个新的数据库\n",
    "arcpy.management.CreateFileGDB(os.path.dirname(sample_gdb_path), \"test\", \"CURRENT\")\n",
    "# 逐个采样并保存到csv文件\n",
    "for one_feature in feature_list:\n",
    "    sample_point(point_data,one_feature,os.path.join(sample_gdb_path,one_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = os.path.join(sample_gdb_path) # 切换工作空间用于导出csv文件\n",
    "# 读取数据表并保存到csv文件\n",
    "result_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(point_data,filter_list))\n",
    "result_df.rename(columns={\"OBJECTID\":sample_name},inplace=True)\n",
    "#  读取每个表的最后一个字段的数据,存储每个表的最后一个字段的数据\n",
    "for table in feature_list:\n",
    "    # 将表转换为pandas数据帧\n",
    "    df = pd.DataFrame(arcpy.da.TableToNumPyArray(table, \"*\"))  # 确保数据表中无空值\n",
    "    # 提取最后一个字段的数据\n",
    "    merged_df = df[[sample_name, df.columns[-1]]]\n",
    "    # 合并\n",
    "    result_df = pd.merge(result_df, merged_df, on=[sample_name])\n",
    "# 保存到csv文件\n",
    "result_df.rename(columns=dict(zip(result_df.columns[-len(feature_list):], feature_list)),inplace=True)\n",
    "result_df.drop(result_df.columns[0],axis=1,inplace=True)\n",
    "# result_df.rename(columns={\"PH\":\"PH_T\"},inplace=True)\n",
    "result_df.to_csv(os.path.join(sample_csv,sample_csv_name),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
