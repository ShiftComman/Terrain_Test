{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-dab7bd971016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,roc_auc_score,roc_curve,precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "# from autogluon.tabular import TabularPredictor,TabularDataset\n",
    "# import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _arcgisscripting: 找不到指定的程序。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39marcpy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marcpy\u001b[39;00m \u001b[39mimport\u001b[39;00m env\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marcpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmanagement\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\__init__.py:77\u001b[0m\n\u001b[0;32m     74\u001b[0m         sys\u001b[39m.\u001b[39margv \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     75\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39m_initagsenv\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marcpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeoprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m gp\n\u001b[0;32m     78\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marcpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeoprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m env\n\u001b[0;32m     79\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39marcpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeoprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m gptooldoc \u001b[39mas\u001b[39;00m _gptooldoc\n",
      "File \u001b[1;32mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\__init__.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#COPYRIGHT 2018 ESRI\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#TRADE SECRETS: ESRI PROPRIETARY AND CONFIDENTIAL\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#email: contracts@esri.com\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_base\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py:14\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#COPYRIGHT 2018 ESRI\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#TRADE SECRETS: ESRI PROPRIETARY AND CONFIDENTIAL\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#email: contracts@esri.com\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39marcgisscripting\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfunctools\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m\"\"\"Geoprocessing wrapper for the arcgisscripting library. Attempts to organize/make usage easier.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Program Files\\ArcGIS\\clone_env\\arcgispro_clone\\lib\\site-packages\\arcgisscripting\\__init__.py:131\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mactive_pyd_pth\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m():\u001b[39mdel\u001b[39;00m(active_pyd_pth)\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mpristine_pyd_pth\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mlocals\u001b[39m():\u001b[39mdel\u001b[39;00m(pristine_pyd_pth)\n\u001b[1;32m--> 131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_arcgisscripting\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    132\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_arcgisscripting\u001b[39;00m \u001b[39mimport\u001b[39;00m _addTimeInterval, _analyzeForSD, _attachLocator, \\\n\u001b[0;32m    133\u001b[0m     _convertWebMapToMapDocument, _createGISServerConnectionFile, \\\n\u001b[0;32m    134\u001b[0m     _createGeocodeSDDraft, _createMapSDDraft, _createimageservicesddraft, \\\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     _setRasterKeyMetadata, _sharing, _ss, _wrapLocalFunctionRaster, \\\n\u001b[0;32m    139\u001b[0m     _wrapToolRaster, _ia\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _arcgisscripting: 找不到指定的程序。"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.management import *\n",
    "from arcpy.sa import *\n",
    "from arcpy.da import *\n",
    "from arcpy.conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析函数\n",
    "# 取消并行处理\n",
    "def disable_parallel_processing(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with arcpy.EnvManager(parallelProcessingFactor=\"0\"):\n",
    "            return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "# 采样\n",
    "def sample_point(point_,raster_,out_name):\n",
    "    \"\"\"根据栅格采样点,输出为表格\"\"\"\n",
    "    Sample(raster_,point_,out_name,\"NEAREST\", \"OBJECTID\", \"CURRENT_SLICE\", None, '', None, None, \"ROW_WISE\", \"TABLE\")\n",
    "    return None\n",
    "\n",
    "# 导出CSV\n",
    "def export_csv(table_,out_path,out_name):\n",
    "    TableToTable(table_,out_path,out_name)\n",
    "    return None\n",
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster\n",
    "# 数组整形\n",
    "def resize_arrays(A, B, fill_value=0):\n",
    "    \"\"\"调整数组形状一致,A为参考数组, B为待调整数组, fill_value为填充值\"\"\"\n",
    "    # new_shape = (max(A.shape[0], B.shape[0]), max(A.shape[1], B.shape[1]))\n",
    "    new_shape = (A.shape[0], A.shape[1])\n",
    "\n",
    "    if A.shape != new_shape:\n",
    "        if A.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - A.shape[0]\n",
    "            padding = np.full((padding_rows, A.shape[1]), fill_value)\n",
    "            A = np.vstack((A, padding))\n",
    "        elif A.shape[0] > new_shape[0]:\n",
    "            A = A[:new_shape[0], :]\n",
    "\n",
    "        if A.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - A.shape[1]))\n",
    "            A = np.pad(A, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif A.shape[1] > new_shape[1]:\n",
    "            A = A[:, :new_shape[1]]\n",
    "    \n",
    "    if B.shape != new_shape:\n",
    "        if B.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - B.shape[0]\n",
    "            padding = np.full((padding_rows, B.shape[1]), fill_value)\n",
    "            B = np.vstack((B, padding))\n",
    "        elif B.shape[0] > new_shape[0]:\n",
    "            B = B[:new_shape[0], :]\n",
    "\n",
    "        if B.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - B.shape[1]))\n",
    "            B = np.pad(B, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif B.shape[1] > new_shape[1]:\n",
    "            B = B[:, :new_shape[1]]\n",
    "    \n",
    "    return A, B\n",
    "# rf寻找最优参数\n",
    "def rf_best_param(X_train,y_train,n_estimators_range,k=5):\n",
    "    \"\"\"默认为5折交叉验证,评价指标为R2\"\"\"\n",
    "    # 设置树的数目范围\n",
    "    n_estimators_range = n_estimators_range\n",
    "    cv_scores = []\n",
    "    # 使用交叉验证\n",
    "    for n_estimators in n_estimators_range:\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, random_state=0)\n",
    "        scores = cross_val_score(rf,X_train, y_train, cv=k, scoring='accuracy')  # K折交叉验证 分类问题默认使用accuracy\n",
    "        cv_scores.append(scores.mean())\n",
    "    # 选择最优数量的树\n",
    "    optimal_n_estimators = n_estimators_range[cv_scores.index(max(cv_scores))]\n",
    "    return optimal_n_estimators\n",
    "\n",
    "# arcpy栅格众数滤波\n",
    "@disable_parallel_processing\n",
    "def mode_filter(in_raster,filter_size=\"FOUR\",filter_method=\"MAJORITY\"):\n",
    "    \"\"\"栅格众数滤波,filter_size:滤波窗口大小,filter_method:滤波方法\"\"\"\n",
    "    result_raster = MajorityFilter(in_raster, filter_size, filter_method) # 默认为4邻域 众数滤波  可选为8邻域 半数滤波\n",
    "    return result_raster\n",
    "    \n",
    "# arcpy栅格边界清理\n",
    "@disable_parallel_processing\n",
    "def clean_boundary(in_raster,sort_method=\"NO_SORT\",clean_method=\"TWO_WAY\"):\n",
    "    \"\"\"栅格边界清理,sort_method:排序方法,clean_method:清理方法\"\"\"\n",
    "    result_raster = BoundaryClean(in_raster, \"NO_SORT\", \"TWO_WAY\") # 默认为不排序 两边清理 可选为排序 一边清理\n",
    "    return result_raster\n",
    "# arcpy栅格区域分组\n",
    "@disable_parallel_processing\n",
    "def region_group(in_raster,group_size=\"FOUR\",method=\"WITHIN\",add_link=\"ADD_LINK\",clear=None):\n",
    "    \"\"\"栅格区域分组,group_size:分组大小,method:分组方法,add_link:添加链接,clear:排除的值\"\"\"\n",
    "    result_raster = RegionGroup(in_raster, group_size, method, add_link, clear) # 默认为4邻域 分组方法为WITHIN 可选为8邻域 分组方法为CROSS\n",
    "    return result_raster\n",
    "# arcpy栅格按属性提取\n",
    "@disable_parallel_processing\n",
    "def extract_by_attributes(in_raster,where_clause=\"count >= 100\"):\n",
    "    \"\"\"栅格按属性提取,where_clause:属性条件\"\"\"\n",
    "    result_raster = ExtractByAttributes(in_raster, where_clause) # 默认为count >= 100\n",
    "    return result_raster\n",
    "\n",
    "# arcpy栅格Nibble\n",
    "@disable_parallel_processing\n",
    "def nibble(in_raster,mask_raster, nibble_mask=\"ALL_VALUES\", nibble_values=\"PRESERVE_NODATA\"):\n",
    "    \"\"\"栅格Nibble,nibble_mask:掩膜,nibble_values:填充值\"\"\"\n",
    "    result_raster = Nibble(in_raster, mask_raster,nibble_mask, nibble_values) # 默认为ALL_VALUES PRESERVE_NODATA 可选为DATA_ONLY PRESERVE_DATA\n",
    "    return result_raster\n",
    "\n",
    "# arcpy栅格查找表\n",
    "@disable_parallel_processing\n",
    "def lookup(in_raster,lookup_field=\"LINK\"):\n",
    "    \"\"\"栅格查找表,lookup_field:查找字段\"\"\"\n",
    "    result_raster = Lookup(in_raster, lookup_field) # 默认为LINK\n",
    "    return result_raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地理数据库路径\n",
    "base_gdb_5m = r\"D:\\ArcgisData\\basedata\\basetrain_5m.gdb\"\n",
    "base_gdb_30m = r\"D:\\ArcgisData\\basedata\\basetrain_30m.gdb\"\n",
    "# 数据点文件路径\n",
    "point_data = r\"D:\\ArcgisData\\pred_tl\\pred_database\\pred_tl.gdb\\ALL_POINT\"  # 需要改变\n",
    "# 存储采样数据表的文件地理数据库\n",
    "sample_gdb_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\test.gdb\" # 需要改变\n",
    "# 存储采样结果CSV文件的路径\n",
    "sample_csv = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\feature_table_result\"\n",
    "# 输出CSV文件的名称\n",
    "sample_csv_name = \"feature_table_result.csv\" # 需要改变\n",
    "# 目标标签\n",
    "target_label = \"土类\"\n",
    "# 随机森林树的范围\n",
    "n_estimators_range = range(10, 2000, 10)\n",
    "# 模型存储路径\n",
    "modle_save_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\test_modle\" # 需要改变\n",
    "# 栅格输出标准化的数据库\n",
    "stander_raster_gdb = base_gdb_5m\n",
    "# 标准化待预测数据分割路径\n",
    "cut_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\cut_csv\" # 需要改变\n",
    "# 预测完成CSV文件存储路径\n",
    "pred_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\pred_csv\" # 需要改变\n",
    "# 完整预测数据存储路径\n",
    "merge_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\test\\merge_csv\" # 需要改变\n",
    "# 完整预测数据存储名称\n",
    "merge_csv_name = \"merge_sdt.csv\" # 需要改变\n",
    "# 栅格输出预测结果数据库\n",
    "pred_raster_gdb = r\"D:\\ArcgisData\\pred_tl\\pred_database\\TL_basedata.gdb\"\n",
    "# 栅格输出预测结果栅格名称\n",
    "pred_raster_name = \"TEST\" # 需要改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
