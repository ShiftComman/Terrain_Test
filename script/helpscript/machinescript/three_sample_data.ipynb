{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import arcpy\n",
    "from arcpy import env\n",
    "from arcpy.management import *\n",
    "from arcpy.sa import *\n",
    "from arcpy.da import *\n",
    "from arcpy.conversion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析函数\n",
    "# 取消并行处理\n",
    "def disable_parallel_processing(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with arcpy.EnvManager(parallelProcessingFactor=\"0\"):\n",
    "            return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "# 采样\n",
    "def sample_point(point_,raster_,out_name):\n",
    "    \"\"\"根据栅格采样点,输出为表格\"\"\"\n",
    "    Sample(raster_,point_,out_name,\"NEAREST\", \"OBJECTID\", \"CURRENT_SLICE\", None, '', None, None, \"ROW_WISE\", \"TABLE\")\n",
    "    return None\n",
    "\n",
    "# 导出CSV\n",
    "def export_csv(table_,out_path,out_name):\n",
    "    TableToTable(table_,out_path,out_name)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地理数据库路径\n",
    "# base_gdb_5m = r\"D:\\ArcgisData\\basedata\\basetrain_5m.gdb\"\n",
    "base_gdb_5m = r\"D:\\ArcGISProjects\\workspace\\shbyq\\features_data_dy.gdb\"\n",
    "# base_gdb_deep = r\"D:\\ArcgisData\\pred_soildeep\\pre_database\\pred_soildeep_gz.gdb\"\n",
    "# 用于采样的标准数据库\n",
    "stander_raster_gdb = base_gdb_5m\n",
    "# 数据点文件路径\n",
    "point_data = r\"D:\\ArcGISProjects\\workspace\\shbyq\\features_data_vector.gdb\\features\\dy_point\"  # 需要改变\n",
    "# 存储采样数据表的文件地理数据库\n",
    "sample_gdb_path = r\"D:\\ArcGISProjects\\workspace\\process_table_database\\tabledata.gdb\" # 需要改变\n",
    "# 存储采样结果CSV文件的路径\n",
    "sample_csv = r\"D:\\ArcGISProjects\\workspace\\shbyq\\resule_table\"\n",
    "# 输出CSV文件的名称\n",
    "sample_csv_name = \"feature_dy_ph.csv\" # 需要改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'lon', 'lat', 'B', 'Cu', 'Mn', 'N', 'P', 'Zn', 'K2O', 'som', 'pH']\n",
      "['OBJECTID', 'pH']\n"
     ]
    }
   ],
   "source": [
    "# 采样点数据名称\n",
    "sample_name = 'dy_point'\n",
    "filed_list = [_.name for _ in arcpy.ListFields(point_data)]\n",
    "print(filed_list)\n",
    "# 需要保留的字段\n",
    "# elements_yes = ['OBJECTID', '横坐标', '纵坐标', 'N', 'P', 'K2O', '有机质含量', 'pH']\n",
    "elements_yes = ['OBJECTID', 'pH']\n",
    "filter_list = [_ for _ in filed_list if _ in elements_yes]\n",
    "print(filter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采集的特征字段\n",
    "# feature_list = ['BIO', 'PRE', 'SRA', 'TMP', 'VAP', 'WIN', 'DEM', 'NDVI', 'TDQS', 'LIGHT', 'LON', 'LAT', 'SLOPE', 'ASP', 'CUR', 'TWI3', 'TWI5', 'TPI3', 'TPI5']\n",
    "feature_list = ['DEM', 'AnalyticalHillshading', 'Aspect', 'ChannelNetworkBaseLevel', 'ChannelNetworkDistance', 'ClosedDepressions', 'ConvergenceIndex', 'LSFactor', 'PlanCurvature', 'ProfileCurvature', 'RelativeSlopePosition', 'Slope', 'TopographicWetnessIndex', 'TotalCatchmentArea', 'ValleyDepth', 'Contrast', 'Correlation', 'Dissimilarity', 'Entropy', 'Homogeneity', 'Mean', 'ndvi', 'PCA_0', 'PCA_1', 'SecondMoment', 'Variance', 'PRE', 'SRA', 'TMP', 'VAP', 'WIND', 'BIO', 'LON', 'LAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEM\n",
      "AnalyticalHillshading\n",
      "Aspect\n",
      "ChannelNetworkBaseLevel\n",
      "ChannelNetworkDistance\n",
      "ClosedDepressions\n",
      "ConvergenceIndex\n",
      "LSFactor\n",
      "PlanCurvature\n",
      "ProfileCurvature\n",
      "RelativeSlopePosition\n",
      "Slope\n",
      "TopographicWetnessIndex\n",
      "TotalCatchmentArea\n",
      "ValleyDepth\n",
      "Contrast\n",
      "Correlation\n",
      "Dissimilarity\n",
      "Entropy\n",
      "Homogeneity\n",
      "Mean\n",
      "ndvi\n",
      "PCA_0\n",
      "PCA_1\n",
      "SecondMoment\n",
      "Variance\n",
      "PRE\n",
      "SRA\n",
      "TMP\n",
      "VAP\n",
      "WIND\n",
      "BIO\n",
      "LON\n",
      "LAT\n"
     ]
    }
   ],
   "source": [
    "# 使用训练点数据集采样并输出到csv文件\n",
    "# 选择用于采样的数据库\n",
    "env.workspace = stander_raster_gdb # 切换工作空间用于采样\n",
    "# 选择用于采样的要素类\n",
    "point_data = point_data\n",
    "# 使用Delete_management函数删除数据库中的所有内容\n",
    "try:\n",
    "    arcpy.Delete_management(sample_gdb_path)\n",
    "except:\n",
    "    pass\n",
    "# 再创建一个新的数据库\n",
    "arcpy.management.CreateFileGDB(os.path.dirname(sample_gdb_path), \"tabledata\", \"CURRENT\")\n",
    "# 逐个采样并保存到csv文件\n",
    "for one_feature in feature_list:\n",
    "    print(one_feature)\n",
    "    sample_point(point_data,one_feature,os.path.join(sample_gdb_path,one_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.workspace = os.path.join(sample_gdb_path) # 切换工作空间用于导出csv文件\n",
    "# 读取数据表并保存到csv文件\n",
    "result_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(point_data,filter_list))\n",
    "result_df.rename(columns={\"OBJECTID\":sample_name},inplace=True)\n",
    "#  读取每个表的最后一个字段的数据,存储每个表的最后一个字段的数据\n",
    "for table in feature_list:\n",
    "    # 将表转换为pandas数据帧\n",
    "    df = pd.DataFrame(arcpy.da.TableToNumPyArray(table, \"*\"))  # 确保数据表中无空值\n",
    "    # 提取最后一个字段的数据\n",
    "    merged_df = df[[sample_name, df.columns[-1]]]\n",
    "    # 合并\n",
    "    result_df = pd.merge(result_df, merged_df, on=[sample_name])\n",
    "# 保存到csv文件\n",
    "result_df.rename(columns=dict(zip(result_df.columns[-len(feature_list):], feature_list)),inplace=True)\n",
    "result_df.drop(result_df.columns[0],axis=1,inplace=True)\n",
    "# result_df.rename(columns={\"PH\":\"PH_T\"},inplace=True)\n",
    "result_df.to_csv(os.path.join(sample_csv,sample_csv_name),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
