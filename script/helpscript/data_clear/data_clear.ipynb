{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据连接和清洗 基于xjsh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_file_with_string(path, string):\n",
    "    \"\"\"获取指定路径下包含指定字符串的文件路径,优先选择csv文件\"\"\"\n",
    "    result_files = []\n",
    "    \n",
    "    # 遍历目录获取所有csv和xlsx文件\n",
    "    for root, _, files in os.walk(path):\n",
    "        # 先添加所有csv文件\n",
    "        for file in files:\n",
    "            if string in file and file.endswith('.csv'):\n",
    "                result_files.append(os.path.join(root, file))\n",
    "                \n",
    "        # 再添加不重名的xlsx文件\n",
    "        csv_names = {os.path.splitext(os.path.basename(f))[0] for f in result_files}\n",
    "        for file in files:\n",
    "            if string in file and file.endswith('.xlsx'):\n",
    "                name = os.path.splitext(os.path.basename(file))[0]\n",
    "                if name not in csv_names:\n",
    "                    result_files.append(os.path.join(root, file))\n",
    "    \n",
    "    if not result_files:\n",
    "        raise FileNotFoundError(f\"在{path}路径下未找到包含{string}的csv或xlsx文件\")\n",
    "        \n",
    "    return result_files\n",
    "# 输入excel或csv文件路径列表，合并excel或cv文件为一个DataFrame\n",
    "def merge_excel_files(file_list,use_columns):\n",
    "    df_list = []\n",
    "    for file in file_list:\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file,usecols=use_columns)\n",
    "        elif file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(file,usecols=use_columns)\n",
    "        df_list.append(df)\n",
    "    # 合并所有DataFrame为一个\n",
    "    merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# province_name\n",
    "province_name = '贵州省'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析对象路径\n",
    "folder_path = rf'F:\\collection_spb_info\\XJSH\\ALL_DATA\\ALL_BASE\\{province_name}'\n",
    "# 检测信息对象路径\n",
    "ch_data_path = rf'F:\\collection_spb_info\\XJSH\\ALL_DATA\\ALL_JCJG\\{province_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_file_list = find_file_with_string(folder_path, 'base_info')\n",
    "ldtj_file_list = find_file_with_string(folder_path, 'ldtj_info')\n",
    "pm_file_list = find_file_with_string(folder_path, 'pm_info')\n",
    "ch_file_list = find_file_with_string(ch_data_path, 'all_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "base_df = merge_excel_files(base_file_list,base_info_list)\n",
    "ldtj_df = merge_excel_files(ldtj_file_list,ldtj_info_list)\n",
    "pm_df = merge_excel_files(pm_file_list,pm_info_list)\n",
    "ch_df = merge_excel_files(ch_file_list,phy_che_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先连接前两个表\n",
    "df_temp1 = pd.merge(base_df, ldtj_df, on='ydbh', how='left')\n",
    "# 再连接第三个表\n",
    "df_temp2 = pd.merge(df_temp1, pm_df, on='ydbh', how='left')\n",
    "# 最后连接第四个表\n",
    "df_base_ch = pd.merge(df_temp2, ch_df, on='ydbh', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 替换指定列中的非数值型值为0.0001\n",
    "for one_col in phy_che_list[:-1]:\n",
    "    df_base_ch[one_col] = pd.to_numeric(df_base_ch[one_col], errors='coerce').fillna(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "from datetime import datetime\n",
    "\n",
    "# 将所有列转换为适当的数据类型\n",
    "df_base_ch['ydbh'] = df_base_ch['ydbh'].astype('str')\n",
    "df_base_ch['yypbh'] = df_base_ch['yypbh'].astype('str')\n",
    "# 给ydbh,yypbh第一位加T\n",
    "df_base_ch['ydbht'] = 'T' + df_base_ch['ydbh']\n",
    "df_base_ch['yypbht'] = 'T' + df_base_ch['yypbh']\n",
    "\n",
    "# 将数值型列转换为float类型并填充0.0001\n",
    "numeric_columns = df_base_ch.select_dtypes(include=['int32', 'float32', 'int64', 'float64']).columns\n",
    "for col in numeric_columns:\n",
    "    df_base_ch[col] = df_base_ch[col].astype('float32').fillna(0.0001)\n",
    "\n",
    "# 将字符串列转换为string类型并填充空字符串\n",
    "string_columns = df_base_ch.select_dtypes(include=['object']).columns\n",
    "for col in string_columns:\n",
    "    df_base_ch[col] = df_base_ch[col].astype('string').fillna('')\n",
    "\n",
    "# 保存路径\n",
    "save_path = rf\"F:\\collection_spb_info\\XJSH\\ALL_DATA\\ALL_RESULT\\{province_name}_all_info_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
    "\n",
    "# 获取目录，如果没有则创建\n",
    "if not os.path.exists(os.path.dirname(save_path)):\n",
    "    os.makedirs(os.path.dirname(save_path))\n",
    "else:\n",
    "    print(\"目录已存在\")\n",
    "\n",
    "# 保存时指定数据类型,并设置dtype参数\n",
    "df_base_ch.to_csv(save_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(save_path,encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_ch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历df_result中的每一列\n",
    "for column in df_base_ch.columns[4:-1]:\n",
    "    # 检查列的数据类型是否为数值型\n",
    "    if pd.api.types.is_numeric_dtype(df_base_ch[column]):\n",
    "        # 创建一个图和两个子图\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        # 在第一个子图上绘制直方图\n",
    "        sns.histplot(df_base_ch[column], kde=False, bins=30, ax=ax[0])\n",
    "        ax[0].set_title(f'{column} Histogram')\n",
    "        ax[0].set_xlabel(column)\n",
    "        ax[0].set_ylabel('Frequency')\n",
    "\n",
    "        # 在第二个子图上绘制正态分布检验图\n",
    "        stats.probplot(df_base_ch[column], plot=ax[1])\n",
    "        ax[1].set_title(f'{column} Normal Q-Q Plot')\n",
    "\n",
    "        # 调整布局并显示图\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
