{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组整形\n",
    "def resize_arrays(A, B, fill_value=0):\n",
    "    \"\"\"调整数组形状一致\"\"\"\n",
    "    new_shape = (max(A.shape[0], B.shape[0]), max(A.shape[1], B.shape[1]))\n",
    "\n",
    "    if A.shape != new_shape:\n",
    "        if A.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - A.shape[0]\n",
    "            padding = np.full((padding_rows, A.shape[1]), fill_value)\n",
    "            A = np.vstack((A, padding))\n",
    "        elif A.shape[0] > new_shape[0]:\n",
    "            A = A[:new_shape[0], :]\n",
    "\n",
    "        if A.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - A.shape[1]))\n",
    "            A = np.pad(A, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif A.shape[1] > new_shape[1]:\n",
    "            A = A[:, :new_shape[1]]\n",
    "    \n",
    "    if B.shape != new_shape:\n",
    "        if B.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - B.shape[0]\n",
    "            padding = np.full((padding_rows, B.shape[1]), fill_value)\n",
    "            B = np.vstack((B, padding))\n",
    "        elif B.shape[0] > new_shape[0]:\n",
    "            B = B[:new_shape[0], :]\n",
    "\n",
    "        if B.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - B.shape[1]))\n",
    "            B = np.pad(B, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif B.shape[1] > new_shape[1]:\n",
    "            B = B[:, :new_shape[1]]\n",
    "    \n",
    "    return A, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor = TabularPredictor(label=label).fit(train_data,time_limit=600)\n",
    "predictor = TabularPredictor.load(r\"D:\\ArcgisData\\pred_ph\\ph_pred_moudle\\normal3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TWI5',\n",
       " 'TPI201',\n",
       " 'TMP',\n",
       " 'SLOP',\n",
       " 'PRE',\n",
       " 'NIGTH',\n",
       " 'NDVI',\n",
       " 'DZ',\n",
       " 'DL',\n",
       " 'LON',\n",
       " 'LAT']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_metadata_in.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEM',\n",
       " 'TWI_5',\n",
       " 'TPI_201',\n",
       " 'TPI_101',\n",
       " 'TPI_11',\n",
       " 'TPI_3',\n",
       " 'TMP',\n",
       " 'SOILQS',\n",
       " 'SLOP',\n",
       " 'PRE',\n",
       " 'NIGTH',\n",
       " 'NDVI',\n",
       " 'CUR',\n",
       " 'ASP',\n",
       " 'PLCUR',\n",
       " 'POCUR',\n",
       " 'OSJL',\n",
       " 'LAT',\n",
       " 'LON',\n",
       " 'DZ',\n",
       " 'DL']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置工作环境\n",
    "env.workspace = r\"D:\\ArcgisData\\basedata\\basetrain_30m.gdb\"\n",
    "arcpy.ListRasters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TWI_5', 'TPI_201', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI', 'DZ', 'DL'], 9, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 过滤所用的特征因子\n",
    "check_list = ['TWI_5', 'TPI_201', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI', 'DZ', 'DL']\n",
    "feature_list = [_ for _ in arcpy.ListRasters() if _ in check_list ]\n",
    "feature_list,len(feature_list),len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWI_5 (2481, 1849)\n",
      "TPI_201 (2481, 1849)\n",
      "TMP (2481, 1849)\n",
      "SLOP (2481, 1849)\n",
      "PRE (2481, 1849)\n",
      "NIGTH (2481, 1849)\n",
      "NDVI (2481, 1849)\n",
      "DZ (2481, 1849)\n",
      "DL (2481, 1849)\n"
     ]
    }
   ],
   "source": [
    "for one_raster in feature_list:\n",
    "    print(one_raster,arcpy.RasterToNumPyArray(one_raster).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_array = arcpy.RasterToNumPyArray(\"DEM\")\n",
    "dl_array = arcpy.RasterToNumPyArray(\"DL\")\n",
    "dz_array = arcpy.RasterToNumPyArray(\"DZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2481, 1849), (2481, 1849))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_array = resize_arrays(dem_array,dz_array,8)[1]\n",
    "dl_array = resize_arrays(dem_array,dz_array,9)[1]\n",
    "dz_array.shape,dl_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(['TWI_5', 'TPI_201', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI', 'DZ'], 8, 8)\n",
    "# asp = arcpy.RasterToNumPyArray(\"ASP\").flatten()\n",
    "# dem = arcpy.RasterToNumPyArray(\"DEM\").flatten()\n",
    "dl = dl_array.flatten()\n",
    "ndvi = arcpy.RasterToNumPyArray(\"NDVI\").flatten()\n",
    "night = arcpy.RasterToNumPyArray(\"NIGTH\").flatten()\n",
    "pre = arcpy.RasterToNumPyArray(\"PRE\").flatten()\n",
    "slope = arcpy.RasterToNumPyArray(\"SLOP\").flatten()\n",
    "# soilqs = arcpy.RasterToNumPyArray(\"SOILQS\").flatten()\n",
    "tmp = arcpy.RasterToNumPyArray(\"TMP\").flatten()\n",
    "# tpi11 = arcpy.RasterToNumPyArray(\"TPI_11\").flatten()\n",
    "# tpi101 = arcpy.RasterToNumPyArray(\"TPI_101\").flatten()\n",
    "tpi201 = arcpy.RasterToNumPyArray(\"TPI_201\").flatten()\n",
    "# tpi3 = arcpy.RasterToNumPyArray(\"TPI_3\").flatten()\n",
    "twi5 = arcpy.RasterToNumPyArray(\"TWI_5\").flatten()\n",
    "dz = dz_array.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(arcpy.RasterToNumPyArray(\"NDVI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397387.5 3153427.5 30.0 30.0\n"
     ]
    }
   ],
   "source": [
    "# 构造经纬度信息\n",
    "desc = arcpy.Describe(\"DEM\")\n",
    "origin_x = desc.extent.XMin\n",
    "origin_y = desc.extent.YMax\n",
    "pixel_width = desc.meanCellWidth\n",
    "pixel_height = desc.meanCellHeight\n",
    "print(origin_x,origin_y,pixel_width,pixel_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2481, 1849) 397432.5 452842.5\n"
     ]
    }
   ],
   "source": [
    "# 经度\n",
    "array_x = np.zeros(dem_array.shape, dtype=np.float32)\n",
    "array_x[:, 0] = 397387.5+(pixel_width/2)\n",
    "for i in range(1, dem_array.shape[1]):\n",
    "    array_x[:, i] = array_x[:, i-1] + pixel_width\n",
    "print(array_x.shape,array_x[0,1],array_x[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2481, 1849) 3153442.5 3079042.5\n"
     ]
    }
   ],
   "source": [
    "# 纬度\n",
    "array_y = np.zeros(dem_array.shape,dtype=np.float32)\n",
    "array_y[0] = 3153427.5+(pixel_height/2)\n",
    "for i in range(1, dem_array.shape[0]):\n",
    "    array_y[i] = array_y[i-1] - pixel_height\n",
    "print(array_y.shape,array_y[0][0],array_y[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array_x.flatten()\n",
    "y = array_y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2 = np.column_stack((x,y,asp,dem,dl,ndvi,nigth,pre,slope,soilqs,tmp,tpi11,tpi101,tpi201,tpi3,twi5,dz))\n",
    "features2 = np.column_stack((twi5,tpi201,tmp,slope,pre,night,ndvi,dz,dl,x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50461059"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.9965148e+00, 4.2540405e+01, 1.2275000e+02, 1.5501679e+01,\n",
       "       9.1250000e+02, 1.6000000e-01, 3.2400000e+02, 6.0000000e+00,\n",
       "       6.0000000e+00, 4.1126250e+05, 3.1485825e+06], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2[300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xulian_data = pd.DataFrame(features2,columns=['X','Y','ASP','DEM','DL','NDVI','NIGHT','PRE','SLOPE','SOILQS','TMP','TPI11','TPI101','TPI201','TPI3','TWI5','DZ'])\n",
    "\n",
    "xulian_data = pd.DataFrame(features2,columns=predictor.feature_metadata_in.get_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587369, 11)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TWI5      float32\n",
       "TPI201    float32\n",
       "TMP       float32\n",
       "SLOP      float32\n",
       "PRE       float32\n",
       "NIGTH     float32\n",
       "NDVI      float32\n",
       "DZ        float32\n",
       "DL        float32\n",
       "LON       float32\n",
       "LAT       float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xulian_data['DL'] = xulian_data['DL'].astype(str)\n",
    "xulian_data['DZ'] = xulian_data['DZ'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TWI5      float32\n",
       "TPI201    float32\n",
       "TMP       float32\n",
       "SLOP      float32\n",
       "PRE       float32\n",
       "NIGTH     float32\n",
       "NDVI      float32\n",
       "DZ         object\n",
       "DL         object\n",
       "LON       float32\n",
       "LAT       float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWI5</th>\n",
       "      <th>TPI201</th>\n",
       "      <th>TMP</th>\n",
       "      <th>SLOP</th>\n",
       "      <th>PRE</th>\n",
       "      <th>NIGTH</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.957590e+00</td>\n",
       "      <td>5.391708e-02</td>\n",
       "      <td>9.103070e+01</td>\n",
       "      <td>1.641409e+01</td>\n",
       "      <td>5.175721e+02</td>\n",
       "      <td>2.461364e-01</td>\n",
       "      <td>1.472668e+03</td>\n",
       "      <td>4.251226e+05</td>\n",
       "      <td>3.116243e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.687172e+00</td>\n",
       "      <td>3.791690e+01</td>\n",
       "      <td>7.224962e+01</td>\n",
       "      <td>1.707998e+01</td>\n",
       "      <td>4.083257e+02</td>\n",
       "      <td>1.025573e+00</td>\n",
       "      <td>2.307893e+03</td>\n",
       "      <td>1.601281e+04</td>\n",
       "      <td>2.148609e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.508924e-02</td>\n",
       "      <td>-3.219223e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.974025e+05</td>\n",
       "      <td>3.079042e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-9.991333e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.112625e+05</td>\n",
       "      <td>3.097642e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.428443e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.369167e+02</td>\n",
       "      <td>1.308498e+01</td>\n",
       "      <td>8.211667e+02</td>\n",
       "      <td>2.200000e-01</td>\n",
       "      <td>1.830000e+02</td>\n",
       "      <td>4.251225e+05</td>\n",
       "      <td>3.116242e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.885564e+00</td>\n",
       "      <td>9.828369e+00</td>\n",
       "      <td>1.522500e+02</td>\n",
       "      <td>2.974471e+01</td>\n",
       "      <td>8.399167e+02</td>\n",
       "      <td>2.800000e-01</td>\n",
       "      <td>2.311000e+03</td>\n",
       "      <td>4.389825e+05</td>\n",
       "      <td>3.134842e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.508574e+01</td>\n",
       "      <td>2.500112e+02</td>\n",
       "      <td>1.696667e+02</td>\n",
       "      <td>8.459243e+01</td>\n",
       "      <td>9.326667e+02</td>\n",
       "      <td>4.469000e+01</td>\n",
       "      <td>9.773000e+03</td>\n",
       "      <td>4.528425e+05</td>\n",
       "      <td>3.153442e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TWI5        TPI201           TMP          SLOP           PRE  \\\n",
       "count  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06   \n",
       "mean   2.957590e+00  5.391708e-02  9.103070e+01  1.641409e+01  5.175721e+02   \n",
       "std    2.687172e+00  3.791690e+01  7.224962e+01  1.707998e+01  4.083257e+02   \n",
       "min   -4.508924e-02 -3.219223e+02  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00 -9.991333e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    3.428443e+00  0.000000e+00  1.369167e+02  1.308498e+01  8.211667e+02   \n",
       "75%    4.885564e+00  9.828369e+00  1.522500e+02  2.974471e+01  8.399167e+02   \n",
       "max    2.508574e+01  2.500112e+02  1.696667e+02  8.459243e+01  9.326667e+02   \n",
       "\n",
       "              NIGTH          NDVI           LON           LAT  \n",
       "count  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06  \n",
       "mean   2.461364e-01  1.472668e+03  4.251226e+05  3.116243e+06  \n",
       "std    1.025573e+00  2.307893e+03  1.601281e+04  2.148609e+04  \n",
       "min    0.000000e+00  0.000000e+00  3.974025e+05  3.079042e+06  \n",
       "25%    0.000000e+00  0.000000e+00  4.112625e+05  3.097642e+06  \n",
       "50%    2.200000e-01  1.830000e+02  4.251225e+05  3.116242e+06  \n",
       "75%    2.800000e-01  2.311000e+03  4.389825e+05  3.134842e+06  \n",
       "max    4.469000e+01  9.773000e+03  4.528425e+05  3.153442e+06  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400000\n",
      "800000\n",
      "1200000\n",
      "1600000\n",
      "2000000\n",
      "2400000\n",
      "2800000\n",
      "3200000\n",
      "3600000\n",
      "4000000\n",
      "4400000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "out_path = r\"D:\\ArcgisData\\pred_ph\\out_table_30m\\cut_csv\"\n",
    "chunk_size = 400000\n",
    "total_rows = xulian_data.shape[0]\n",
    "for i in range(0, total_rows, chunk_size):\n",
    "    start = i\n",
    "    end = min(i + chunk_size, total_rows)\n",
    "    filename =  os.path.join(out_path,f'data_chunk_{i}.csv') # 文件名格式可以根据您的需要进行修改\n",
    "    df_chunk = xulian_data.iloc[start:end]\n",
    "    df_chunk.to_csv(filename, index=False)\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_0.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_1200000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_1600000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2000000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2800000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_3200000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_3600000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_4000000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_4400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_800000.csv'],\n",
       " 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取特征表\n",
    "table_list = [os.path.join(out_path,_) for _ in os.listdir(out_path)]\n",
    "table_list,len(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_0.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_400000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_800000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_1200000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_1600000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2000000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2400000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_2800000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_3200000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_3600000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_4000000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\cut_csv\\\\data_chunk_4400000.csv']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 排序列表\n",
    "\n",
    "# 使用lambda函数将文件名按照最后一个下划线后面的数字大小进行排序\n",
    "sorted_files = sorted(table_list, key=lambda x: int(x.rsplit('_', 1)[-1].split('.')[0]))\n",
    "sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测数据存储位置\n",
    "result_path = r\"D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for one_table in sorted_files:\n",
    "    data_df = pd.read_csv(one_table)\n",
    "    temp_pred = predictor.predict(data_df)\n",
    "    temp_pred.to_csv(os.path.join(result_path,f\"{n}.csv\"))\n",
    "    n+=1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\0.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\1.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\2.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\3.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\4.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\5.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\6.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\7.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\8.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\9.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\10.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_ph\\\\out_table_30m\\\\pre_csv\\\\11.csv']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取预测结果\n",
    "pre_csv_list = [os.path.join(result_path,_) for _ in os.listdir(result_path)]\n",
    "pre_csv_list = sorted(pre_csv_list,key=lambda x:int(x.rsplit('\\\\', -1)[-1].split('.')[0]))\n",
    "pre_csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\1.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\2.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\3.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\4.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\5.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\6.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\7.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\8.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\9.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\10.csv\n",
      "D:\\ArcgisData\\pred_ph\\out_table_30m\\pre_csv\\11.csv\n"
     ]
    }
   ],
   "source": [
    "pre_df = pd.read_csv(pre_csv_list[0])\n",
    "for one_pred in pre_csv_list[1:]:\n",
    "    temp_df = pd.read_csv(one_pred)\n",
    "    pre_df = pd.concat([pre_df,temp_df],axis=0)\n",
    "    print(one_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存完整的预测数据\n",
    "pre_df.to_csv(os.path.join(r\"D:\\ArcgisData\\pred_ph\\out_table_30m\\merge_csv\",\"result.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2481, 1849), 9174738, 4587369)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_array.shape,pre_df.size,len(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Ph'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Ph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.956571e+05</td>\n",
       "      <td>5.986626e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.155467e+05</td>\n",
       "      <td>4.246971e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.180439e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.557000e+04</td>\n",
       "      <td>5.550124e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.914830e+05</td>\n",
       "      <td>5.987164e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.957410e+05</td>\n",
       "      <td>6.350526e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.999990e+05</td>\n",
       "      <td>7.254052e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0            Ph\n",
       "count  4.587369e+06  4.587369e+06\n",
       "mean   1.956571e+05  5.986626e+00\n",
       "std    1.155467e+05  4.246971e-01\n",
       "min    0.000000e+00  5.180439e+00\n",
       "25%    9.557000e+04  5.550124e+00\n",
       "50%    1.914830e+05  5.987164e+00\n",
       "75%    2.957410e+05  6.350526e+00\n",
       "max    3.999990e+05  7.254052e+00"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.571062 , 5.5710554, 5.5710487, ..., 5.497963 , 5.497978 ,\n",
       "        5.4979935],\n",
       "       [5.571062 , 5.5710554, 5.5710487, ..., 5.497943 , 5.497958 ,\n",
       "        5.4979744],\n",
       "       [5.571061 , 5.5710545, 5.571048 , ..., 5.4979234, 5.4979386,\n",
       "        5.497955 ],\n",
       "       ...,\n",
       "       [5.7387757, 5.7387867, 5.7387967, ..., 5.46234  , 5.4622617,\n",
       "        5.462184 ],\n",
       "       [5.738775 , 5.7387853, 5.7387958, ..., 5.4626155, 5.4625363,\n",
       "        5.4624577],\n",
       "       [5.738774 , 5.7387834, 5.738794 , ..., 5.462891 , 5.462811 ,\n",
       "        5.4627314]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_array = np.reshape(pre_df['Ph'].values,dem_array.shape)\n",
    "raster_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "env.extent = \"DEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成\n"
     ]
    }
   ],
   "source": [
    "# 按掩膜处理\n",
    "result_path = r\"D:\\ArcgisData\\pred_ph\\PH_BaseData.gdb\"\n",
    "result_raster = mask_raster(raster_array,\"DEM\", 30)\n",
    "result_raster.save(os.path.join(result_path,\"RESULT_PH_30\"))\n",
    "print(\"完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
