{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _base: 找不到指定的模块。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mqueue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\rasterio\\__init__.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NullHandler\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gdal_version\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdrivers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m driver_from_extension, is_blacklisted\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrasterio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     bool_,\n\u001b[0;32m     13\u001b[0m     ubyte,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     check_dtype,\n\u001b[0;32m     26\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _base: 找不到指定的模块。"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "# 配置日志记录\n",
    "logging.basicConfig(filename='crop_classification.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def extract_features(image_path, gdf, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                minx, miny, maxx, maxy = geometry.bounds\n",
    "                window = src.window(minx, miny, maxx, maxy)\n",
    "                masked_image = src.read(window=window, indexes=[1, 2, 3])\n",
    "                \n",
    "                if masked_image.shape[0] < 3 or masked_image.size == 0:\n",
    "                    logging.warning(f\"几何体 {idx} 无有效数据，跳过\")\n",
    "                    print(f\"警告：几何体 {idx} 无有效数据，跳过\")\n",
    "                    continue\n",
    "                \n",
    "                rgb_means = np.nanmean(masked_image, axis=(1, 2))\n",
    "                rgb_stds = np.nanstd(masked_image, axis=(1, 2))\n",
    "                \n",
    "                if np.isnan(rgb_means).any() or np.isnan(rgb_stds).any():\n",
    "                    logging.warning(f\"几何体 {idx} 包含 NaN 值，跳过\")\n",
    "                    print(f\"警告：几何体 {idx} 包含 NaN 值，跳过\")\n",
    "                    continue\n",
    "                \n",
    "                r, g, b = rgb_means\n",
    "                exg = 2 * g - r - b\n",
    "                vari = (g - r) / (g + r - b + 1e-8)\n",
    "                \n",
    "                hsv_image = rgb2hsv(np.moveaxis(masked_image, 0, -1))\n",
    "                hsv_means = np.nanmean(hsv_image, axis=(0, 1))\n",
    "                \n",
    "                green_channel = masked_image[1].astype(np.uint8)\n",
    "                if green_channel.size > 0:\n",
    "                    glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                else:\n",
    "                    logging.warning(f\"几何体 {idx} 的绿色通道为空，使用默认纹理特征\")\n",
    "                    contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                \n",
    "                feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                          [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                features.append(feature)\n",
    "                valid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征\")\n",
    "    \n",
    "    return np.array(features), valid_geometries\n",
    "\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices = extract_features(image_path, gdf_train, progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "        \n",
    "        clf.fit(X_combined, y_combined)\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        clf.fit(X_new, y_new)\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "\n",
    "def predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices = extract_features(new_image_path, gdf_new, progress_callback)\n",
    "    gdf_new = gdf_new.iloc[valid_indices]\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    gdf_new['ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new['ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"高级作物分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"刷新信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def start_training(self):\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "\n",
    "        if not tif_file or not shp_file or not model_dir:\n",
    "            messagebox.showerror(\"错误\", \"请选择TIF文件、SHP文件和模型存储路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        action_text = \"创建新模型\" if force_new else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"操作: {action_text}\\n\")\n",
    "        \n",
    "        def training_thread():\n",
    "            try:\n",
    "                update_or_train_model(tif_file, shp_file, \n",
    "                                      os.path.join(model_dir, \"model.joblib\"), \n",
    "                                      os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                                      os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                                      force_new,\n",
    "                                      self.update_progress)\n",
    "                self.master.after(0, self.training_complete)\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.training_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=training_thread).start()\n",
    "\n",
    "    def start_prediction(self):\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "\n",
    "        if not tif_file or not shp_file or not model_dir or not output_file:\n",
    "            messagebox.showerror(\"错误\", \"请选择所有必要的文件和路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        \n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                predict_new_data(os.path.join(model_dir, \"model.joblib\"), \n",
    "                                 os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                                 tif_file, shp_file, output_file,\n",
    "                                 self.update_progress)\n",
    "                self.master.after(0, self.prediction_complete)\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=prediction_thread).start()\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\")\n",
    "        self.refresh_info()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "\n",
    "    def prediction_complete(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        messagebox.showinfo(\"成功\", \"预测完成\")\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "\n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"高级作物分类模型 v1.0\\n\\n作者：AI Assistant\\n\\n版权所有 © 2023\")\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 配置日志记录\n",
    "logging.basicConfig(filename='crop_classification.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def extract_features(image_path, gdf, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                minx, miny, maxx, maxy = geometry.bounds\n",
    "                window = src.window(minx, miny, maxx, maxy)\n",
    "                masked_image = src.read(window=window, indexes=[1, 2, 3])\n",
    "                \n",
    "                if masked_image.shape[0] < 3 or masked_image.size == 0:\n",
    "                    logging.warning(f\"几何体 {idx} 无有效数据，跳过\")\n",
    "                    print(f\"警告：几何体 {idx} 无有效数据，跳过\")\n",
    "                    continue\n",
    "                \n",
    "                rgb_means = np.nanmean(masked_image, axis=(1, 2))\n",
    "                rgb_stds = np.nanstd(masked_image, axis=(1, 2))\n",
    "                \n",
    "                if np.isnan(rgb_means).any() or np.isnan(rgb_stds).any():\n",
    "                    logging.warning(f\"几何体 {idx} 包含 NaN 值，跳过\")\n",
    "                    print(f\"警告：几何体 {idx} 包含 NaN 值，跳过\")\n",
    "                    continue\n",
    "                \n",
    "                r, g, b = rgb_means\n",
    "                exg = 2 * g - r - b\n",
    "                vari = (g - r) / (g + r - b + 1e-8)\n",
    "                \n",
    "                hsv_image = rgb2hsv(np.moveaxis(masked_image, 0, -1))\n",
    "                hsv_means = np.nanmean(hsv_image, axis=(0, 1))\n",
    "                \n",
    "                green_channel = masked_image[1].astype(np.uint8)\n",
    "                if green_channel.size > 0:\n",
    "                    glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                else:\n",
    "                    logging.warning(f\"几何体 {idx} 的绿色通道为空，使用默认纹理特征\")\n",
    "                    contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                \n",
    "                feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                          [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                features.append(feature)\n",
    "                valid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征\")\n",
    "    \n",
    "    return np.array(features), valid_geometries\n",
    "\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None, hyperparameters=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices = extract_features(image_path, gdf_train, progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    # 定义随机搜索的参数范围\n",
    "    if hyperparameters is None:\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(50, 300),\n",
    "            'max_depth': randint(5, 50),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "    # 创建随机搜索对象\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=hyperparameters,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 执行随机搜索\n",
    "    random_search.fit(X_combined, y_combined)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    clf = random_search.best_estimator_\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_combined)\n",
    "    accuracy = accuracy_score(y_combined, y_pred)\n",
    "    report = classification_report(y_combined, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"最佳参数: {random_search.best_params_}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "    logging.info(\"各类别精度:\")\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            logging.info(f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices = extract_features(new_image_path, gdf_new, progress_callback)\n",
    "    gdf_new = gdf_new.iloc[valid_indices]\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    gdf_new['ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new['ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"高级作物分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 添加超参数输入框\n",
    "        ttk.Label(self.train_tab, text=\"n_estimators 范围:\").grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.n_estimators_min = tk.IntVar(value=50)\n",
    "        self.n_estimators_max = tk.IntVar(value=300)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_min, width=5).grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=5, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_max, width=5).grid(row=5, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"max_depth 范围:\").grid(row=6, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.max_depth_min = tk.IntVar(value=5)\n",
    "        self.max_depth_max = tk.IntVar(value=50)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_min, width=5).grid(row=6, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=6, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_max, width=5).grid(row=6, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "        \n",
    "        \n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"刷新信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def start_training(self):\n",
    "        \n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        hyperparameters = {\n",
    "        'n_estimators': randint(self.n_estimators_min.get(), self.n_estimators_max.get()),\n",
    "        'max_depth': randint(self.max_depth_min.get(), self.max_depth_max.get()),\n",
    "        # ... [添加其他超参数]\n",
    "    }\n",
    "        if not tif_file or not shp_file or not model_dir:\n",
    "            messagebox.showerror(\"错误\", \"请选择TIF文件、SHP文件和模型存储路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        action_text = \"创建新模型\" if force_new else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"操作: {action_text}\\n\")\n",
    "        \n",
    "        def training_thread():\n",
    "            try:\n",
    "                accuracy, report = update_or_train_model(\n",
    "                    tif_file, shp_file, \n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                    force_new,\n",
    "                    self.update_progress,\n",
    "                    hyperparameters\n",
    "                )\n",
    "                self.master.after(0, lambda: self.training_complete(accuracy, report))\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.training_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=training_thread).start()\n",
    "\n",
    "    def start_prediction(self):\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "\n",
    "        if not tif_file or not shp_file or not model_dir or not output_file:\n",
    "            messagebox.showerror(\"错误\", \"请选择所有必要的文件和路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        \n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                predict_new_data(os.path.join(model_dir, \"model.joblib\"), \n",
    "                                 os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                                 tif_file, shp_file, output_file,\n",
    "                                 self.update_progress)\n",
    "                self.master.after(0, self.prediction_complete)\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=prediction_thread).start()\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self, accuracy, report):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        self.log_text.insert(tk.END, f\"模型整体精度: {accuracy:.4f}\\n\")\n",
    "        self.log_text.insert(tk.END, \"各类别精度:\\n\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                self.log_text.insert(tk.END, f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\\n模型整体精度: {accuracy:.4f}\")\n",
    "        self.refresh_info()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "\n",
    "    def prediction_complete(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        messagebox.showinfo(\"成功\", \"预测完成\")\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "\n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"高级作物分类模型 v1.0\\n\\n作者：AI Assistant\\n\\n版权所有 © 2023\")\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'drvsupport'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m logging\u001b[38;5;241m.\u001b[39mbasicConfig(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop_classification.log\u001b[39m\u001b[38;5;124m'\u001b[39m, level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m     23\u001b[0m                     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m fiona\u001b[38;5;241m.\u001b[39msupported_drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESRI Shapefile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiona\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrvsupport\u001b[49m\u001b[38;5;241m.\u001b[39msupported_drivers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mESRI Shapefile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_shp_data\u001b[39m(gdf, column_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZZZW\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    验证SHP数据是否包含指定的标签列，以及该列是否有空值\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'drvsupport'"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# 配置日志记录\n",
    "logging.basicConfig(filename='crop_classification.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def validate_shp_data(gdf, column_name='ZZZW'):\n",
    "    \"\"\"\n",
    "    验证SHP数据是否包含指定的标签列，以及该列是否有空值\n",
    "    \"\"\"\n",
    "    if column_name not in gdf.columns:\n",
    "        raise ValueError(f\"SHP文件中缺少'{column_name}'列\")\n",
    "    \n",
    "    if gdf[column_name].isnull().any():\n",
    "        raise ValueError(f\"'{column_name}'列中存在空值\")\n",
    "\n",
    "def extract_features(image_path, gdf, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    invalid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                minx, miny, maxx, maxy = geometry.bounds\n",
    "                window = src.window(minx, miny, maxx, maxy)\n",
    "                masked_image = src.read(window=window, indexes=[1, 2, 3])\n",
    "                \n",
    "                if masked_image.shape[0] < 3 or masked_image.size == 0:\n",
    "                    logging.warning(f\"几何体 {idx} 无有效数据，跳过\")\n",
    "                    invalid_geometries.append(idx)\n",
    "                    continue\n",
    "                \n",
    "                rgb_means = np.nanmean(masked_image, axis=(1, 2))\n",
    "                rgb_stds = np.nanstd(masked_image, axis=(1, 2))\n",
    "                \n",
    "                if np.isnan(rgb_means).any() or np.isnan(rgb_stds).any():\n",
    "                    logging.warning(f\"几何体 {idx} 包含 NaN 值，跳过\")\n",
    "                    invalid_geometries.append(idx)\n",
    "                    continue\n",
    "                \n",
    "                r, g, b = rgb_means\n",
    "                exg = 2 * g - r - b\n",
    "                vari = (g - r) / (g + r - b + 1e-8)\n",
    "                \n",
    "                hsv_image = rgb2hsv(np.moveaxis(masked_image, 0, -1))\n",
    "                hsv_means = np.nanmean(hsv_image, axis=(0, 1))\n",
    "                \n",
    "                green_channel = masked_image[1].astype(np.uint8)\n",
    "                if green_channel.size > 0:\n",
    "                    glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                else:\n",
    "                    logging.warning(f\"几何体 {idx} 的绿色通道为空，使用默认纹理特征\")\n",
    "                    contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                \n",
    "                feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                          [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                features.append(feature)\n",
    "                valid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "                invalid_geometries.append(idx)\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征\")\n",
    "    \n",
    "    return np.array(features), valid_geometries, invalid_geometries\n",
    "\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None, hyperparameters=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    \n",
    "    # 验证SHP数据\n",
    "    validate_shp_data(gdf_train)\n",
    "    \n",
    "    X_new, valid_indices, _ = extract_features(image_path, gdf_train, progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    # 定义随机搜索的参数范围\n",
    "    if hyperparameters is None:\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(50, 300),\n",
    "            'max_depth': randint(5, 50),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "    # 创建随机搜索对象\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=hyperparameters,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 执行随机搜索\n",
    "    random_search.fit(X_combined, y_combined)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    clf = random_search.best_estimator_\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_combined)\n",
    "    accuracy = accuracy_score(y_combined, y_pred)\n",
    "    report = classification_report(y_combined, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"最佳参数: {random_search.best_params_}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "    logging.info(\"各类别精度:\")\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            logging.info(f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices, invalid_indices = extract_features(new_image_path, gdf_new, progress_callback)\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    \n",
    "    # 为有效的几何体添加预测结果\n",
    "    gdf_new.loc[valid_indices, 'ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new.loc[valid_indices, 'ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    \n",
    "    # 为无效的几何体添加标记\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW'] = 'Invalid'\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW_proba'] = 0\n",
    "    \n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "    return len(invalid_indices)\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"RGB分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"模型信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择带有标签的SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 超参数输入框\n",
    "        ttk.Label(self.train_tab, text=\"n_estimators 范围:\").grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.n_estimators_min = tk.IntVar(value=50)\n",
    "        self.n_estimators_max = tk.IntVar(value=300)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_min, width=5).grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=5, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_max, width=5).grid(row=5, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"max_depth 范围:\").grid(row=6, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.max_depth_min = tk.IntVar(value=5)\n",
    "        self.max_depth_max = tk.IntVar(value=50)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_min, width=5).grid(row=6, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=6, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_max, width=5).grid(row=6, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=7, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50).grid(row=0, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50).grid(row=1, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"获取模型信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def start_training(self):\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(self.n_estimators_min.get(), self.n_estimators_max.get()),\n",
    "            'max_depth': randint(self.max_depth_min.get(), self.max_depth_max.get()),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "        if not tif_file or not shp_file or not model_dir:\n",
    "            messagebox.showerror(\"错误\", \"请选择TIF文件、SHP文件和模型存储路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        action_text = \"创建新模型\" if force_new else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"操作: {action_text}\\n\")\n",
    "        \n",
    "        def training_thread():\n",
    "            try:\n",
    "                accuracy, report = update_or_train_model(\n",
    "                    tif_file, shp_file, \n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                    force_new,\n",
    "                    self.update_progress,\n",
    "                    hyperparameters\n",
    "                )\n",
    "                self.master.after(0, lambda: self.training_complete(accuracy, report))\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.training_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=training_thread).start()\n",
    "\n",
    "    def start_prediction(self):\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "\n",
    "        if not tif_file or not shp_file or not model_dir or not output_file:\n",
    "            messagebox.showerror(\"错误\", \"请选择所有必要的文件和路径\")\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        \n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                invalid_count = predict_new_data(\n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    tif_file, shp_file, output_file,\n",
    "                    self.update_progress\n",
    "                )\n",
    "                self.master.after(0, lambda: self.prediction_complete(invalid_count))\n",
    "            except Exception as e:\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        threading.Thread(target=prediction_thread).start()\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self, accuracy, report):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        self.log_text.insert(tk.END, f\"模型整体精度: {accuracy:.4f}\\n\")\n",
    "        self.log_text.insert(tk.END, \"各类别精度:\\n\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                self.log_text.insert(tk.END, f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\\n模型整体精度: {accuracy:.4f}\")\n",
    "        self.refresh_info()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "\n",
    "    def prediction_complete(self, invalid_count):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        if invalid_count > 0:\n",
    "            self.log_text.insert(tk.END, f\"警告：{invalid_count}个几何体无法进行预测，已在输出中标记为'Invalid'\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"预测完成\\n{invalid_count}个几何体无法预测\")\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "\n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            info += f\"最大深度：{model.max_depth}\\n\"\n",
    "            info += f\"最小分裂样本数：{model.min_samples_split}\\n\"\n",
    "            info += f\"最小叶子节点样本数：{model.min_samples_leaf}\\n\"\n",
    "            info += f\"特征选择方式：{model.max_features}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"RGB分类模型 v1.0\\n\\n作者：AI 贵州雏阳\\n\\n版权所有 © 2024\")\n",
    "\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# ... [前面的导入和设置保持不变]\n",
    "\n",
    "def get_raster_info(raster_path):\n",
    "    with rasterio.open(raster_path) as src:\n",
    "        return {\n",
    "            'pixel_size': src.res,\n",
    "            'crs': src.crs,\n",
    "            'bounds': src.bounds\n",
    "        }\n",
    "\n",
    "def validate_raster_consistency(new_raster_path, model_info_path):\n",
    "    new_info = get_raster_info(new_raster_path)\n",
    "    \n",
    "    if os.path.exists(model_info_path):\n",
    "        old_info = joblib.load(model_info_path)\n",
    "        if new_info['pixel_size'] != old_info['pixel_size']:\n",
    "            return False, f\"像元大小不匹配。原始: {old_info['pixel_size']}, 新: {new_info['pixel_size']}\"\n",
    "        if new_info['crs'] != old_info['crs']:\n",
    "            return False, f\"坐标系统不匹配。原始: {old_info['crs']}, 新: {new_info['crs']}\"\n",
    "    \n",
    "    return True, \"\"\n",
    "\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, model_info_path, force_new_model=False, progress_callback=None, hyperparameters=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    \n",
    "    # 检查栅格一致性\n",
    "    if not force_new_model:\n",
    "        is_consistent, message = validate_raster_consistency(image_path, model_info_path)\n",
    "        if not is_consistent:\n",
    "            raise ValueError(f\"栅格数据不一致: {message}\")\n",
    "    \n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    \n",
    "    # 验证SHP数据\n",
    "    validate_shp_data(gdf_train)\n",
    "    \n",
    "    X_new, valid_indices, _ = extract_features(image_path, gdf_train, progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    # 使用StandardScaler进行特征标准化\n",
    "    scaler = StandardScaler()\n",
    "    X_new_scaled = scaler.fit_transform(X_new)\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        old_scaler = joblib.load(os.path.join(os.path.dirname(model_output_path), \"scaler.joblib\"))\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        # 使用旧的scaler转换新数据，确保一致性\n",
    "        X_new_scaled = old_scaler.transform(X_new)\n",
    "        \n",
    "        if X_old.shape[1] != X_new_scaled.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new_scaled.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new_scaled, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new_scaled))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new_scaled, y_new\n",
    "\n",
    "    # ... [随机搜索和模型训练部分保持不变]\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "    joblib.dump(scaler, os.path.join(os.path.dirname(model_output_path), \"scaler.joblib\"))\n",
    "    \n",
    "    # 保存栅格信息\n",
    "    raster_info = get_raster_info(image_path)\n",
    "    joblib.dump(raster_info, model_info_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"特征缩放器已保存到: {os.path.join(os.path.dirname(model_output_path), 'scaler.joblib')}\")\n",
    "    logging.info(f\"栅格信息已保存到: {model_info_path}\")\n",
    "    logging.info(f\"最佳参数: {clf.get_params()}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "class CropClassificationApp:\n",
    "    # ... [大部分代码保持不变]\n",
    "\n",
    "    def start_training(self):\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        \n",
    "        if not force_new:\n",
    "            is_consistent, message = validate_raster_consistency(tif_file, os.path.join(model_dir, \"raster_info.joblib\"))\n",
    "            if not is_consistent:\n",
    "                response = messagebox.askyesno(\"警告\", f\"{message}\\n是否继续更新模型？这可能会影响模型性能。\")\n",
    "                if not response:\n",
    "                    return\n",
    "\n",
    "        # ... [其余代码保持不变]\n",
    "\n",
    "    def start_prediction(self):\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "\n",
    "        is_consistent, message = validate_raster_consistency(tif_file, os.path.join(model_dir, \"raster_info.joblib\"))\n",
    "        if not is_consistent:\n",
    "            response = messagebox.askyesno(\"警告\", f\"{message}\\n是否继续进行预测？这可能会影响预测结果的准确性。\")\n",
    "            if not response:\n",
    "                return\n",
    "\n",
    "        # ... [其余代码保持不变]\n",
    "\n",
    "# ... [主函数和其他部分保持不变]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "from osgeo import gdal\n",
    "\n",
    "# 设置GDAL不要压缩输出文件\n",
    "gdal.SetConfigOption('COMPRESS_OVERVIEW', 'NONE')\n",
    "gdal.UseExceptions()  # 启用GDAL异常\n",
    "\n",
    "# ... [其他导入和设置保持不变]\n",
    "\n",
    "def process_raster(input_file, output_file, target_srs, target_res):\n",
    "    try:\n",
    "        # 如果输出文件已存在，跳过处理\n",
    "        if os.path.exists(output_file):\n",
    "            print(f\"输出文件已存在，跳过处理: {output_file}\")\n",
    "            return output_file\n",
    "\n",
    "        # 打开输入文件\n",
    "        ds = gdal.Open(input_file)\n",
    "        if ds is None:\n",
    "            print(f\"无法打开文件: {input_file}\")\n",
    "            return None\n",
    "\n",
    "        # 设置转换选项\n",
    "        options = gdal.WarpOptions(\n",
    "            dstSRS=target_srs,\n",
    "            xRes=target_res[0], yRes=target_res[1],\n",
    "            resampleAlg=gdal.GRA_Bilinear,\n",
    "            format='GTiff',\n",
    "            creationOptions=['COMPRESS=LZW', 'TILED=YES', 'BLOCKXSIZE=256', 'BLOCKYSIZE=256', 'BIGTIFF=YES'],\n",
    "            warpOptions=['CUTLINE_ALL_TOUCHED=TRUE'],\n",
    "            multithread=True,\n",
    "            warpMemoryLimit=4096  # 限制内存使用为4GB\n",
    "        )\n",
    "\n",
    "        # 执行转换\n",
    "        print(f\"正在处理文件: {input_file}\")\n",
    "        gdal.Warp(output_file, ds, options=options)\n",
    "        \n",
    "        # 关闭数据集\n",
    "        ds = None\n",
    "        print(f\"成功处理文件: {input_file}\")\n",
    "        return output_file\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {input_file} 时出错: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ... [其他函数保持不变]\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"高级作物分类模型\")\n",
    "        master.geometry(\"800x700\")  # 增加窗口高度以容纳新的控件\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "        self.settings_tab = ttk.Frame(self.notebook)  # 新增设置标签页\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"信息\")\n",
    "        self.notebook.add(self.settings_tab, text=\"设置\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "        self.setup_settings_tab()  # 设置新的标签页\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    # ... [其他方法保持不变]\n",
    "\n",
    "    def setup_settings_tab(self):\n",
    "        ttk.Label(self.settings_tab, text=\"目标坐标系统 (EPSG):\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.target_srs = tk.StringVar(value=\"EPSG:4544\")\n",
    "        ttk.Entry(self.settings_tab, textvariable=self.target_srs, width=20).grid(row=0, column=1, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.settings_tab, text=\"目标像元大小 X:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.target_res_x = tk.DoubleVar(value=0.1)\n",
    "        ttk.Entry(self.settings_tab, textvariable=self.target_res_x, width=10).grid(row=1, column=1, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.settings_tab, text=\"目标像元大小 Y:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.target_res_y = tk.DoubleVar(value=0.1)\n",
    "        ttk.Entry(self.settings_tab, textvariable=self.target_res_y, width=10).grid(row=2, column=1, padx=5, pady=5)\n",
    "\n",
    "    def start_training(self):\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        \n",
    "        if not os.path.exists(tif_file) or not os.path.exists(shp_file):\n",
    "            messagebox.showerror(\"错误\", \"TIF文件或SHP文件不存在\")\n",
    "            return\n",
    "\n",
    "        # 处理TIF文件\n",
    "        processed_tif = os.path.join(os.path.dirname(tif_file), 'processed_' + os.path.basename(tif_file))\n",
    "        processed_tif = process_raster(tif_file, processed_tif, self.target_srs.get(), (self.target_res_x.get(), self.target_res_y.get()))\n",
    "        \n",
    "        if processed_tif is None:\n",
    "            messagebox.showerror(\"错误\", \"TIF文件处理失败\")\n",
    "            return\n",
    "\n",
    "        # 更新SHP文件的坐标系\n",
    "        gdf = gpd.read_file(shp_file)\n",
    "        gdf = gdf.to_crs(self.target_srs.get())\n",
    "        processed_shp = os.path.join(os.path.dirname(shp_file), 'processed_' + os.path.basename(shp_file))\n",
    "        gdf.to_file(processed_shp)\n",
    "\n",
    "        # ... [其余训练代码保持不变，但使用processed_tif和processed_shp]\n",
    "\n",
    "    def start_prediction(self):\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "\n",
    "        if not os.path.exists(tif_file) or not os.path.exists(shp_file):\n",
    "            messagebox.showerror(\"错误\", \"TIF文件或SHP文件不存在\")\n",
    "            return\n",
    "\n",
    "        # 处理TIF文件\n",
    "        processed_tif = os.path.join(os.path.dirname(tif_file), 'processed_' + os.path.basename(tif_file))\n",
    "        processed_tif = process_raster(tif_file, processed_tif, self.target_srs.get(), (self.target_res_x.get(), self.target_res_y.get()))\n",
    "        \n",
    "        if processed_tif is None:\n",
    "            messagebox.showerror(\"错误\", \"TIF文件处理失败\")\n",
    "            return\n",
    "\n",
    "        # 更新SHP文件的坐标系\n",
    "        gdf = gpd.read_file(shp_file)\n",
    "        gdf = gdf.to_crs(self.target_srs.get())\n",
    "        processed_shp = os.path.join(os.path.dirname(shp_file), 'processed_' + os.path.basename(shp_file))\n",
    "        gdf.to_file(processed_shp)\n",
    "\n",
    "        # ... [其余预测代码保持不变，但使用processed_tif和processed_shp]\n",
    "\n",
    "# ... [主函数和其他部分保持不变]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.23; you have 1.22.4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinterdnd2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_tkagg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasTkAgg\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filedialog, messagebox, ttk, scrolledtext\n",
      "File \u001b[1;32mc:\\Users\\Runker\\.conda\\envs\\geo_env\\lib\\site-packages\\matplotlib\\__init__.py:263\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 263\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\Runker\\.conda\\envs\\geo_env\\lib\\site-packages\\matplotlib\\__init__.py:259\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    257\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    260\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Matplotlib requires numpy>=1.23; you have 1.22.4"
     ]
    }
   ],
   "source": [
    "import tkinterdnd2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from tkinter import filedialog, messagebox, ttk, scrolledtext\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "def setup_logging():\n",
    "    log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    log_file = 'crop_classification.log'\n",
    "    log_handler = RotatingFileHandler(log_file, maxBytes=1024 * 1024, backupCount=5)\n",
    "    log_handler.setFormatter(log_formatter)\n",
    "    log_handler.setLevel(logging.INFO)\n",
    "\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    root_logger.addHandler(log_handler)\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "# 配置日志记录\n",
    "logging.basicConfig(filename='crop_classification.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def validate_shp_data(gdf, column_name='ZZZW'):\n",
    "    \"\"\"\n",
    "    验证SHP数据是否包含指定的标签列，以及该列是否有空值\n",
    "    \"\"\"\n",
    "    if column_name not in gdf.columns:\n",
    "        raise ValueError(f\"SHP文件中缺少'{column_name}'列\")\n",
    "    \n",
    "    if gdf[column_name].isnull().any():\n",
    "        raise ValueError(f\"'{column_name}'列中存在空值\")\n",
    "def extract_features_chunked(image_path, gdf, use_chunking=False, chunk_size=1024, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    invalid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                window = rasterio.features.geometry_window(src, [geometry])\n",
    "                \n",
    "                if use_chunking:\n",
    "                    chunk_windows = []\n",
    "                    for col_off in range(0, window.width, chunk_size):\n",
    "                        for row_off in range(0, window.height, chunk_size):\n",
    "                            chunk_window = rasterio.windows.Window(\n",
    "                                window.col_off + col_off, \n",
    "                                window.row_off + row_off,\n",
    "                                min(chunk_size, window.width - col_off),\n",
    "                                min(chunk_size, window.height - row_off)\n",
    "                            )\n",
    "                            chunk_windows.append(chunk_window)\n",
    "                else:\n",
    "                    chunk_windows = [window]\n",
    "\n",
    "                feature_chunks = []\n",
    "                for chunk_window in chunk_windows:\n",
    "                    masked_chunk = src.read(window=chunk_window, indexes=[1, 2, 3])\n",
    "                    \n",
    "                    if masked_chunk.size == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    rgb_means = np.nanmean(masked_chunk, axis=(1, 2))\n",
    "                    rgb_stds = np.nanstd(masked_chunk, axis=(1, 2))\n",
    "                    \n",
    "                    r, g, b = rgb_means\n",
    "                    exg = 2 * g - r - b\n",
    "                    vari = (g - r) / (g + r - b + 1e-8)\n",
    "                    \n",
    "                    hsv_chunk = rgb2hsv(np.moveaxis(masked_chunk, 0, -1))\n",
    "                    hsv_means = np.nanmean(hsv_chunk, axis=(0, 1))\n",
    "                    \n",
    "                    green_channel = masked_chunk[1].astype(np.uint8)\n",
    "                    if green_channel.size > 0:\n",
    "                        glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                    else:\n",
    "                        contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                    \n",
    "                    chunk_feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                                    [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                    feature_chunks.append(chunk_feature)\n",
    "                \n",
    "                if feature_chunks:\n",
    "                    feature = np.mean(feature_chunks, axis=0)\n",
    "                    features.append(feature)\n",
    "                    valid_geometries.append(idx)\n",
    "                else:\n",
    "                    invalid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "                invalid_geometries.append(idx)\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征\")\n",
    "    \n",
    "    return np.array(features), valid_geometries, invalid_geometries\n",
    "\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None, hyperparameters=None, use_chunking=False, chunk_size=None,cancel_check=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    \n",
    "    # 验证SHP数据\n",
    "    validate_shp_data(gdf_train)\n",
    "    \n",
    "    X_new, valid_indices, _ = extract_features_chunked(image_path, gdf_train, use_chunking=use_chunking, chunk_size=chunk_size, progress_callback=progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    # 定义随机搜索的参数范围\n",
    "    if hyperparameters is None:\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(50, 300),\n",
    "            'max_depth': randint(5, 50),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "    # 创建随机搜索对象\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=hyperparameters,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 执行随机搜索\n",
    "    random_search.fit(X_combined, y_combined)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    clf = random_search.best_estimator_\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_combined)\n",
    "    accuracy = accuracy_score(y_combined, y_pred)\n",
    "    report = classification_report(y_combined, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"最佳参数: {random_search.best_params_}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "    logging.info(\"各类别精度:\")\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            logging.info(f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\")\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def  predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None, use_chunking=False, chunk_size=None,cancel_check=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices, invalid_indices = extract_features_chunked(new_image_path, gdf_new, use_chunking=use_chunking, chunk_size=chunk_size, progress_callback=progress_callback)\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    \n",
    "    # 为有效的几何体添加预测结果\n",
    "    gdf_new.loc[valid_indices, 'ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new.loc[valid_indices, 'ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    \n",
    "    # 为无效的几何体添加标记\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW'] = 'Invalid'\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW_proba'] = 0\n",
    "    \n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "    return len(invalid_indices)\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"RGB分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "        \n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "        \n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "        self.use_chunking = tk.BooleanVar(value=False)\n",
    "        self.chunk_size = tk.IntVar(value=1024)\n",
    "\n",
    "        self.cancel_operation = False\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"模型信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        tif_entry = ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50)\n",
    "        tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.tif_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择带有标签的SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        shp_entry = ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50)\n",
    "        shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.shp_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 超参数输入框\n",
    "        ttk.Label(self.train_tab, text=\"n_estimators 范围:\").grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.n_estimators_min = tk.IntVar(value=50)\n",
    "        self.n_estimators_max = tk.IntVar(value=300)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_min, width=5).grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=5, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_max, width=5).grid(row=5, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"max_depth 范围:\").grid(row=6, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.max_depth_min = tk.IntVar(value=5)\n",
    "        self.max_depth_max = tk.IntVar(value=50)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_min, width=5).grid(row=6, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=6, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_max, width=5).grid(row=6, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=7, column=0, columnspan=3, pady=20)\n",
    "\n",
    "\n",
    "        ttk.Checkbutton(self.train_tab, text=\"使用分块处理\", variable=self.use_chunking, command=self.toggle_chunk_size).grid(row=8, column=0, columnspan=2, sticky=\"w\", padx=5, pady=5)\n",
    "    \n",
    "        self.chunk_size_label = ttk.Label(self.train_tab, text=\"分块大小:\")\n",
    "        self.chunk_size_label.grid(row=9, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.chunk_size_entry = ttk.Entry(self.train_tab, textvariable=self.chunk_size, width=10)\n",
    "        self.chunk_size_entry.grid(row=9, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 初始状态下禁用分块大小输入\n",
    "        self.chunk_size_label['state'] = 'disabled'\n",
    "        self.chunk_size_entry['state'] = 'disabled'\n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        predict_tif_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50)\n",
    "        predict_tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        predict_tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_tif_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        predict_shp_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50)\n",
    "        predict_shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        predict_shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_shp_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=4, column=0, columnspan=3, pady=20)\n",
    "\n",
    "        self.show_map_button = ttk.Button(self.predict_tab, text=\"显示分类地图\", command=lambda: self.show_classification_map(self.output_path.get()))\n",
    "        self.show_map_button.grid(row=5, column=0, columnspan=3, pady=10)\n",
    "        self.show_map_button['state'] = 'disabled'  # 初始状态为禁用\n",
    "\n",
    "        ttk.Checkbutton(self.predict_tab, text=\"使用分块处理\", variable=self.use_chunking, command=self.toggle_chunk_size).grid(row=5, column=0, columnspan=2, sticky=\"w\", padx=5, pady=5)\n",
    "    \n",
    "        self.chunk_size_label_predict = ttk.Label(self.predict_tab, text=\"分块大小:\")\n",
    "        self.chunk_size_label_predict.grid(row=6, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.chunk_size_entry_predict = ttk.Entry(self.predict_tab, textvariable=self.chunk_size, width=10)\n",
    "        self.chunk_size_entry_predict.grid(row=6, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "    \n",
    "        # 初始状态下禁用分块大小输入\n",
    "        self.chunk_size_label_predict['state'] = 'disabled'\n",
    "        self.chunk_size_entry_predict['state'] = 'disabled'\n",
    "    def toggle_chunk_size(self):\n",
    "        state = 'normal' if self.use_chunking.get() else 'disabled'\n",
    "        self.chunk_size_label['state'] = state\n",
    "        self.chunk_size_entry['state'] = state\n",
    "        self.chunk_size_label_predict['state'] = state\n",
    "        self.chunk_size_entry_predict['state'] = state\n",
    "\n",
    "    def validate_inputs(self):\n",
    "        errors = []\n",
    "        if not self.tif_path.get():\n",
    "            errors.append(\"请选择TIF文件\")\n",
    "        if not self.shp_path.get():\n",
    "            errors.append(\"请选择SHP文件\")\n",
    "        if self.use_chunking.get() and (self.chunk_size.get() <= 0 or self.chunk_size.get() > 10000):\n",
    "            errors.append(\"分块大小应在1到10000之间\")\n",
    "        return errors\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"获取模型信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def drop_file(self, event, path_var):\n",
    "        file_path = event.data\n",
    "        if file_path.startswith('{') and file_path.endswith('}'):\n",
    "            file_path = file_path[1:-1]\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        if (path_var in [self.tif_path, self.predict_tif_path] and file_extension == '.tif') or \\\n",
    "        (path_var in [self.shp_path, self.predict_shp_path] and file_extension == '.shp'):\n",
    "            path_var.set(file_path)\n",
    "        else:\n",
    "            messagebox.showerror(\"错误\", \"请拖放正确的文件类型\")\n",
    "    @staticmethod\n",
    "    def get_file_info(file_path):\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "        file_type = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        info = f\"文件路径: {file_path}\\n\"\n",
    "        info += f\"文件大小: {file_size:.2f} MB\\n\"\n",
    "        info += f\"文件类型: {file_type}\\n\"\n",
    "        \n",
    "        if file_type == '.tif':\n",
    "            with rasterio.open(file_path) as src:\n",
    "                info += f\"图像大小: {src.width} x {src.height}\\n\"\n",
    "                info += f\"波段数: {src.count}\\n\"\n",
    "                info += f\"坐标系统: {src.crs}\\n\"\n",
    "        elif file_type == '.shp':\n",
    "            gdf = gpd.read_file(file_path)\n",
    "            info += f\"要素数量: {len(gdf)}\\n\"\n",
    "            info += f\"几何类型: {gdf.geom_type.iloc[0]}\\n\"\n",
    "            info += f\"属性列: {', '.join(gdf.columns)}\\n\"\n",
    "        \n",
    "        return info\n",
    "    def show_classification_map(self, shp_file_path):\n",
    "        try:\n",
    "            # 读取分类结果的shapefile\n",
    "            gdf = gpd.read_file(shp_file_path)\n",
    "            \n",
    "            # 创建一个新的Toplevel窗口\n",
    "            map_window = tk.Toplevel(self.master)\n",
    "            map_window.title(\"分类结果地图\")\n",
    "            map_window.geometry(\"800x600\")\n",
    "\n",
    "            # 创建matplotlib图形\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            \n",
    "            # 绘制地图\n",
    "            gdf.plot(column='ZZZW', ax=ax, legend=True, cmap='viridis', legend_kwds={'label': '分类结果', 'orientation': 'horizontal'})\n",
    "            ax.set_axis_off()\n",
    "            plt.title('分类结果空间分布')\n",
    "\n",
    "            # 将matplotlib图形嵌入到Tkinter窗口中\n",
    "            canvas = FigureCanvasTkAgg(fig, master=map_window)\n",
    "            canvas.draw()\n",
    "            canvas.get_tk_widget().pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"错误\", f\"无法创建地图：{str(e)}\")\n",
    "    def preview_file(self, path_var):\n",
    "        file_path = path_var.get()\n",
    "        if not file_path:\n",
    "            messagebox.showwarning(\"警告\", \"请先选择文件\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            info = self.get_file_info(file_path)\n",
    "            messagebox.showinfo(\"文件预览\", info)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"错误\", f\"无法预览文件：{str(e)}\")\n",
    "    def cancel_current_operation(self):\n",
    "        self.cancel_operation = True\n",
    "        self.log_text.insert(tk.END, \"正在取消操作...\\n\")\n",
    "        self.status_bar['text'] = \"正在取消...\"\n",
    "\n",
    "    def operation_cancelled(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"操作已取消\"\n",
    "        self.log_text.insert(tk.END, \"操作已取消\\n\")\n",
    "        messagebox.showinfo(\"已取消\", \"操作已被用户取消\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def save_model_version(self, model, le, accuracy, report, timestamp):\n",
    "        version_dir = os.path.join(self.model_path.get(), f\"version_{timestamp}\")\n",
    "        os.makedirs(version_dir, exist_ok=True)\n",
    "        \n",
    "        joblib.dump(model, os.path.join(version_dir, \"model.joblib\"))\n",
    "        joblib.dump(le, os.path.join(version_dir, \"label_encoder.joblib\"))\n",
    "        \n",
    "        # 保存模型性能信息\n",
    "        with open(os.path.join(version_dir, \"performance.txt\"), \"w\") as f:\n",
    "            f.write(f\"Accuracy: {accuracy}\\n\\n\")\n",
    "            f.write(\"Classification Report:\\n\")\n",
    "            f.write(str(report))\n",
    "        \n",
    "        # 更新版本列表\n",
    "        versions = self.load_model_versions()\n",
    "        versions.append({\n",
    "            \"timestamp\": timestamp,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"path\": version_dir\n",
    "        })\n",
    "        with open(os.path.join(self.model_path.get(), \"versions.json\"), \"w\") as f:\n",
    "            json.dump(versions, f)\n",
    "    def load_model_versions(self):\n",
    "        version_file = os.path.join(self.model_path.get(), \"versions.json\")\n",
    "        if os.path.exists(version_file):\n",
    "            with open(version_file, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        return []        \n",
    "        \n",
    "    def start_training(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        use_chunking = self.use_chunking.get()\n",
    "        chunk_size = self.chunk_size.get() if use_chunking else None\n",
    "\n",
    "        def training_thread():\n",
    "            try:\n",
    "                accuracy, report = update_or_train_model(\n",
    "                    tif_file, shp_file, \n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                    force_new,\n",
    "                    self.update_progress,\n",
    "                    use_chunking=use_chunking,\n",
    "                    chunk_size=chunk_size,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                    \n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.training_complete(accuracy, report))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"训练过程中出错\")\n",
    "                self.master.after(0, lambda: self.training_error(str(e)))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=training_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.train_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=10, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def start_prediction(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "        use_chunking = self.use_chunking.get()\n",
    "        chunk_size = self.chunk_size.get() if use_chunking else None\n",
    "\n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                invalid_count = predict_new_data(\n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    tif_file, shp_file, output_file,\n",
    "                    self.update_progress,\n",
    "                    use_chunking=use_chunking,\n",
    "                    chunk_size=chunk_size,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.prediction_complete(invalid_count))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"预测过程中出错\")\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=prediction_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.predict_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self, accuracy, report):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        self.log_text.insert(tk.END, f\"模型整体精度: {accuracy:.4f}\\n\")\n",
    "        self.log_text.insert(tk.END, \"各类别精度:\\n\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                self.log_text.insert(tk.END, f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\\n模型整体精度: {accuracy:.4f}\")\n",
    "        self.refresh_info()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "\n",
    "    def prediction_complete(self, invalid_count):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        if invalid_count > 0:\n",
    "            self.log_text.insert(tk.END, f\"警告：{invalid_count}个几何体无法进行预测，已在输出中标记为'Invalid'\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"预测完成\\n{invalid_count}个几何体无法预测\")\n",
    "        # 显示分类结果地图\n",
    "        self.show_classification_map(self.output_path.get())\n",
    "        # 启用显示地图\n",
    "        self.show_map_button['state'] = 'normal'  # 启用显示地图按钮\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "        \n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            info += f\"最大深度：{model.max_depth}\\n\"\n",
    "            info += f\"最小分裂样本数：{model.min_samples_split}\\n\"\n",
    "            info += f\"最小叶子节点样本数：{model.min_samples_leaf}\\n\"\n",
    "            info += f\"特征选择方式：{model.max_features}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"RGB分类模型 v1.0\\n\\n作者：AI 贵州雏阳\\n\\n版权所有 © 2024\")\n",
    "\n",
    "def main():\n",
    "    root = tkinterdnd2.TkinterDnD.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "import os\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "import tkinterdnd2\n",
    "\n",
    "# 配置日志记录\n",
    "def setup_logging():\n",
    "    log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    log_file = 'crop_classification.log'\n",
    "    log_handler = RotatingFileHandler(log_file, maxBytes=1024 * 1024, backupCount=5)\n",
    "    log_handler.setFormatter(log_formatter)\n",
    "    log_handler.setLevel(logging.INFO)\n",
    "\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    root_logger.addHandler(log_handler)\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "# gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def validate_shp_data(gdf, column_name='ZZZW'):\n",
    "    \"\"\"\n",
    "    验证SHP数据是否包含指定的标签列，以及该列是否有空值\n",
    "    \"\"\"\n",
    "    if column_name not in gdf.columns:\n",
    "        raise ValueError(f\"SHP文件中缺少'{column_name}'列\")\n",
    "    \n",
    "    if gdf[column_name].isnull().any():\n",
    "        raise ValueError(f\"'{column_name}'列中存在空值\")\n",
    "\n",
    "def extract_features_chunked(image_path, gdf, use_chunking=False, chunk_size=1024, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    invalid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                window = rasterio.windows.from_bounds(*geometry.bounds, src.transform)\n",
    "                \n",
    "                if use_chunking:\n",
    "                    chunk_windows = []\n",
    "                    for col_off in range(0, window.width, chunk_size):\n",
    "                        for row_off in range(0, window.height, chunk_size):\n",
    "                            chunk_window = rasterio.windows.Window(\n",
    "                                window.col_off + col_off, \n",
    "                                window.row_off + row_off,\n",
    "                                min(chunk_size, window.width - col_off),\n",
    "                                min(chunk_size, window.height - row_off)\n",
    "                            )\n",
    "                            chunk_windows.append(chunk_window)\n",
    "                else:\n",
    "                    chunk_windows = [window]\n",
    "\n",
    "                feature_chunks = []\n",
    "                for chunk_window in chunk_windows:\n",
    "                    masked_chunk = src.read(window=chunk_window, indexes=[1, 2, 3])\n",
    "                    \n",
    "                    if masked_chunk.size == 0:\n",
    "                        logging.warning(f\"几何体 {idx}: 无数据\")\n",
    "                        continue\n",
    "                    \n",
    "                    rgb_means = np.nanmean(masked_chunk, axis=(1, 2))\n",
    "                    rgb_stds = np.nanstd(masked_chunk, axis=(1, 2))\n",
    "                    \n",
    "                    r, g, b = rgb_means\n",
    "                    exg = 2 * g - r - b\n",
    "                    vari = (g - r) / (g + r - b + 1e-8)\n",
    "                    \n",
    "                    hsv_chunk = rgb2hsv(np.moveaxis(masked_chunk, 0, -1))\n",
    "                    hsv_means = np.nanmean(hsv_chunk, axis=(0, 1))\n",
    "                    \n",
    "                    green_channel = masked_chunk[1].astype(np.uint8)\n",
    "                    if green_channel.size > 0:\n",
    "                        glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                        dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                    else:\n",
    "                        contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                    \n",
    "                    chunk_feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                                    [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                    feature_chunks.append(chunk_feature)\n",
    "                \n",
    "                if feature_chunks:\n",
    "                    feature = np.mean(feature_chunks, axis=0)\n",
    "                    features.append(feature)\n",
    "                    valid_geometries.append(idx)\n",
    "                else:\n",
    "                    logging.warning(f\"几何体 {idx}: 未能提取特征\")\n",
    "                    invalid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "                invalid_geometries.append(idx)\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征。请检查输入数据是否正确，以及TIF和SHP文件是否匹配。\")\n",
    "    \n",
    "    return np.array(features), valid_geometries, invalid_geometries\n",
    "    \n",
    "    return np.array(features), valid_geometries, invalid_geometries\n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None, hyperparameters=None, use_chunking=False, chunk_size=None, cancel_check=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    \n",
    "    # 验证SHP数据\n",
    "    validate_shp_data(gdf_train)\n",
    "    \n",
    "    X_new, valid_indices, _ = extract_features_chunked(image_path, gdf_train, use_chunking=use_chunking, chunk_size=chunk_size, progress_callback=progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    # 定义随机搜索的参数范围\n",
    "    if hyperparameters is None:\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(50, 300),\n",
    "            'max_depth': randint(5, 50),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "    # 创建随机搜索对象\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=hyperparameters,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 执行随机搜索\n",
    "    random_search.fit(X_combined, y_combined)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    clf = random_search.best_estimator_\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_combined)\n",
    "    accuracy = accuracy_score(y_combined, y_pred)\n",
    "    report = classification_report(y_combined, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"最佳参数: {random_search.best_params_}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "    logging.info(\"各类别精度:\")\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            logging.info(f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\")\n",
    "\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None, use_chunking=False, chunk_size=None, cancel_check=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices, invalid_indices = extract_features_chunked(new_image_path, gdf_new, use_chunking=use_chunking, chunk_size=chunk_size, progress_callback=progress_callback)\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    \n",
    "    # 为有效的几何体添加预测结果\n",
    "    gdf_new.loc[valid_indices, 'ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new.loc[valid_indices, 'ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    \n",
    "    # 为无效的几何体添加标记\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW'] = 'Invalid'\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW_proba'] = 0\n",
    "    \n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "    return len(invalid_indices)\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"RGB分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "\n",
    "        # 初始化所有需要的属性\n",
    "        self.use_chunking = tk.BooleanVar(value=False)\n",
    "        self.chunk_size = tk.IntVar(value=1024)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        self.shp_path = tk.StringVar()\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        self.output_path = tk.StringVar()\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "        self.cancel_operation = False\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"模型信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        tif_entry = ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50)\n",
    "        tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.tif_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择带有标签的SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        shp_entry = ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50)\n",
    "        shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.shp_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "\n",
    "        ttk.Checkbutton(self.train_tab, text=\"使用分块处理\", variable=self.use_chunking, command=self.toggle_chunk_size).grid(row=4, column=0, columnspan=2, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        self.chunk_size_label = ttk.Label(self.train_tab, text=\"分块大小:\")\n",
    "        self.chunk_size_label.grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.chunk_size_entry = ttk.Entry(self.train_tab, textvariable=self.chunk_size, width=10)\n",
    "        self.chunk_size_entry.grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 初始状态下禁用分块大小输入\n",
    "        self.chunk_size_label['state'] = 'disabled'\n",
    "        self.chunk_size_entry['state'] = 'disabled'\n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=6, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        predict_tif_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50)\n",
    "        predict_tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        predict_tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_tif_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        predict_shp_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50)\n",
    "        predict_shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        predict_shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_shp_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Checkbutton(self.predict_tab, text=\"使用分块处理\", variable=self.use_chunking, command=self.toggle_chunk_size).grid(row=4, column=0, columnspan=2, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        self.chunk_size_label_predict = ttk.Label(self.predict_tab, text=\"分块大小:\")\n",
    "        self.chunk_size_label_predict.grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.chunk_size_entry_predict = ttk.Entry(self.predict_tab, textvariable=self.chunk_size, width=10)\n",
    "        self.chunk_size_entry_predict.grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        \n",
    "        # 初始状态下禁用分块大小输入\n",
    "        self.chunk_size_label_predict['state'] = 'disabled'\n",
    "        self.chunk_size_entry_predict['state'] = 'disabled'\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=6, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"获取模型信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def toggle_chunk_size(self):\n",
    "        state = 'normal' if self.use_chunking.get() else 'disabled'\n",
    "        self.chunk_size_label['state'] = state\n",
    "        self.chunk_size_entry['state'] = state\n",
    "        self.chunk_size_label_predict['state'] = state\n",
    "        self.chunk_size_entry_predict['state'] = state\n",
    "\n",
    "    def drop_file(self, event, path_var):\n",
    "        file_path = event.data\n",
    "        if file_path.startswith('{') and file_path.endswith('}'):\n",
    "            file_path = file_path[1:-1]\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        if (path_var in [self.tif_path, self.predict_tif_path] and file_extension == '.tif') or \\\n",
    "           (path_var in [self.shp_path, self.predict_shp_path] and file_extension == '.shp'):\n",
    "            path_var.set(file_path)\n",
    "        else:\n",
    "            messagebox.showerror(\"错误\", \"请拖放正确的文件类型\")\n",
    "\n",
    "    def preview_file(self, path_var):\n",
    "        file_path = path_var.get()\n",
    "        if not file_path:\n",
    "            messagebox.showwarning(\"警告\", \"请先选择文件\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            info = self.get_file_info(file_path)\n",
    "            messagebox.showinfo(\"文件预览\", info)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"错误\", f\"无法预览文件：{str(e)}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_info(file_path):\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "        file_type = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        info = f\"文件路径: {file_path}\\n\"\n",
    "        info += f\"文件大小: {file_size:.2f} MB\\n\"\n",
    "        info += f\"文件类型: {file_type}\\n\"\n",
    "        \n",
    "        if file_type == '.tif':\n",
    "            with rasterio.open(file_path) as src:\n",
    "                info += f\"图像大小: {src.width} x {src.height}\\n\"\n",
    "                info += f\"波段数: {src.count}\\n\"\n",
    "                info += f\"坐标系统: {src.crs}\\n\"\n",
    "        elif file_type == '.shp':\n",
    "            gdf = gpd.read_file(file_path)\n",
    "            info += f\"要素数量: {len(gdf)}\\n\"\n",
    "            info += f\"几何类型: {gdf.geom_type.iloc[0]}\\n\"\n",
    "            info += f\"属性列: {', '.join(gdf.columns)}\\n\"\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def start_training(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        use_chunking = self.use_chunking.get()\n",
    "        chunk_size = self.chunk_size.get() if use_chunking else None\n",
    "\n",
    "        def training_thread():\n",
    "            try:\n",
    "                accuracy, report = update_or_train_model(\n",
    "                    tif_file, shp_file, \n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                    force_new,\n",
    "                    self.update_progress,\n",
    "                    use_chunking=use_chunking,\n",
    "                    chunk_size=chunk_size,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.training_complete(accuracy, report))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"训练过程中出错\")\n",
    "                error_message = str(e)\n",
    "                self.master.after(0, lambda: self.training_error(error_message))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=training_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.train_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def start_prediction(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "        use_chunking = self.use_chunking.get()\n",
    "        chunk_size = self.chunk_size.get() if use_chunking else None\n",
    "\n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                invalid_count = predict_new_data(\n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    tif_file, shp_file, output_file,\n",
    "                    self.update_progress,\n",
    "                    use_chunking=use_chunking,\n",
    "                    chunk_size=chunk_size,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.prediction_complete(invalid_count))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"预测过程中出错\")\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=prediction_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.predict_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self, accuracy, report):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        self.log_text.insert(tk.END, f\"模型整体精度: {accuracy:.4f}\\n\")\n",
    "        self.log_text.insert(tk.END, \"各类别精度:\\n\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                self.log_text.insert(tk.END, f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\\n模型整体精度: {accuracy:.4f}\")\n",
    "        self.refresh_info()\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def prediction_complete(self, invalid_count):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        if invalid_count > 0:\n",
    "            self.log_text.insert(tk.END, f\"警告：{invalid_count}个几何体无法进行预测，已在输出中标记为'Invalid'\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"预测完成\\n{invalid_count}个几何体无法预测\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            info += f\"最大深度：{model.max_depth}\\n\"\n",
    "            info += f\"最小分裂样本数：{model.min_samples_split}\\n\"\n",
    "            info += f\"最小叶子节点样本数：{model.min_samples_leaf}\\n\"\n",
    "            info += f\"特征选择方式：{model.max_features}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"RGB分类模型 v1.0\\n\\n作者：AI 贵州雏阳\\n\\n版权所有 © 2024\")\n",
    "\n",
    "    def cancel_current_operation(self):\n",
    "        self.cancel_operation = True\n",
    "        self.log_text.insert(tk.END, \"正在取消操作...\\n\")\n",
    "        self.status_bar['text'] = \"正在取消...\"\n",
    "\n",
    "    def operation_cancelled(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"操作已取消\"\n",
    "        self.log_text.insert(tk.END, \"操作已取消\\n\")\n",
    "        messagebox.showinfo(\"已取消\", \"操作已被用户取消\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def validate_inputs(self):\n",
    "        errors = []\n",
    "        if not self.tif_path.get():\n",
    "            errors.append(\"请选择TIF文件\")\n",
    "        if not self.shp_path.get():\n",
    "            errors.append(\"请选择SHP文件\")\n",
    "        if self.use_chunking.get() and (self.chunk_size.get() <= 0 or self.chunk_size.get() > 10000):\n",
    "            errors.append(\"分块大小应在1到10000之间\")\n",
    "        return errors\n",
    "\n",
    "def main():\n",
    "    root = tkinterdnd2.TkinterDnD.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "\n",
    "import joblib\n",
    "import threading\n",
    "import queue\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import rasterio\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2hsv\n",
    "import fiona\n",
    "from collections import Counter\n",
    "from scipy.stats import randint, uniform\n",
    "import tkinterdnd2\n",
    "# 修改版本号\n",
    "np.__version__ = '1.23.0'\n",
    "# 配置日志记录\n",
    "def setup_logging():\n",
    "    log_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    log_file = 'crop_classification.log'\n",
    "    log_handler = RotatingFileHandler(log_file, maxBytes=1024 * 1024, backupCount=5)\n",
    "    log_handler.setFormatter(log_formatter)\n",
    "    log_handler.setLevel(logging.INFO)\n",
    "\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    root_logger.addHandler(log_handler)\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "fiona.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "# gpd.io.file.fiona.drvsupport.supported_drivers['ESRI Shapefile'] = 'rw'\n",
    "\n",
    "def validate_shp_data(gdf, column_name='ZZZW'):\n",
    "    \"\"\"\n",
    "    验证SHP数据是否包含指定的标签列，以及该列是否有空值\n",
    "    \"\"\"\n",
    "    if column_name not in gdf.columns:\n",
    "        raise ValueError(f\"SHP文件中缺少'{column_name}'列\")\n",
    "    \n",
    "    if gdf[column_name].isnull().any():\n",
    "        raise ValueError(f\"'{column_name}'列中存在空值\")\n",
    "\n",
    "def extract_features(image_path, gdf, progress_callback=None):\n",
    "    features = []\n",
    "    valid_geometries = []\n",
    "    invalid_geometries = []\n",
    "    total_geometries = len(gdf)\n",
    "\n",
    "    with rasterio.open(image_path) as src:\n",
    "        for idx, geometry in enumerate(gdf.geometry):\n",
    "            try:\n",
    "                window = rasterio.windows.from_bounds(*geometry.bounds, src.transform)\n",
    "                masked_image = src.read(window=window, indexes=[1, 2, 3])\n",
    "                \n",
    "                if masked_image.shape[0] < 3 or masked_image.size == 0:\n",
    "                    logging.warning(f\"几何体 {idx}: 无数据\")\n",
    "                    invalid_geometries.append(idx)\n",
    "                    continue\n",
    "                \n",
    "                rgb_means = np.nanmean(masked_image, axis=(1, 2))\n",
    "                rgb_stds = np.nanstd(masked_image, axis=(1, 2))\n",
    "                \n",
    "                r, g, b = rgb_means\n",
    "                exg = 2 * g - r - b\n",
    "                vari = (g - r) / (g + r - b + 1e-8)\n",
    "                \n",
    "                hsv_image = rgb2hsv(np.moveaxis(masked_image, 0, -1))\n",
    "                hsv_means = np.nanmean(hsv_image, axis=(0, 1))\n",
    "                \n",
    "                green_channel = masked_image[1].astype(np.uint8)\n",
    "                if green_channel.size > 0:\n",
    "                    glcm = graycomatrix(green_channel, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "                    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "                    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "                    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "                    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "                else:\n",
    "                    contrast = dissimilarity = homogeneity = energy = correlation = 0\n",
    "                \n",
    "                feature = np.concatenate([rgb_means, rgb_stds, [exg, vari], hsv_means, \n",
    "                                          [contrast, dissimilarity, homogeneity, energy, correlation]])\n",
    "                features.append(feature)\n",
    "                valid_geometries.append(idx)\n",
    "\n",
    "                if progress_callback:\n",
    "                    progress_callback((idx + 1) / total_geometries * 100)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"处理几何体 {idx} 时出错: {str(e)}\")\n",
    "                invalid_geometries.append(idx)\n",
    "    \n",
    "    if not features:\n",
    "        raise ValueError(\"没有成功提取到任何特征\")\n",
    "    \n",
    "    return np.array(features), valid_geometries, invalid_geometries\n",
    "    \n",
    "def update_or_train_model(image_path, train_shp_path, model_output_path, le_output_path, data_output_path, force_new_model=False, progress_callback=None, hyperparameters=None, cancel_check=None):\n",
    "    logging.info(f\"开始{'创建新模型' if force_new_model else '更新模型'}\")\n",
    "    gdf_train = gpd.read_file(train_shp_path, encoding='utf-8')\n",
    "    \n",
    "    # 验证SHP数据\n",
    "    validate_shp_data(gdf_train)\n",
    "    \n",
    "    X_new, valid_indices, _ = extract_features(image_path, gdf_train, progress_callback=progress_callback)\n",
    "    gdf_train = gdf_train.iloc[valid_indices]\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y_new = le.fit_transform(gdf_train['ZZZW'])\n",
    "    \n",
    "    if os.path.exists(model_output_path) and os.path.exists(le_output_path) and os.path.exists(data_output_path) and not force_new_model:\n",
    "        logging.info(\"加载现有模型并进行更新\")\n",
    "        clf = joblib.load(model_output_path)\n",
    "        X_old, y_old = joblib.load(data_output_path)\n",
    "        \n",
    "        if X_old.shape[1] != X_new.shape[1]:\n",
    "            logging.warning(f\"新旧数据的特征数量不一致。旧数据：{X_old.shape[1]}，新数据：{X_new.shape[1]}\")\n",
    "            logging.info(\"将重新训练模型\")\n",
    "            X_combined, y_combined = X_new, y_new\n",
    "        else:\n",
    "            X_combined = np.vstack((X_old, X_new))\n",
    "            y_combined = np.concatenate((y_old, y_new))\n",
    "    else:\n",
    "        logging.info(\"创建新模型\")\n",
    "        X_combined, y_combined = X_new, y_new\n",
    "\n",
    "    # 定义随机搜索的参数范围\n",
    "    if hyperparameters is None:\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(10, 1000),\n",
    "            'max_depth': randint(2, 50),\n",
    "            'min_samples_split': randint(2, 50),\n",
    "            'min_samples_leaf': randint(1, 20),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "\n",
    "    # 创建随机搜索对象\n",
    "    random_search = RandomizedSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_distributions=hyperparameters,\n",
    "        n_iter=50,\n",
    "        cv=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # 执行随机搜索\n",
    "    random_search.fit(X_combined, y_combined)\n",
    "\n",
    "    # 获取最佳模型\n",
    "    clf = random_search.best_estimator_\n",
    "\n",
    "    # 评估模型\n",
    "    y_pred = clf.predict(X_combined)\n",
    "    accuracy = accuracy_score(y_combined, y_pred)\n",
    "    report = classification_report(y_combined, y_pred, target_names=le.classes_, output_dict=True)\n",
    "\n",
    "    # 保存模型和数据\n",
    "    joblib.dump(clf, model_output_path)\n",
    "    joblib.dump(le, le_output_path)\n",
    "    joblib.dump((X_combined, y_combined), data_output_path)\n",
    "\n",
    "    logging.info(f\"模型已保存到: {model_output_path}\")\n",
    "    logging.info(f\"标签编码器已保存到: {le_output_path}\")\n",
    "    logging.info(f\"训练数据已保存到: {data_output_path}\")\n",
    "    logging.info(f\"最佳参数: {random_search.best_params_}\")\n",
    "    logging.info(f\"模型整体精度: {accuracy}\")\n",
    "    logging.info(\"各类别精度:\")\n",
    "    for class_name, metrics in report.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            logging.info(f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\")\n",
    "\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "\n",
    "    return accuracy, report\n",
    "\n",
    "def predict_new_data(model_path, le_path, new_image_path, new_shp_path, output_shp_path, progress_callback=None, use_chunking=False, chunk_size=None, cancel_check=None):\n",
    "    logging.info(\"开始预测新数据\")\n",
    "    clf = joblib.load(model_path)\n",
    "    le = joblib.load(le_path)\n",
    "\n",
    "    gdf_new = gpd.read_file(new_shp_path, encoding='utf-8')\n",
    "    X_new, valid_indices, invalid_indices = extract_features(new_image_path, gdf_new, use_chunking=use_chunking, chunk_size=chunk_size, progress_callback=progress_callback)\n",
    "    \n",
    "    if X_new.shape[1] != clf.n_features_in_:\n",
    "        raise ValueError(f\"错误：特征数量不匹配。模型期望 {clf.n_features_in_} 个特征，但提供了 {X_new.shape[1]} 个特征。\")\n",
    "    \n",
    "    y_pred = clf.predict(X_new)\n",
    "    y_proba = clf.predict_proba(X_new)\n",
    "    \n",
    "    # 为有效的几何体添加预测结果\n",
    "    gdf_new.loc[valid_indices, 'ZZZW'] = le.inverse_transform(y_pred)\n",
    "    gdf_new.loc[valid_indices, 'ZZZW_proba'] = np.max(y_proba, axis=1)\n",
    "    \n",
    "    # 为无效的几何体添加标记\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW'] = 'Invalid'\n",
    "    gdf_new.loc[invalid_indices, 'ZZZW_proba'] = 0\n",
    "    \n",
    "    gdf_new.to_file(output_shp_path, encoding='utf-8')\n",
    "\n",
    "    if cancel_check and cancel_check():\n",
    "        raise InterruptedError(\"操作被用户取消\")\n",
    "\n",
    "    logging.info(f\"预测结果已保存到: {output_shp_path}\")\n",
    "    return len(invalid_indices)\n",
    "\n",
    "class CropClassificationApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"RGB分类模型\")\n",
    "        master.geometry(\"800x600\")\n",
    "\n",
    "        # 初始化所有需要的属性\n",
    "        self.tif_path = tk.StringVar()\n",
    "        self.shp_path = tk.StringVar()\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        self.output_path = tk.StringVar()\n",
    "\n",
    "        # 添加这些行来初始化超参数变量\n",
    "        self.n_estimators_min = tk.IntVar(value=50)\n",
    "        self.n_estimators_max = tk.IntVar(value=300)\n",
    "        self.max_depth_min = tk.IntVar(value=5)\n",
    "        self.max_depth_max = tk.IntVar(value=50)\n",
    "\n",
    "        self.create_widgets()\n",
    "        self.create_menu()\n",
    "\n",
    "        self.progress_queue = queue.Queue()\n",
    "        self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "        self.cancel_operation = False\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.notebook = ttk.Notebook(self.master)\n",
    "        self.notebook.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "        self.train_tab = ttk.Frame(self.notebook)\n",
    "        self.predict_tab = ttk.Frame(self.notebook)\n",
    "        self.info_tab = ttk.Frame(self.notebook)\n",
    "\n",
    "        self.notebook.add(self.train_tab, text=\"训练模型\")\n",
    "        self.notebook.add(self.predict_tab, text=\"模型预测\")\n",
    "        self.notebook.add(self.info_tab, text=\"模型信息\")\n",
    "\n",
    "        self.setup_train_tab()\n",
    "        self.setup_predict_tab()\n",
    "        self.setup_info_tab()\n",
    "\n",
    "        self.status_bar = ttk.Label(self.master, text=\"就绪\", relief=tk.SUNKEN, anchor=tk.W)\n",
    "        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        self.progress = ttk.Progressbar(self.master, length=780, mode='determinate')\n",
    "        self.progress.pack(pady=10)\n",
    "\n",
    "        self.log_text = scrolledtext.ScrolledText(self.master, wrap=tk.WORD, width=95, height=10)\n",
    "        self.log_text.pack(padx=10, pady=10)\n",
    "\n",
    "    def create_menu(self):\n",
    "        menubar = tk.Menu(self.master)\n",
    "        self.master.config(menu=menubar)\n",
    "\n",
    "        file_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"文件\", menu=file_menu)\n",
    "        file_menu.add_command(label=\"退出\", command=self.master.quit)\n",
    "\n",
    "        help_menu = tk.Menu(menubar, tearoff=0)\n",
    "        menubar.add_cascade(label=\"帮助\", menu=help_menu)\n",
    "        help_menu.add_command(label=\"关于\", command=self.show_about)\n",
    "\n",
    "    def setup_train_tab(self):\n",
    "        ttk.Label(self.train_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.tif_path = tk.StringVar()\n",
    "        tif_entry = ttk.Entry(self.train_tab, textvariable=self.tif_path, width=50)\n",
    "        tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.tif_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"选择带有标签的SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.shp_path = tk.StringVar()\n",
    "        shp_entry = ttk.Entry(self.train_tab, textvariable=self.shp_path, width=50)\n",
    "        shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.shp_path))\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=lambda: self.browse_file(self.shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"预览\", command=lambda: self.preview_file(self.shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"模型存储路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.train_tab, textvariable=self.model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.train_tab, text=\"浏览\", command=self.browse_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        self.model_action = tk.StringVar(value=\"update\")\n",
    "        ttk.Radiobutton(self.train_tab, text=\"更新现有模型\", variable=self.model_action, value=\"update\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Radiobutton(self.train_tab, text=\"创建新模型\", variable=self.model_action, value=\"new\").grid(row=3, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "\n",
    "        # 添加超参数设置控件\n",
    "        ttk.Label(self.train_tab, text=\"n_estimators:\").grid(row=4, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_min, width=5).grid(row=4, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=4, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.n_estimators_max, width=5).grid(row=4, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.train_tab, text=\"max_depth:\").grid(row=5, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_min, width=5).grid(row=5, column=1, sticky=\"w\", padx=5, pady=5)\n",
    "        ttk.Label(self.train_tab, text=\"-\").grid(row=5, column=1)\n",
    "        ttk.Entry(self.train_tab, textvariable=self.max_depth_max, width=5).grid(row=5, column=1, sticky=\"e\", padx=5, pady=5)\n",
    "        \n",
    "\n",
    "        self.train_button = ttk.Button(self.train_tab, text=\"开始训练\", command=self.start_training)\n",
    "        self.train_button.grid(row=6, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_predict_tab(self):\n",
    "        ttk.Label(self.predict_tab, text=\"选择TIF文件:\").grid(row=0, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_tif_path = tk.StringVar()\n",
    "        predict_tif_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_tif_path, width=50)\n",
    "        predict_tif_entry.grid(row=0, column=1, padx=5, pady=5)\n",
    "        predict_tif_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_tif_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_tif_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_tif_path, [(\"TIF files\", \"*.tif\")])).grid(row=0, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_tif_path)).grid(row=0, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"选择SHP文件:\").grid(row=1, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_shp_path = tk.StringVar()\n",
    "        predict_shp_entry = ttk.Entry(self.predict_tab, textvariable=self.predict_shp_path, width=50)\n",
    "        predict_shp_entry.grid(row=1, column=1, padx=5, pady=5)\n",
    "        predict_shp_entry.drop_target_register(tkinterdnd2.DND_FILES)\n",
    "        predict_shp_entry.dnd_bind('<<Drop>>', lambda e: self.drop_file(e, self.predict_shp_path))\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_file(self.predict_shp_path, [(\"SHP files\", \"*.shp\")])).grid(row=1, column=2, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"预览\", command=lambda: self.preview_file(self.predict_shp_path)).grid(row=1, column=3, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"模型路径:\").grid(row=2, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.predict_model_path = tk.StringVar(value=os.getcwd())\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.predict_model_path, width=50).grid(row=2, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=self.browse_predict_model_path).grid(row=2, column=2, padx=5, pady=5)\n",
    "\n",
    "        ttk.Label(self.predict_tab, text=\"输出文件路径:\").grid(row=3, column=0, sticky=\"w\", padx=5, pady=5)\n",
    "        self.output_path = tk.StringVar()\n",
    "        ttk.Entry(self.predict_tab, textvariable=self.output_path, width=50).grid(row=3, column=1, padx=5, pady=5)\n",
    "        ttk.Button(self.predict_tab, text=\"浏览\", command=lambda: self.browse_save_file(self.output_path, [(\"SHP files\", \"*.shp\")])).grid(row=3, column=2, padx=5, pady=5)\n",
    "\n",
    "\n",
    "        self.predict_button = ttk.Button(self.predict_tab, text=\"开始预测\", command=self.start_prediction)\n",
    "        self.predict_button.grid(row=6, column=0, columnspan=3, pady=20)\n",
    "\n",
    "    def setup_info_tab(self):\n",
    "        self.info_text = scrolledtext.ScrolledText(self.info_tab, wrap=tk.WORD, width=90, height=20)\n",
    "        self.info_text.pack(padx=10, pady=10)\n",
    "\n",
    "        ttk.Button(self.info_tab, text=\"获取模型信息\", command=self.refresh_info).pack(pady=10)\n",
    "\n",
    "    def browse_file(self, path_var, file_types):\n",
    "        filename = filedialog.askopenfilename(filetypes=file_types)\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_save_file(self, path_var, file_types):\n",
    "        filename = filedialog.asksaveasfilename(filetypes=file_types, defaultextension=file_types[0][1])\n",
    "        if filename:\n",
    "            path_var.set(filename)\n",
    "\n",
    "    def browse_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.model_path.set(path)\n",
    "\n",
    "    def browse_predict_model_path(self):\n",
    "        path = filedialog.askdirectory()\n",
    "        if path:\n",
    "            self.predict_model_path.set(path)\n",
    "\n",
    "    def toggle_chunk_size(self):\n",
    "        state = 'normal' if self.use_chunking.get() else 'disabled'\n",
    "        self.chunk_size_label['state'] = state\n",
    "        self.chunk_size_entry['state'] = state\n",
    "        self.chunk_size_label_predict['state'] = state\n",
    "        self.chunk_size_entry_predict['state'] = state\n",
    "\n",
    "    def drop_file(self, event, path_var):\n",
    "        file_path = event.data\n",
    "        if file_path.startswith('{') and file_path.endswith('}'):\n",
    "            file_path = file_path[1:-1]\n",
    "        file_extension = os.path.splitext(file_path)[1].lower()\n",
    "        if (path_var in [self.tif_path, self.predict_tif_path] and file_extension == '.tif') or \\\n",
    "           (path_var in [self.shp_path, self.predict_shp_path] and file_extension == '.shp'):\n",
    "            path_var.set(file_path)\n",
    "        else:\n",
    "            messagebox.showerror(\"错误\", \"请拖放正确的文件类型\")\n",
    "\n",
    "    def preview_file(self, path_var):\n",
    "        file_path = path_var.get()\n",
    "        if not file_path:\n",
    "            messagebox.showwarning(\"警告\", \"请先选择文件\")\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            info = self.get_file_info(file_path)\n",
    "            messagebox.showinfo(\"文件预览\", info)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"错误\", f\"无法预览文件：{str(e)}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_info(file_path):\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # Size in MB\n",
    "        file_type = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        info = f\"文件路径: {file_path}\\n\"\n",
    "        info += f\"文件大小: {file_size:.2f} MB\\n\"\n",
    "        info += f\"文件类型: {file_type}\\n\"\n",
    "        \n",
    "        if file_type == '.tif':\n",
    "            with rasterio.open(file_path) as src:\n",
    "                info += f\"图像大小: {src.width} x {src.height}\\n\"\n",
    "                info += f\"波段数: {src.count}\\n\"\n",
    "                info += f\"坐标系统: {src.crs}\\n\"\n",
    "        elif file_type == '.shp':\n",
    "            gdf = gpd.read_file(file_path)\n",
    "            info += f\"要素数量: {len(gdf)}\\n\"\n",
    "            info += f\"几何类型: {gdf.geom_type.iloc[0]}\\n\"\n",
    "            info += f\"属性列: {', '.join(gdf.columns)}\\n\"\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def start_training(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"训练中...\"\n",
    "        self.log_text.insert(tk.END, \"开始训练...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.tif_path.get()\n",
    "        shp_file = self.shp_path.get()\n",
    "        model_dir = self.model_path.get()\n",
    "        force_new = self.model_action.get() == \"new\"\n",
    "        # 添加超参数设置\n",
    "        hyperparameters = {\n",
    "            'n_estimators': randint(self.n_estimators_min.get(), self.n_estimators_max.get()),\n",
    "            'max_depth': randint(self.max_depth_min.get(), self.max_depth_max.get()),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': uniform(0.1, 0.9)\n",
    "        }\n",
    "        def training_thread():\n",
    "            try:\n",
    "                accuracy, report = update_or_train_model(\n",
    "                    tif_file, shp_file, \n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    os.path.join(model_dir, \"training_data.joblib\"), \n",
    "                    force_new,\n",
    "                    self.update_progress,\n",
    "                     hyperparameters=hyperparameters,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.training_complete(accuracy, report))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"训练过程中出错\")\n",
    "                error_message = str(e)\n",
    "                self.master.after(0, lambda: self.training_error(error_message))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=training_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.train_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "\n",
    "    def start_prediction(self):\n",
    "        errors = self.validate_inputs()\n",
    "        if errors:\n",
    "            messagebox.showerror(\"输入错误\", \"\\n\".join(errors))\n",
    "            return\n",
    "\n",
    "        self.disable_buttons()\n",
    "        self.progress['value'] = 0\n",
    "        self.status_bar['text'] = \"预测中...\"\n",
    "        self.log_text.insert(tk.END, \"开始预测...\\n\")\n",
    "        self.cancel_operation = False\n",
    "\n",
    "        tif_file = self.predict_tif_path.get()\n",
    "        shp_file = self.predict_shp_path.get()\n",
    "        model_dir = self.predict_model_path.get()\n",
    "        output_file = self.output_path.get()\n",
    "        # 添加文件存在性检查\n",
    "        if not self.check_file_exists(tif_file):\n",
    "            self.prediction_error(f\"TIF文件不存在: {tif_file}\")\n",
    "            return\n",
    "        if not self.check_file_exists(shp_file):\n",
    "            self.prediction_error(f\"SHP文件不存在: {shp_file}\")\n",
    "            return\n",
    "        if not self.check_file_exists(os.path.join(model_dir, \"model.joblib\")):\n",
    "            self.prediction_error(f\"模型文件不存在: {os.path.join(model_dir, 'model.joblib')}\")\n",
    "            return\n",
    "        def prediction_thread():\n",
    "            try:\n",
    "                invalid_count = predict_new_data(\n",
    "                    os.path.join(model_dir, \"model.joblib\"), \n",
    "                    os.path.join(model_dir, \"label_encoder.joblib\"), \n",
    "                    tif_file, shp_file, output_file,\n",
    "                    self.update_progress,\n",
    "                    cancel_check=lambda: self.cancel_operation\n",
    "                )\n",
    "                if not self.cancel_operation:\n",
    "                    self.master.after(0, lambda: self.prediction_complete(invalid_count))\n",
    "                else:\n",
    "                    self.master.after(0, self.operation_cancelled)\n",
    "            except Exception as e:\n",
    "                logging.exception(\"预测过程中出错\")\n",
    "                self.master.after(0, lambda: self.prediction_error(str(e)))\n",
    "\n",
    "        self.current_thread = threading.Thread(target=prediction_thread)\n",
    "        self.current_thread.start()\n",
    "\n",
    "        # 添加取消按钮\n",
    "        self.cancel_button = ttk.Button(self.predict_tab, text=\"取消\", command=self.cancel_current_operation)\n",
    "        self.cancel_button.grid(row=7, column=0, columnspan=3, pady=10)\n",
    "    def check_file_exists(self, file_path):\n",
    "        return os.path.exists(file_path)\n",
    "    def update_progress(self, value):\n",
    "        self.progress_queue.put(value)\n",
    "\n",
    "    def check_progress_queue(self):\n",
    "        try:\n",
    "            while True:\n",
    "                value = self.progress_queue.get_nowait()\n",
    "                self.progress['value'] = value\n",
    "        except queue.Empty:\n",
    "            pass\n",
    "        finally:\n",
    "            self.master.after(100, self.check_progress_queue)\n",
    "\n",
    "    def training_complete(self, accuracy, report):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练完成\"\n",
    "        action_text = \"创建新模型\" if self.model_action.get() == \"new\" else \"更新现有模型\"\n",
    "        self.log_text.insert(tk.END, f\"{action_text}完成\\n\")\n",
    "        self.log_text.insert(tk.END, f\"模型整体精度: {accuracy:.4f}\\n\")\n",
    "        self.log_text.insert(tk.END, \"各类别精度:\\n\")\n",
    "        for class_name, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                self.log_text.insert(tk.END, f\"{class_name}: 精度 = {metrics['precision']:.2f}, 召回率 = {metrics['recall']:.2f}, F1分数 = {metrics['f1-score']:.2f}\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"{action_text}完成\\n模型整体精度: {accuracy:.4f}\")\n",
    "        self.refresh_info()\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def prediction_complete(self, invalid_count):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测完成\"\n",
    "        self.log_text.insert(tk.END, \"预测完成\\n\")\n",
    "        if invalid_count > 0:\n",
    "            self.log_text.insert(tk.END, f\"警告：{invalid_count}个几何体无法进行预测，已在输出中标记为'Invalid'\\n\")\n",
    "        messagebox.showinfo(\"成功\", f\"预测完成\\n{invalid_count}个几何体无法预测\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def training_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"训练出错\"\n",
    "        self.log_text.insert(tk.END, f\"训练过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"训练过程中出错：{error_message}\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def prediction_error(self, error_message):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"预测出错\"\n",
    "        self.log_text.insert(tk.END, f\"预测过程中出错：{error_message}\\n\")\n",
    "        messagebox.showerror(\"错误\", f\"预测过程中出错：{error_message}\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def refresh_info(self):\n",
    "        self.info_text.delete('1.0', tk.END)\n",
    "        model_dir = self.model_path.get()\n",
    "        try:\n",
    "            model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "            le = joblib.load(os.path.join(model_dir, \"label_encoder.joblib\"))\n",
    "            \n",
    "            info = f\"模型信息：\\n\"\n",
    "            info += f\"模型存储路径：{model_dir}\\n\"\n",
    "            info += f\"特征数量：{model.n_features_in_}\\n\"\n",
    "            info += f\"类别：{', '.join(le.classes_)}\\n\"\n",
    "            info += f\"树的数量：{model.n_estimators}\\n\"\n",
    "            info += f\"最大深度：{model.max_depth}\\n\"\n",
    "            info += f\"最小分裂样本数：{model.min_samples_split}\\n\"\n",
    "            info += f\"最小叶子节点样本数：{model.min_samples_leaf}\\n\"\n",
    "            info += f\"特征选择方式：{model.max_features}\\n\"\n",
    "            \n",
    "            # 尝试加载训练数据并获取样本数量\n",
    "            try:\n",
    "                X, y = joblib.load(os.path.join(model_dir, \"training_data.joblib\"))\n",
    "                info += f\"参训练样本数量：{len(X)}\\n\"\n",
    "            except Exception as e:\n",
    "                info += f\"无法加载训练数据信息：{str(e)}\\n\"\n",
    "            \n",
    "            self.info_text.insert(tk.END, info)\n",
    "        except Exception as e:\n",
    "            self.info_text.insert(tk.END, f\"无法加载模型信息：{str(e)}\")\n",
    "\n",
    "    def disable_buttons(self):\n",
    "        self.train_button['state'] = 'disabled'\n",
    "        self.predict_button['state'] = 'disabled'\n",
    "\n",
    "    def enable_buttons(self):\n",
    "        self.train_button['state'] = 'normal'\n",
    "        self.predict_button['state'] = 'normal'\n",
    "\n",
    "    def show_about(self):\n",
    "        messagebox.showinfo(\"关于\", \"RGB分类模型 v1.0\\n\\n作者：AI 贵州雏阳\\n\\n版权所有 © 2024\")\n",
    "\n",
    "    def cancel_current_operation(self):\n",
    "        self.cancel_operation = True\n",
    "        self.log_text.insert(tk.END, \"正在取消操作...\\n\")\n",
    "        self.status_bar['text'] = \"正在取消...\"\n",
    "\n",
    "    def operation_cancelled(self):\n",
    "        self.enable_buttons()\n",
    "        self.status_bar['text'] = \"操作已取消\"\n",
    "        self.log_text.insert(tk.END, \"操作已取消\\n\")\n",
    "        messagebox.showinfo(\"已取消\", \"操作已被用户取消\")\n",
    "        if hasattr(self, 'cancel_button'):\n",
    "            self.cancel_button.destroy()\n",
    "\n",
    "    def validate_inputs(self):\n",
    "        errors = []\n",
    "        if self.notebook.index(self.notebook.select()) == 0:  # Training tab\n",
    "            if not self.tif_path.get():\n",
    "                errors.append(\"请选择训练用TIF文件\")\n",
    "            if not self.shp_path.get():\n",
    "                errors.append(\"请选择训练用SHP文件\")\n",
    "        else:  # Prediction tab\n",
    "            if not self.predict_tif_path.get():\n",
    "                errors.append(\"请选择预测用TIF文件\")\n",
    "            if not self.predict_shp_path.get():\n",
    "                errors.append(\"请选择预测用SHP文件\")\n",
    "            if not self.predict_model_path.get():\n",
    "                errors.append(\"请选择模型路径\")\n",
    "            if not self.output_path.get():\n",
    "                errors.append(\"请选择输出文件路径\")\n",
    "        return errors\n",
    "\n",
    "def main():\n",
    "    root = tkinterdnd2.TkinterDnD.Tk()\n",
    "    app = CropClassificationApp(root)\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvgis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
