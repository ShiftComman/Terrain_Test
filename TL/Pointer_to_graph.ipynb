{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arcpy import env\n",
    "from arcpy.management import *\n",
    "from arcpy.conversion import *\n",
    "from arcpy.da import *\n",
    "from arcpy.sa import *\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,roc_auc_score,roc_curve,precision_recall_curve\n",
    "from sklearn.model_selection import cross_val_score,train_test_split\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析函数\n",
    "# 采样\n",
    "def sample_point(point_,raster_,out_name):\n",
    "    Sample(raster_,point_,out_name,\"NEAREST\", \"OBJECTID\", \"CURRENT_SLICE\", None, '', None, None, \"ROW_WISE\", \"TABLE\")\n",
    "    return None\n",
    "\n",
    "# 导出CSV\n",
    "def export_csv(table_,out_path,out_name):\n",
    "    TableToTable(table_,out_path,out_name)\n",
    "    return None\n",
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster\n",
    "# 数组整形\n",
    "def resize_arrays(A, B, fill_value=0):\n",
    "    \"\"\"调整数组形状一致\"\"\"\n",
    "    new_shape = (max(A.shape[0], B.shape[0]), max(A.shape[1], B.shape[1]))\n",
    "\n",
    "    if A.shape != new_shape:\n",
    "        if A.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - A.shape[0]\n",
    "            padding = np.full((padding_rows, A.shape[1]), fill_value)\n",
    "            A = np.vstack((A, padding))\n",
    "        elif A.shape[0] > new_shape[0]:\n",
    "            A = A[:new_shape[0], :]\n",
    "\n",
    "        if A.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - A.shape[1]))\n",
    "            A = np.pad(A, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif A.shape[1] > new_shape[1]:\n",
    "            A = A[:, :new_shape[1]]\n",
    "    \n",
    "    if B.shape != new_shape:\n",
    "        if B.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - B.shape[0]\n",
    "            padding = np.full((padding_rows, B.shape[1]), fill_value)\n",
    "            B = np.vstack((B, padding))\n",
    "        elif B.shape[0] > new_shape[0]:\n",
    "            B = B[:new_shape[0], :]\n",
    "\n",
    "        if B.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - B.shape[1]))\n",
    "            B = np.pad(B, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif B.shape[1] > new_shape[1]:\n",
    "            B = B[:, :new_shape[1]]\n",
    "    \n",
    "    return A, B\n",
    "# rf寻找最优参数\n",
    "def rf_best_param(X_train,y_train,n_estimators_range,k=5):\n",
    "    \"\"\"默认为5折交叉验证,评价指标为R2\"\"\"\n",
    "    # 设置树的数目范围\n",
    "    n_estimators_range = n_estimators_range\n",
    "    cv_scores = []\n",
    "    # 使用交叉验证\n",
    "    for n_estimators in n_estimators_range:\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "        scores = cross_val_score(rf,X_train, y_train, cv=k, scoring='r2')  # K折交叉验证\n",
    "        cv_scores.append(scores.mean())\n",
    "    # 选择最优数量的树\n",
    "    optimal_n_estimators = n_estimators_range[cv_scores.index(max(cv_scores))]\n",
    "    return optimal_n_estimators\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 地理数据库路径\n",
    "base_gdb_5m = r\"D:\\ArcgisData\\basedata\\basetrain_5m.gdb\"\n",
    "base_gdb_30m = r\"D:\\ArcgisData\\basedata\\basetrain_30m.gdb\"\n",
    "# 数据点文件路径\n",
    "point_data = r\"D:\\ArcgisData\\pred_tl\\pred_database\\TL.gdb\\SY_sample_pro\"\n",
    "# 存储采样数据表的文件地理数据库\n",
    "sample_gdb_path = r\"D:\\ArcgisData\\pred_organic_p_n\\feature_table\\tableresult.gdb\"\n",
    "# 存储采样结果CSV文件的路径\n",
    "sample_csv = r\"D:\\ArcgisData\\pred_organic_p_n\\feature_table\\feature_table_result\"\n",
    "# 输出CSV文件的名称\n",
    "sample_csv_name = \"feature_table_result.csv\"\n",
    "# 目标标签\n",
    "target_label = \"A\"\n",
    "# 随机森林树的范围\n",
    "n_estimators_range = range(10, 2000, 300)\n",
    "# rf模型存储路径\n",
    "modle_save_path = r\"D:\\ArcgisData\\pred_tl\\pred_moudle\"\n",
    "# rf模型名称\n",
    "modle_name = \"rf_model.pkl\"\n",
    "# 栅格输出标准化的数据库\n",
    "stander_raster_gdb = base_gdb_30m\n",
    "# 标准化待预测数据分割路径\n",
    "cut_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\cut_csv\"\n",
    "# 预测完成CSV文件存储路径\n",
    "pred_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\"\n",
    "# 完整预测数据存储路径\n",
    "merge_csv_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\merge_csv\"\n",
    "# 完整预测数据存储名称\n",
    "merge_csv_name = \"merge.csv\"\n",
    "# 栅格输出预测结果数据库\n",
    "pred_raster_gdb = r\"D:\\ArcgisData\\pred_tl\\pred_database\\TL_basedata.gdb\"\n",
    "# 栅格输出预测结果栅格名称\n",
    "pred_raster_name = \"TL_pred_raster\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', '代码', 'Shape_Leng', 'A', 'B', 'C', 'D']\n",
      "['OBJECTID', 'A', 'B', 'C', 'D']\n"
     ]
    }
   ],
   "source": [
    "# 采样点数据名称\n",
    "sample_name = 'SY_sample_pro'\n",
    "filed_list = [_.name for _ in arcpy.ListFields(point_data)]\n",
    "print(filed_list)\n",
    "elements_yes = ['OBJECTID', 'A', 'B','C','D']\n",
    "filter_list = [_ for _ in filed_list if _ in elements_yes]\n",
    "print(filter_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定指标\n",
    "# 指标列表['TWI5','TPI201','TPI101','TPI11','TPI3','TMP','SOILQS','SLOP','PRE','NIGTH','NDVI','DEM','CUR','ASP','PLCUR','POCUR','OSJL','LAT','LON','DZ','DL']\n",
    "feature_list = ['TWI5','TPI201','TMP','SLOP','PRE','NDVI','DEM','ASP','LAT','LON','DZ','DL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用训练点数据集采样并输出到csv文件\n",
    "# 选择用于采样的数据库\n",
    "env.workspace = base_gdb_5m # 切换工作空间用于采样\n",
    "# 选择用于采样的要素类\n",
    "point_data = point_data\n",
    "# 使用Delete_management函数删除数据库中的所有内容\n",
    "try:\n",
    "    arcpy.Delete_management(sample_gdb_path)\n",
    "except:\n",
    "    pass\n",
    "# 再创建一个新的数据库\n",
    "arcpy.management.CreateFileGDB(os.path.dirname(sample_gdb_path), \"tableresult\", \"CURRENT\")\n",
    "# 逐个采样并保存到csv文件\n",
    "for one_feature in feature_list:\n",
    "    sample_point(point_data,one_feature,os.path.join(sample_gdb_path,one_feature))\n",
    "env.workspace = os.path.join(sample_gdb_path) # 切换工作空间用于导出csv文件\n",
    "# 读取数据表并保存到csv文件\n",
    "result_df = pd.DataFrame(arcpy.da.FeatureClassToNumPyArray(point_data,filter_list))\n",
    "result_df.rename(columns={\"OBJECTID\":sample_name},inplace=True)\n",
    "#  读取每个表的最后一个字段的数据,存储每个表的最后一个字段的数据\n",
    "for table in feature_list:\n",
    "    # 将表转换为pandas数据帧\n",
    "    df = pd.DataFrame(arcpy.da.TableToNumPyArray(table, \"*\"))  # 确保数据表中无空值\n",
    "    # 提取最后一个字段的数据\n",
    "    merged_df = df[[sample_name, df.columns[-1]]]\n",
    "    # 合并\n",
    "    result_df = pd.merge(result_df, merged_df, on=[sample_name])\n",
    "# 保存到csv文件\n",
    "result_df.rename(columns=dict(zip(result_df.columns[-len(feature_list):], feature_list)),inplace=True)\n",
    "result_df.drop(result_df.columns[0],axis=1,inplace=True)\n",
    "result_df.to_csv(os.path.join(sample_csv,sample_csv_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n",
      "最优树的个数为:910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=910, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=910, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=910, random_state=42)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取CSV文件使用RF训练模型\n",
    "data = pd.read_csv(os.path.join(sample_csv,sample_csv_name))\n",
    "print(len(data))\n",
    "# 删除有缺失值的行\n",
    "data.dropna(inplace=True)\n",
    "len(data),data.columns\n",
    "# 划分数据集\n",
    "X = data[feature_list]\n",
    "y = data[target_label]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "# 寻找最优树的个数\n",
    "best_tree = rf_best_param(X_train,y_train,n_estimators_range,2)\n",
    "print(f\"最优树的个数为:{best_tree}\")\n",
    "# 初始化和训练随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=best_tree, random_state=42)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "with open(os.path.join(modle_save_path,modle_name), 'wb') as f:\n",
    "    pickle.dump(rf, f)\n",
    "# 加载模型\n",
    "with open(os.path.join(modle_save_path,modle_name), 'rb') as f:\n",
    "    predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试验区域预测数据统一\n",
    "env.workspace = stander_raster_gdb\n",
    "# 查看数据形状的一致性\n",
    "stand_shape = arcpy.RasterToNumPyArray(feature_list[0]).shape\n",
    "for one_raster in feature_list[1:]:\n",
    "    if arcpy.RasterToNumPyArray(one_raster).shape != stand_shape:\n",
    "        # 将形状不同的数据输出\n",
    "        print(one_raster)\n",
    "# 构造数据\n",
    "feature_array_list = []\n",
    "for one_raster in feature_list:\n",
    "    # 读取数据\n",
    "    one_array = arcpy.RasterToNumPyArray(one_raster)\n",
    "    # 将数据转换为一维数组\n",
    "    one_array = one_array.flatten()\n",
    "    # 将数据添加到列表中\n",
    "    feature_array_list.append(one_array)\n",
    "# 将列表转换为数组\n",
    "feature_array_list = np.column_stack(feature_array_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数组转换为数据帧\n",
    "feature_df = pd.DataFrame(feature_array_list,columns=feature_list)\n",
    "# 修改部分列的数据类型\n",
    "feature_df['DL'] = feature_df['DL'].astype('str')\n",
    "feature_df['DZ'] = feature_df['DZ'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400000\n",
      "800000\n",
      "1200000\n",
      "1600000\n",
      "2000000\n",
      "2400000\n",
      "2800000\n",
      "3200000\n",
      "3600000\n",
      "4000000\n",
      "4400000\n"
     ]
    }
   ],
   "source": [
    "# 分割数据并保存为csv文件\n",
    "chunk_size = 400000  # 每个文件的行数\n",
    "total_rows = feature_df.shape[0]\n",
    "for i in range(0, total_rows, chunk_size):\n",
    "    start = i\n",
    "    end = min(i + chunk_size, total_rows)\n",
    "    filename =  os.path.join(cut_csv_path,f'data_chunk_{i}.csv') # 文件名格式可以根据您的需要进行修改\n",
    "    df_chunk = feature_df.iloc[start:end]\n",
    "    df_chunk.to_csv(filename, index=False)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "cut_csv_table_list = [os.path.join(cut_csv_path,_) for _ in os.listdir(cut_csv_path)]\n",
    "# 排序\n",
    "sorted_csv_files = sorted(cut_csv_table_list, key=lambda x: int(x.rsplit('_', 1)[-1].split('.')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# 预测试验区域数据\n",
    "pre_n = 0  # 记录预测的表索引\n",
    "for one_table in sorted_csv_files:\n",
    "    data_df = pd.read_csv(one_table)\n",
    "    temp_pred = predictor.predict(data_df)\n",
    "    temp_pred = pd.DataFrame(temp_pred,columns=[target_label])\n",
    "    temp_pred.to_csv(os.path.join(pred_csv_path,f\"{pre_n}.csv\"))\n",
    "    pre_n += 1\n",
    "    print(pre_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\1.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\2.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\3.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\4.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\5.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\6.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\7.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\8.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\9.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\10.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\11.csv\n"
     ]
    }
   ],
   "source": [
    "# 读取预测结果\n",
    "pre_csv_list = [os.path.join(pred_csv_path,_) for _ in os.listdir(pred_csv_path)]\n",
    "sorted_pre_csv_list = sorted(pre_csv_list,key=lambda x:int(x.rsplit('\\\\', -1)[-1].split('.')[0]))\n",
    "# 保存完整的预测结果\n",
    "pred_df = pd.read_csv(sorted_pre_csv_list[0])\n",
    "for one_pred in sorted_pre_csv_list[1:]:\n",
    "    temp_df = pd.read_csv(one_pred)\n",
    "    pred_df = pd.concat([pred_df,temp_df],axis=0)\n",
    "    print(one_pred)\n",
    "pred_df.to_csv(os.path.join(merge_csv_path,merge_csv_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出预测栅格图\n",
    "env.workspace = stander_raster_gdb\n",
    "pred_df['category_encoded'] = pd.factorize(pred_df[target_label])[0]\n",
    "pred_df['category_encoded'] = pred_df['category_encoded'].astype('float32')\n",
    "raster_array = np.reshape(pred_df['category_encoded'].values,arcpy.RasterToNumPyArray(\"DEM\").shape)\n",
    "env.extent = \"DEM\"  # 指定输出栅格的范围\n",
    "pred_result_raster = mask_raster(raster_array, \"DEM\",30)\n",
    "pred_result_raster.save(os.path.join(pred_raster_gdb,pred_raster_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预览栅格图\n",
    "arcpy.sa.Raster(os.path.join(pred_raster_gdb,pred_raster_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
