{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组整形\n",
    "def resize_arrays(A, B, fill_value=0):\n",
    "    \"\"\"调整数组形状一致\"\"\"\n",
    "    new_shape = (max(A.shape[0], B.shape[0]), max(A.shape[1], B.shape[1]))\n",
    "\n",
    "    if A.shape != new_shape:\n",
    "        if A.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - A.shape[0]\n",
    "            padding = np.full((padding_rows, A.shape[1]), fill_value)\n",
    "            A = np.vstack((A, padding))\n",
    "        elif A.shape[0] > new_shape[0]:\n",
    "            A = A[:new_shape[0], :]\n",
    "\n",
    "        if A.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - A.shape[1]))\n",
    "            A = np.pad(A, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif A.shape[1] > new_shape[1]:\n",
    "            A = A[:, :new_shape[1]]\n",
    "    \n",
    "    if B.shape != new_shape:\n",
    "        if B.shape[0] < new_shape[0]:\n",
    "            padding_rows = new_shape[0] - B.shape[0]\n",
    "            padding = np.full((padding_rows, B.shape[1]), fill_value)\n",
    "            B = np.vstack((B, padding))\n",
    "        elif B.shape[0] > new_shape[0]:\n",
    "            B = B[:new_shape[0], :]\n",
    "\n",
    "        if B.shape[1] < new_shape[1]:\n",
    "            pad_width = ((0, 0), (0, new_shape[1] - B.shape[1]))\n",
    "            B = np.pad(B, pad_width, mode='constant', constant_values=fill_value)\n",
    "        elif B.shape[1] > new_shape[1]:\n",
    "            B = B[:, :new_shape[1]]\n",
    "    \n",
    "    return A, B\n",
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster\n",
    "# 数组整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "modle_path = r\"D:\\ArcgisData\\pred_tl\\pred_moudle\\rfmodel_test.pkl\"\n",
    "with open(modle_path, 'rb') as f:\n",
    "    predictor = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11452727, 0.07394894, 0.06652614, 0.100425  , 0.08745574,\n",
       "       0.08328563, 0.07299646, 0.08405847, 0.09352639, 0.10190037,\n",
       "       0.08690169, 0.0344479 ])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TWI5',\n",
       " 'TPI201',\n",
       " 'TPI101',\n",
       " 'TPI11',\n",
       " 'TPI3',\n",
       " 'TMP',\n",
       " 'SOILQS',\n",
       " 'SLOP',\n",
       " 'PRE',\n",
       " 'NIGTH',\n",
       " 'NDVI',\n",
       " 'DEM',\n",
       " 'CUR',\n",
       " 'ASP',\n",
       " 'PLCUR',\n",
       " 'POCUR',\n",
       " 'OSJL',\n",
       " 'DZ',\n",
       " 'DL',\n",
       " 'LON',\n",
       " 'LAT',\n",
       " 'PH',\n",
       " 'SC',\n",
       " 'SOM']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置工作环境\n",
    "env.workspace = r\"D:\\ArcgisData\\basedata\\basetrain_5m.gdb\"\n",
    "arcpy.ListRasters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['DEM',\n",
       "  'TWI_5',\n",
       "  'TPI_101',\n",
       "  'TMP',\n",
       "  'SLOP',\n",
       "  'PRE',\n",
       "  'NIGTH',\n",
       "  'NDVI',\n",
       "  'LAT',\n",
       "  'LON',\n",
       "  'DZ',\n",
       "  'DL'],\n",
       " 12,\n",
       " 13)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 过滤所用的特征因子\n",
    "check_list = ['A', 'DEM', 'TWI5', 'TPI101', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI',\n",
    "       'LAT', 'LON', 'DZ', 'DL']\n",
    "feature_list = [_ for _ in arcpy.ListRasters() if str(_).replace(\"_\",\"\") in check_list ]\n",
    "feature_list,len(feature_list),len(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWI5 (14884, 11094)\n",
      "TPI201 (14884, 11094)\n",
      "TPI101 (14884, 11094)\n",
      "TPI11 (14884, 11094)\n",
      "TPI3 (14884, 11094)\n",
      "TMP (14884, 11094)\n",
      "SOILQS (14884, 11094)\n",
      "SLOP (14884, 11094)\n",
      "PRE (14884, 11094)\n",
      "NIGTH (14884, 11094)\n",
      "NDVI (14884, 11094)\n",
      "DEM (14884, 11094)\n",
      "CUR (14884, 11094)\n",
      "ASP (14884, 11094)\n",
      "PLCUR (14884, 11094)\n",
      "POCUR (14884, 11094)\n",
      "OSJL (14816, 11002)\n",
      "DZ (14884, 11094)\n",
      "DL (14815, 11002)\n",
      "LON (14884, 11094)\n",
      "LAT (14884, 11094)\n",
      "PH (14884, 11094)\n",
      "SC (14817, 11002)\n",
      "SOM (14886, 11094)\n",
      "SOM1 (14886, 11094)\n"
     ]
    }
   ],
   "source": [
    "# for one_raster in feature_list:\n",
    "#     print(one_raster,arcpy.RasterToNumPyArray(one_raster).shape)\n",
    "for one_raster in arcpy.ListRasters():\n",
    "    print(one_raster,arcpy.RasterToNumPyArray(one_raster).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14884, 11094), (14886, 11094))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dem_array = arcpy.RasterToNumPyArray(\"DEM\")\n",
    "som_array = arcpy.RasterToNumPyArray(\"SOM\")\n",
    "# dl_array = arcpy.RasterToNumPyArray(\"DL\")\n",
    "# dz_array = arcpy.RasterToNumPyArray(\"DZ\")\n",
    "# osjl_array = arcpy.RasterToNumPyArray(\"OSJL\")\n",
    "dem_array.shape, som_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14886, 11094)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dz_array = resize_arrays(dem_array,dz_array,8)[1]\n",
    "# dl_array = resize_arrays(dem_array,dz_array,9)[1]\n",
    "# dz_array.shape,dl_array.shape\n",
    "# osjl_array = resize_arrays(dem_array,osjl_array,0)[1]\n",
    "# osjl_array.shape\n",
    "som_array = resize_arrays(dem_array,som_array,0)[1]\n",
    "som_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造array\n",
    "dem = arcpy.RasterToNumPyArray(\"DEM\").flatten()\n",
    "twi = arcpy.RasterToNumPyArray(\"TWI_5\").flatten()\n",
    "tpi201 = arcpy.RasterToNumPyArray(\"TPI_201\").flatten()\n",
    "tpi101 = arcpy.RasterToNumPyArray(\"TPI_101\").flatten()\n",
    "tpi11 = arcpy.RasterToNumPyArray(\"TPI_11\").flatten()\n",
    "tpi3 = arcpy.RasterToNumPyArray(\"TPI_3\").flatten()\n",
    "tmp = arcpy.RasterToNumPyArray(\"TMP\").flatten()\n",
    "soilqs = arcpy.RasterToNumPyArray(\"SOILQS\").flatten()\n",
    "slop = arcpy.RasterToNumPyArray(\"SLOP\").flatten()\n",
    "pre = arcpy.RasterToNumPyArray(\"PRE\").flatten()\n",
    "night = arcpy.RasterToNumPyArray(\"NIGTH\").flatten()\n",
    "ndvi = arcpy.RasterToNumPyArray(\"NDVI\").flatten()\n",
    "cur = arcpy.RasterToNumPyArray(\"CUR\").flatten()\n",
    "asp = arcpy.RasterToNumPyArray(\"ASP\").flatten()\n",
    "plcur = arcpy.RasterToNumPyArray(\"PLCUR\").flatten()\n",
    "pocur = arcpy.RasterToNumPyArray(\"POCUR\").flatten()\n",
    "# osjl = osjl_array.flatten()\n",
    "lat = arcpy.RasterToNumPyArray(\"LAT\").flatten()\n",
    "lon =  arcpy.RasterToNumPyArray(\"LON\").flatten()\n",
    "dz = arcpy.RasterToNumPyArray(\"DZ\").flatten()\n",
    "dl = arcpy.RasterToNumPyArray(\"DL\").flatten()\n",
    "tri = arcpy.RasterToNumPyArray(\"TRI\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(arcpy.RasterToNumPyArray(\"OSJL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397387.5 3153427.5 5.0 5.0\n"
     ]
    }
   ],
   "source": [
    "# 构造经纬度信息\n",
    "desc = arcpy.Describe(\"DEM\")\n",
    "origin_x = desc.extent.XMin\n",
    "origin_y = desc.extent.YMax\n",
    "pixel_width = desc.meanCellWidth\n",
    "pixel_height = desc.meanCellHeight\n",
    "print(origin_x,origin_y,pixel_width,pixel_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14884, 11094) 397395.0 452855.0\n"
     ]
    }
   ],
   "source": [
    "# 经度\n",
    "array_x = np.zeros(dem_array.shape, dtype=np.float32)\n",
    "array_x[:, 0] = 397387.5+(pixel_width/2)\n",
    "for i in range(1, dem_array.shape[1]):\n",
    "    array_x[:, i] = array_x[:, i-1] + pixel_width\n",
    "print(array_x.shape,array_x[0,1],array_x[0,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14884, 11094) 3153425.0 3079010.0\n"
     ]
    }
   ],
   "source": [
    "# 纬度\n",
    "array_y = np.zeros(dem_array.shape,dtype=np.float32)\n",
    "array_y[0] = 3153427.5-(pixel_height/2)\n",
    "for i in range(1, dem_array.shape[0]):\n",
    "    array_y[i] = array_y[i-1] - pixel_height\n",
    "print(array_y.shape,array_y[0][0],array_y[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = array_x.flatten()\n",
    "y = array_y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features2 = np.column_stack((x,y,asp,dem,dl,ndvi,nigth,pre,slope,soilqs,tmp,tpi11,tpi101,tpi201,tpi3,twi5,dz))\n",
    "['A', 'DEM', 'TWI5', 'TPI101', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI',\n",
    "       'LAT', 'LON', 'DZ', 'DL']\n",
    "features2 = np.column_stack((dem,twi,tpi101,tmp,slop,pre,night,ndvi,lat,lon,dz,dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55048428"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.64787500e+03, 3.99651480e+00, 1.37606201e+01, 1.22750000e+02,\n",
       "       1.55016794e+01, 9.12500000e+02, 1.59999996e-01, 3.24000000e+02,\n",
       "       3.12418000e+06, 4.80640000e+05, 6.00000000e+00, 6.00000000e+00])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features2[300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xulian_data = pd.DataFrame(features2,columns=['X','Y','ASP','DEM','DL','NDVI','NIGHT','PRE','SLOPE','SOILQS','TMP','TPI11','TPI101','TPI201','TPI3','TWI5','DZ'])\n",
    "\n",
    "xulian_data = pd.DataFrame(features2,columns=['DEM', 'TWI5', 'TPI101', 'TMP', 'SLOP', 'PRE', 'NIGTH', 'NDVI',\n",
    "       'LAT', 'LON', 'DZ', 'DL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587369, 12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEM       float64\n",
       "TWI5      float64\n",
       "TPI101    float64\n",
       "TMP       float64\n",
       "SLOP      float64\n",
       "PRE       float64\n",
       "NIGTH     float64\n",
       "NDVI      float64\n",
       "LAT       float64\n",
       "LON       float64\n",
       "DZ        float64\n",
       "DL        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xulian_data['DL'] = xulian_data['DL'].astype(str)\n",
    "xulian_data['DZ'] = xulian_data['DZ'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEM       float64\n",
       "TWI5      float64\n",
       "TPI101    float64\n",
       "TMP       float64\n",
       "SLOP      float64\n",
       "PRE       float64\n",
       "NIGTH     float64\n",
       "NDVI      float64\n",
       "LAT       float64\n",
       "LON       float64\n",
       "DZ         object\n",
       "DL         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEM</th>\n",
       "      <th>TWI5</th>\n",
       "      <th>TPI101</th>\n",
       "      <th>TMP</th>\n",
       "      <th>SLOP</th>\n",
       "      <th>PRE</th>\n",
       "      <th>NIGTH</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "      <td>4.587369e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.586016e+02</td>\n",
       "      <td>2.957591e+00</td>\n",
       "      <td>2.291479e-02</td>\n",
       "      <td>9.103070e+01</td>\n",
       "      <td>1.641409e+01</td>\n",
       "      <td>5.175720e+02</td>\n",
       "      <td>2.461364e-01</td>\n",
       "      <td>1.472668e+03</td>\n",
       "      <td>1.801334e+06</td>\n",
       "      <td>3.314217e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.459478e+02</td>\n",
       "      <td>2.687172e+00</td>\n",
       "      <td>2.367683e+01</td>\n",
       "      <td>7.224962e+01</td>\n",
       "      <td>1.707998e+01</td>\n",
       "      <td>4.083257e+02</td>\n",
       "      <td>1.025573e+00</td>\n",
       "      <td>2.307893e+03</td>\n",
       "      <td>1.422068e+06</td>\n",
       "      <td>2.685677e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-4.508924e-02</td>\n",
       "      <td>-2.395056e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.968567e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.660000e+02</td>\n",
       "      <td>3.428443e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.369167e+02</td>\n",
       "      <td>1.308498e+01</td>\n",
       "      <td>8.211667e+02</td>\n",
       "      <td>2.200000e-01</td>\n",
       "      <td>1.830000e+02</td>\n",
       "      <td>2.814400e+06</td>\n",
       "      <td>4.579600e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.110025e+03</td>\n",
       "      <td>4.885564e+00</td>\n",
       "      <td>5.534058e+00</td>\n",
       "      <td>1.522500e+02</td>\n",
       "      <td>2.974471e+01</td>\n",
       "      <td>8.399167e+02</td>\n",
       "      <td>2.800000e-01</td>\n",
       "      <td>2.311000e+03</td>\n",
       "      <td>2.946160e+06</td>\n",
       "      <td>5.521000e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.806200e+03</td>\n",
       "      <td>2.508574e+01</td>\n",
       "      <td>1.808566e+02</td>\n",
       "      <td>1.696667e+02</td>\n",
       "      <td>8.459243e+01</td>\n",
       "      <td>9.326667e+02</td>\n",
       "      <td>4.469000e+01</td>\n",
       "      <td>9.773000e+03</td>\n",
       "      <td>3.152800e+06</td>\n",
       "      <td>7.292200e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                DEM          TWI5        TPI101           TMP          SLOP  \\\n",
       "count  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06   \n",
       "mean   6.586016e+02  2.957591e+00  2.291479e-02  9.103070e+01  1.641409e+01   \n",
       "std    5.459478e+02  2.687172e+00  2.367683e+01  7.224962e+01  1.707998e+01   \n",
       "min    0.000000e+00 -4.508924e-02 -2.395056e+02  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00 -5.968567e+00  0.000000e+00  0.000000e+00   \n",
       "50%    8.660000e+02  3.428443e+00  0.000000e+00  1.369167e+02  1.308498e+01   \n",
       "75%    1.110025e+03  4.885564e+00  5.534058e+00  1.522500e+02  2.974471e+01   \n",
       "max    1.806200e+03  2.508574e+01  1.808566e+02  1.696667e+02  8.459243e+01   \n",
       "\n",
       "                PRE         NIGTH          NDVI           LAT           LON  \n",
       "count  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06  4.587369e+06  \n",
       "mean   5.175720e+02  2.461364e-01  1.472668e+03  1.801334e+06  3.314217e+05  \n",
       "std    4.083257e+02  1.025573e+00  2.307893e+03  1.422068e+06  2.685677e+05  \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "50%    8.211667e+02  2.200000e-01  1.830000e+02  2.814400e+06  4.579600e+05  \n",
       "75%    8.399167e+02  2.800000e-01  2.311000e+03  2.946160e+06  5.521000e+05  \n",
       "max    9.326667e+02  4.469000e+01  9.773000e+03  3.152800e+06  7.292200e+05  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xulian_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400000\n",
      "800000\n",
      "1200000\n",
      "1600000\n",
      "2000000\n",
      "2400000\n",
      "2800000\n",
      "3200000\n",
      "3600000\n",
      "4000000\n",
      "4400000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "out_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\cut_csv\"\n",
    "chunk_size = 400000\n",
    "total_rows = xulian_data.shape[0]\n",
    "for i in range(0, total_rows, chunk_size):\n",
    "    start = i\n",
    "    end = min(i + chunk_size, total_rows)\n",
    "    filename =  os.path.join(out_path,f'data_chunk_{i}.csv') # 文件名格式可以根据您的需要进行修改\n",
    "    df_chunk = xulian_data.iloc[start:end]\n",
    "    df_chunk.to_csv(filename, index=False)\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_0.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_1200000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_1600000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2000000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2800000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_3200000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_3600000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_4000000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_4400000.csv',\n",
       "  'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_800000.csv'],\n",
       " 12)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取特征表\n",
    "table_list = [os.path.join(out_path,_) for _ in os.listdir(out_path)]\n",
    "table_list,len(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_0.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_400000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_800000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_1200000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_1600000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2000000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2400000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_2800000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_3200000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_3600000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_4000000.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\cut_csv\\\\data_chunk_4400000.csv']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 排序列表\n",
    "\n",
    "# 使用lambda函数将文件名按照最后一个下划线后面的数字大小进行排序\n",
    "sorted_files = sorted(table_list, key=lambda x: int(x.rsplit('_', 1)[-1].split('.')[0]))\n",
    "sorted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测数据存储位置\n",
    "result_path = r\"D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# rf tabular prediction\n",
    "n = 0\n",
    "for one_table in sorted_files:\n",
    "    data_df = pd.read_csv(one_table)\n",
    "    temp_pred = predictor.predict(data_df)\n",
    "    temp_pred = pd.DataFrame(temp_pred,columns=['A'])\n",
    "    temp_pred.to_csv(os.path.join(result_path,f\"{n}.csv\"))\n",
    "    n+=1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-492e8472bd0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtemp_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtemp_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf\"{n}.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mn\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "# autogluon tabular prediction\n",
    "n = 0\n",
    "for one_table in sorted_files:\n",
    "    data_df = pd.read_csv(one_table)\n",
    "    temp_pred = predictor.predict(data_df)\n",
    "    temp_pred.to_csv(os.path.join(result_path,f\"{n}.csv\"))\n",
    "    n+=1\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\0.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\1.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\2.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\3.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\4.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\5.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\6.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\7.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\8.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\9.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\10.csv',\n",
       " 'D:\\\\ArcgisData\\\\pred_tl\\\\pred_table\\\\pre_csv\\\\11.csv']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取预测结果\n",
    "pre_csv_list = [os.path.join(result_path,_) for _ in os.listdir(result_path)]\n",
    "pre_csv_list = sorted(pre_csv_list,key=lambda x:int(x.rsplit('\\\\', -1)[-1].split('.')[0]))\n",
    "pre_csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\1.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\2.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\3.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\4.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\5.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\6.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\7.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\8.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\9.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\10.csv\n",
      "D:\\ArcgisData\\pred_tl\\pred_table\\pre_csv\\11.csv\n"
     ]
    }
   ],
   "source": [
    "pre_df = pd.read_csv(pre_csv_list[0])\n",
    "for one_pred in pre_csv_list[1:]:\n",
    "    temp_df = pd.read_csv(one_pred)\n",
    "    pre_df = pd.concat([pre_df,temp_df],axis=0)\n",
    "    print(one_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存完整的预测数据\n",
    "pre_df.to_csv(os.path.join(r\"D:\\ArcgisData\\pred_tl\\pred_table\\merge_csv\",\"result.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9174738, 4587369)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.size,len(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'A'], dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['category_encoded'] = pd.factorize(pre_df['A'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            int64\n",
       "A                     int64\n",
       "category_encoded    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df['category_encoded'] = pre_df['category_encoded'].astype('float32')\n",
    "pre_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_array = np.reshape(pre_df['category_encoded'].values,arcpy.RasterToNumPyArray(\"DEM\").shape)\n",
    "raster_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "env.extent = \"DEM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 掩膜提取\n",
    "def mask_raster(array,mask_ele,cell_size):\n",
    "    out_raster = arcpy.NumPyArrayToRaster(\n",
    "    array,\n",
    "    arcpy.Point(arcpy.env.extent.XMin, arcpy.env.extent.YMin),\n",
    "    cell_size,\n",
    "    cell_size,\n",
    ")\n",
    "    \"\"\"按掩膜提取栅格,空间参考设定为:CGCS2000_3_Degree_GK_CM_108E\"\"\"\n",
    "    output_coordinate_system = arcpy.Describe(mask_ele).spatialReference\n",
    "    with arcpy.EnvManager(outputCoordinateSystem=output_coordinate_system,snapRaster=mask_ele, cellSize=mask_ele):\n",
    "        result_raster = arcpy.sa.ExtractByMask(out_raster, mask_ele, \"INSIDE\")\n",
    "        return result_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成\n"
     ]
    }
   ],
   "source": [
    "# 按掩膜处理\n",
    "# result_path = r\"D:\\ArcgisData\\pred_tl\\pred_database\\TL_basedata.gdb\"\n",
    "result_raster = mask_raster(array_y,\"DEM\", 5)\n",
    "result_raster.save(\"LAT\")\n",
    "print(\"完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
